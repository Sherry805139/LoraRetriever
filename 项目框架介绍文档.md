# LoraRetriever 项目框架介绍文档

## 项目概述

LoraRetriever 是一个基于论文 "LoraRetriever: Input-Aware LoRA Retrieval and Composition for Mixed Tasks in the Wild" (ACL 2024 Findings) 的研究项目。该项目实现了一个能够根据输入任务动态检索和组合多个LoRA（Low-Rank Adaptation）模块的框架，以增强大语言模型在混合任务场景下的性能。

### 核心思想
- **输入感知检索**：根据具体的输入任务，从预训练的LoRA模块库中检索最相关的适配器
- **动态组合**：将多个检索到的LoRA模块进行融合，形成针对当前任务的最优适配器
- **异构任务处理**：能够高效处理多种不同类型的NLP任务

## 项目架构

### 系统整体架构
```
输入文本 → 语义编码 → LoRA检索 → 适配器组合 → 基础模型推理 → 输出结果
```

1. **语义编码模块**：使用InstructorEmbedding对输入文本进行编码
2. **LoRA检索模块**：基于FAISS进行相似度搜索，检索相关的LoRA模块
3. **适配器组合模块**：将多个LoRA模块按照权重进行融合
4. **推理模块**：使用组合后的LoRA适配器增强基础语言模型

### 技术栈
- **基础模型**：Llama-2-7b/13b
- **参数高效微调**：PEFT（Parameter-Efficient Fine-Tuning）
- **向量检索**：FAISS-GPU
- **语义编码**：InstructorEmbedding
- **深度学习框架**：PyTorch + Transformers

## 核心文件详解

### 主要执行文件

#### 1. `main.py`（主程序入口）
**作用**：项目的核心执行文件，包含完整的评估流程

**核心功能**：
- `load_base_model()`: 加载基础Llama模型和分词器
- `init_vector_db()`: 初始化向量数据库，用于LoRA检索
- `load_peft_model()`: 加载和配置多个PEFT适配器
- `eval_datasets()`: 主要评估函数，实现完整的检索-组合-推理流程

**关键流程**：
1. 加载基础模型（Llama-2）
2. 初始化LoRA检索索引
3. 对每个输入进行LoRA检索
4. 组合检索到的LoRA模块
5. 使用组合后的适配器进行推理
6. 保存结果

#### 2. `eval_all.sh`（批量评估脚本）
**作用**：运行所有评估配置的shell脚本

**评估模式**：
- `mixture`: LoRA模块混合组合
- `fusion`: LoRA模块融合
- `selection`: 单个LoRA选择
- `best_selection`: 最佳LoRA选择

**参数说明**：
- `--lora_num`: 检索的LoRA数量（1或3）
- `--ood`: 是否进行域外（Out-of-Domain）评估
- `--eval_type`: 评估类型（mixture/fusion）

#### 3. `summarize_results.py`（结果汇总脚本）
**作用**：汇总和分析所有实验结果

**功能**：
- 计算BLEU、ROUGE、EM等评估指标
- 按领域和任务组织结果
- 生成LaTeX格式的结果表格

### 核心工具模块

#### 1. `utils/instructor_retrieval.py`（检索模块）
**作用**：实现基于语义相似度的LoRA检索机制

**核心函数**：
- `initialize_index()`: 初始化FAISS索引
  - 加载InstructorEmbedding模型
  - 为每个LoRA计算平均嵌入向量
  - 构建FAISS索引用于快速检索

- `get_embeddings()`: 文本编码函数
  - 使用预训练的Instructor模型进行文本嵌入

- `perform_search()`: 执行相似度搜索
  - 对查询文本进行编码
  - 在FAISS索引中搜索最相似的LoRA模块
  - 返回检索结果和映射矩阵

**技术细节**：
- 使用`Styxxxx/lora_retriever`作为检索模型
- 支持域外样本排除（exclude_list）
- 返回二进制映射矩阵指示每个查询检索到的LoRA

#### 2. `utils/prompter.py`（提示词管理）
**作用**：管理不同任务的提示词模板

**核心功能**：
- 加载JSON格式的提示词模板
- 根据输入生成完整的提示词
- 支持有输入和无输入两种模式

**模板格式**：
- `prompt_input`: 包含指令和输入的模板
- `prompt_no_input`: 仅包含指令的模板
- `response_split`: 响应分割标记

### 配置文件

#### 1. `config/config2.json`（LoRA配置文件）
**作用**：定义所有可用的LoRA模块及其训练样本

**结构**：
```json
[
    {
        "model_name": "任务名称",
        "sample": [
            {
                "inputs": "输入文本",
                "targets": "目标输出"
            }
        ],
        "domain": "任务域"
    }
]
```

**包含的任务类型**：
- 情感分析（sentiment）：sst2
- 自然语言推理（nli）：cb, wnli
- 阅读理解（reading comp）：multirc, squad_v2
- 结构化文本生成（struct to text）：web_nlg_en
- 指代消解（coreference）：definite_pronoun_resolution
- 机器翻译（translation）：wmt16_translate_tren

#### 2. `templates/`目录（提示词模板）
**作用**：存储不同格式的提示词模板

**主要模板**：
- `alpaca.json`: Alpaca格式模板，用于指令微调
- `alpaca_legacy.json`: 旧版Alpaca格式
- `alpaca_short.json`: 简化版Alpaca格式
- `vigogne.json`: Vigogne格式模板

### PEFT模块

#### `peft/`目录（参数高效微调库）
**作用**：项目使用的自定义PEFT库，支持高级LoRA操作

**核心特性**：
- 支持多LoRA适配器的动态加载和卸载
- 实现LoRA模块的混合和融合策略
- 提供mapping矩阵驱动的适配器组合

**关键文件**：
- `src/peft/peft_model.py`: PEFT模型的核心实现
- `src/peft/tuners/`: 包含各种tuner实现
- `src/peft/utils/`: 工具函数

## 实验设计

### 评估策略
1. **mixture**: 多个LoRA模块按权重混合
2. **fusion**: LoRA模块深度融合
3. **selection**: 选择单个最佳LoRA
4. **best_selection**: 理想情况下的最佳选择

### 域外评估（OOD）
- 在检索时排除与当前任务相同的LoRA模块
- 模拟真实场景中的跨域泛化能力

### 评估指标
- **BLEU**: 机器翻译和文本生成质量
- **ROUGE**: 摘要和文本生成质量
- **EM（Exact Match）**: 精确匹配准确率

## 运行流程

### 环境配置
```bash
conda create --name lora_retriever python=3.10
conda activate lora_retriever
pip install -e peft/
pip install -r requirements.txt
```

### 执行评估
```bash
# 运行所有评估
bash eval_all.sh

# 汇总结果
python summarize_results.py
```

### 单独运行示例
```bash
python main.py --data_path dataset/combined_test.json \
                --res_path results/fusion.json \
                --eval_type fusion \
                --lora_num 3 \
                --batch_size 8
```

## 关键技术创新

### 1. 输入感知检索
- 使用InstructorEmbedding进行任务感知的文本编码
- 基于语义相似度而非任务标签进行LoRA检索
- 支持跨域任务的LoRA重用

### 2. 动态适配器组合
- 实现多种LoRA组合策略（mixture, fusion）
- 使用映射矩阵控制不同样本的LoRA组合
- 支持运行时动态加载和卸载适配器

### 3. 混合任务处理
- 单一模型处理多种NLP任务
- 避免为每个新任务重新训练整个模型
- 提高参数效率和推理速度

## 实验结果分析

### 性能对比
- 相比传统的单一LoRA方法，混合策略显著提升性能
- 域外评估验证了方法的泛化能力
- 不同组合策略在不同任务上表现各异

### 消融研究
- LoRA数量对性能的影响
- 不同检索策略的效果比较
- 组合方法的优劣分析

## 未来发展方向

1. **扩展到更多模型**：支持其他大语言模型（GPT、Claude等）
2. **动态权重学习**：学习任务特定的LoRA组合权重
3. **在线学习**：支持新任务的实时LoRA训练和集成
4. **多模态扩展**：扩展到视觉-语言任务

## 总结

LoraRetriever项目提供了一个创新的框架，通过输入感知的LoRA检索和动态组合机制，有效解决了大语言模型在混合任务场景下的适配问题。项目的模块化设计和完整的评估体系为参数高效微调领域的研究提供了重要参考。

对于刚接触LoRA研究的同学，建议：
1. 首先理解LoRA的基本原理和PEFT概念
2. 深入研究检索模块的实现机制
3. 分析不同组合策略的效果差异
4. 尝试在新任务上应用该框架

这个项目不仅展示了LoRA技术的实际应用，也为多任务学习和参数高效微调提供了新的思路。