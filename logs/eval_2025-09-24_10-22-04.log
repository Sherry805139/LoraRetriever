/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/sentence_transformers/models/Dense.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(os.path.join(input_path, 'pytorch_model.bin'), map_location=torch.device('cpu')))
load INSTRUCTOR_Transformer
max_seq_length  512
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.84it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.90it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.70it/s]
Evaluating:   0%|          | 0/2395 [00:00<?, ?item/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Evaluating:   0%|          | 0/2395 [00:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:09<?, ?item/s]['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Abraham A. Ribicoff was married to Casey Ribicoff who was born in Chicago. Abraham A. Ribicoff served as the United States Secretary of Health, Education, and Welfare., expected_answer: Abraham A. Ribicoff once worked for the United States Secretary of Health, Education, and Welfare office and was married to Chicago-born Casey Ribicoff.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: What is the elevation of Ardmore Airport (New Zealand) above the sea level?, expected_answer: Ardmore Airport in New Zealand is operated by the Civil Aviation Authority of New Zealand and is 34 metres above sea level. It has a runway named 03R/21L which is 1,411 long and its third runway has a poaceae surface.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: African Americans are an ethnic group in the United States of America. It is also the country of Austin, Texas. Americans is the demonym of the United States., expected_answer: The country of Austin, Texas, is United States and its inhabitants are called Americans and African Americans are an ethnic group within the country.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Andrews County Airport has a runway surface type of asphalt, and is located 973 feet above sea level., expected_answer: Andrews County Airport is 973 metres above sea level and The 4th runway is made of Asphalt.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Alfredo Zitarrosa is a singer, he has a background as a solo singer. He is signed to RCA Records. He has been associated with Ciro Pérez and Héctor Numa Moraes. Alfredo Zitar, expected_answer: Alfredo Zitarrosa, recordLabel, RCA Records; Alfredo Zitarrosa, associatedBand/associatedMusicalArtist, Ciro Pérez; Alfredo Zitarrosa, associatedBand/associatedMusicalArtist, Héctor Numa Moraes; Alfredo Zitarrosa, background, "solo singer"; Alfredo Zitarrosa, genre, Zamba (artform)
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: Chicago is part of DuPage County in Illinois., expected_answer: Chicago is part of DuPage County in Illinois.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Barny Cakes from France is made with sponge cake and French is the language. The leader of France is Gérard Larcher and Claude Bartolone., expected_answer: Barny Cakes, which are made from sponge cake, are from France, where Gerard Larcher and Claude Bartolone are leaders and French is the language spoken.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The country is the location of Albany, a city in Dougherty County, Georgia. The people inhabiting the United States are known as Americans and include the ethnic group of Native Americans., expected_answer: United States, demonym, Americans; Albany, Georgia, isPartOf, Dougherty County, Georgia; Albany, Georgia, country, United States; United States, ethnicGroup, Native Americans in the United States
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: bionico course dessert with variation of honey, expected_answer: A popular dessert is Bionico and a variation of this dish can be honey.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: A loyal character dancer is dancing with a book titled, isbn number, ., expected_answer: The book, A Loyal Character Dancer, has the ISBN number of 1-56947-301-3.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The author of the book Aenir is Garth Nix and it has the oclcNumber 45644811. It is a book in the print media., expected_answer: Aenir, written by Garth Nix, was produced in print and has the OCLC number 45644811.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Alex Plante was born in Brandon, Manitoba in 1989. He played for Anyang Halla and his birthday is May 9th., expected_answer: Alex Plante, who played for the club Anyang Halla, was born on May 9th 1989, in Brandon, Manitoba.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: hypermarket chain in the city of sao paulo, expected_answer: The main product of Hypermarcas, which is located in São Paulo, is drugs.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Elliot See BIRTH_DATE 1927-07-23
Elliot See DEATH_DATE 1987-05-08
Elliot See EDUCATION_LE, expected_answer: Elliot See, almaMater, University of Texas at Austin; Elliot See, occupation, Test pilot; Elliot See, birthDate, "1927-07-23"; Elliot See, birthPlace, Dallas; University of Texas at Austin, affiliation, University of Texas System; Elliot See, deathPlace, St. Louis; Elliot See, status, "Deceased"
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Aleksandre Guruli has played for both FC Karpaty Lviv and AS Lyon-Duchère., expected_answer: Aleksandre Guruli's former clubs include FC Karpaty Lviv and AS Lyon-Duchère.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Alcatraz Versus the Evil Librarians Publisher Hardcover ISBN 0-439-92550-9, expected_answer: Alcatraz Versus the Evil Librarians, mediaType, Hardcover; Alcatraz Versus the Evil Librarians, isbnNumber, "0-439-92550-9"
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: aaron turner is an american musician and artist, best known as a guitarist and vocalist for the bands isis, sumac and syberia. he is also a member of the bands sunn 0))), v, expected_answer: Aaron Turner performed with the band Sumac and is a Black metal musician. Death metal is a musical fusion of black metal.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: hypermarket founding date on 1st january 2001 in the city of brazil with a population density of 23.8 people per square kilometer ., expected_answer: Hypermarcas was founded January 1, 2001 as a pharmaceutical company primarily focusing on cosmetics. It's located in Brazil, which has as population density of 23.8.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: A.F.C. Fylde has 3180 members, plays at Warton in Fylde and is called "Association Football Club Fylde"., expected_answer: AFC Fylde has the full name "Association Football Club Fylde," they have 3180 members and their ground is located in Warton, Fylde.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: AIDAluna was built in 2009 and is active today., expected_answer: AIDAluna service was started on the 22nd of March, 2009.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: language
speak
spoken, expected_answer: Greece, language, Greek language
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Abdulsalami Abubakar was the successor to Olusegun Obasanjo who was the Vice President. Mike Akhigbe was the predecessor to Oladipo Diya., expected_answer: Abdulsalami Abubakar served while Mike Akhigbe, who was preceded by Oladipo Diya, was Vice President. He was succeeded by Olusegun Obasanjo.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: [Table] LEADER_TITLE_SUFFIX Prime Minister of Romania
[Table] ETHNIC_GROUP The Germans of Romania
[Table] COUNTRY_CAPITAL Buchar, expected_answer: Romania, ethnicGroup, Germans of Romania; Romania, leaderTitle, Prime Minister of Romania; Romania, leader, Klaus Iohannis; Romania, capital, Bucharest; 1 Decembrie 1918 University, city, Alba Iulia; 1 Decembrie 1918 University, country, Romania; Romania, anthem, Deșteaptă-te, române!
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
Evaluating:   0%|          | 0/2395 [01:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [01:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:20<?, ?item/s]generated_answer: Gus Poyet played for Chelsea F.C. and is the manager of Real Zaragoza. He was the manager of AEK Athens FC which competes in the Greece Superleague. Olympiacos F., expected_answer: AEK Athens F.C., league, Superleague Greece; Superleague Greece, champions, Olympiacos F.C.; AEK Athens F.C., manager, Gus Poyet; Gus Poyet, club, Real Zaragoza; Gus Poyet, club, Chelsea F.C.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: In the Visayas region of the Philippines, coconut milk is used to prepare the Binignit dish, which includes sweet potato., expected_answer: Binignit comes from the Visayas region of the Philippines. Its main ingredients are sweet potato and coconut milk.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Gruppo Bertone is a design company founded in Turin, Italy, that produced the Abarth 1000 GT Coupé., expected_answer: Gruppo Bertone, of Turin Italy, designed the Abarth 1000 GT Coupe.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Epoch of 1998 RO1 is 2013-11-04, expected_answer: 66063 1998 RO1 has an epoch date of 4 November 2013.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: What is the country that Baked Alaska is from?, expected_answer: Baked Alaska has the main ingredients of meringue, ice cream and sponge cake (or Christmas pudding). It is found in France, the US, China, Hong Kong, New York and Paris.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: Accademia di Architettura di Mendrisio, established in what year?, expected_answer: The Accademia di Architettura di Mendrisio is located in Ticino, Switzerland. It was established in 1996 and it has 600 students. The leader of Switzerland is Johann Schneider-Ammann.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Andrews County Airport is located in Texas which is part of the United States and has the capital city of Austin, the largest city of Houston and the official language of Spanish., expected_answer: Andrews County Airport is in Texas in the U.S.A. where Spanish is one of the languages spoken. Houston is the largest city in the state and its capital is Austin.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: German leader Stanislaw Tillich, expected_answer: The leader of Germany is Stanislaw Tillich.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Amdavad ni Gufa, location, Ahmedabad, expected_answer: The address for Amdavad ni Gufa is Lalbhai Dalpatbhai Campus, near CEPT University, opp. Gujarat University, University Road, Gujarat, Ahmedabad, India.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: Amsterdam Airport Schiphol is an international airport serving Amsterdam, the Netherlands. It is located 9 kilometres (5.6 mi) southwest of Amsterdam city centre, in the municipality of Haarlemmermeer, province of, expected_answer: Amsterdam Airport Schiphol serves the city of Amsterdam.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: bakso noodle with bakso ingredient, expected_answer: The dish Bakso contains noodles.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Andrews County Airport is in Texas, which is in the United States. The language spoken in Texas is English and the demonym is Texan., expected_answer: Andrews County Airport, Texas is in the United States. The inhabitants of Texas, Texans, speak English.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Alan Martin was born on January 1st 1989. He plays for the Crewe Alexandra FC and for the Aldershot Town F.C., expected_answer: Alan Martin (footballer), birthDate, 1989-01-01; Alan Martin (footballer), club, Crewe Alexandra F.C.; Alan Martin (footballer), club, Aldershot Town F.C.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Asian Americans ethnic group United States
A Loyal Character Dancer published there, expected_answer: A Loyal Character Dancer, country, United States; United States, ethnicGroup, Asian Americans
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Bakewell pudding is a dessert from Derbyshire Dales that has a variation called Bakewell tart. It is made from ground almond, jam, butter, eggs., expected_answer: Bakewell tart is a variation of Bakewell pudding that originates from the Derbyshire Dales. It is a dessert that has the main ingredients of ground almond, jam, butter and eggs.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: AWH Engineering College, city, "Kuttikkattoor"; Kerala, hasToItsNorthwest, Mahé, India, expected_answer: AWH Engineering College in Kuttikkattoor, India is in the state of Kerala which has Mahe to its northwest. The school has 250 employees. India is home to the Ganges River and its largest city is Mumbai.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Akeem Dent played for the Houston Texans before he joined the Atlanta Falcons, where Arthur Blank is the owner. The Falcons are based in Atlanta., expected_answer: Akeem Dent made his debut with the Atlanta Falcons who play in Atlanta and are owned by Arthur Blank. He used to play in Houston for the Houston Texans.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Singapore is the country of Beef kway teow, where the currency is the Singapore dollar and the leader is Halimah Yacob., expected_answer: Beef kway teow, country, Singapore; Singapore, currency, Singapore dollar; Singapore, leader, Halimah Yacob
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: N.R. Pogson, an English national, was born in Nottingham and died in Chennai. He discovered 107 Camilla on 17 November 1868., expected_answer: 107 Camilla, discoverer, N. R. Pogson; N. R. Pogson, deathPlace, Chennai; N. R. Pogson, birthPlace, Nottingham; 107 Camilla, discovered, 1868-11-17; N. R. Pogson, nationality, England
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: arena, architect, wall, expected_answer: 3Arena, location, North Wall, Dublin; 3Arena, architect, "HOK SVE"
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: American singer-songwriter and guitarist Anders Osborne has recorded and released several albums with Alligator Records., expected_answer: Anders Osborne was signed to the record label 'Alligator Records'.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: East Link Bridge over the 3Arena, expected_answer: The 3Arena is located at East Link Bridge.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: Barny cakes are high in protein with 1.8 g per 100g, expected_answer: Barny cakes contain 1.8 g of protein.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: discover, discoverer, find, finder, pardon, sentence, sentence, expected_answer: 107 Camilla, discoverer, N. R. Pogson
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Akeem Dent was born on 27 September 1987., expected_answer: Akeem Dent was born September 27, 1987.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: AmeriGas is located in the United States. It is in King of Prussia, Pennsylvania, which is in the North American Eastern Time Zone. The United States has a total area of 9833516.6, expected_answer: AmeriGas is located in King of Prussia, Pennsylvania which is in the North American Eastern Time Zone. AmeriGas is working in the United States which has a total area of 9,833,516.63 square kilometers.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
Evaluating:   0%|          | 0/2395 [02:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [02:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:33<?, ?item/s]generated_answer: Allen Forrest is a solo singer from Fort Campbell, KY who has been raised in Dothan, AL. His genre is acoustic music., expected_answer: Allen Forrest, a solo singer who performs acoustic music, was born in Fort Campbell, KY and was raised in the town of Dothan, AL.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Cocum is a cheap coffee shop. It is family friendly and has a customer rating of 5 out of 5., expected_answer: The coffee shop named Cocum is cheap, serves food, and is family friendly. It is also five star rated.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: die, space, time, expected_answer: Alan Shepard DEATH_PLACE California
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Olympiacos F.C. LEAGUE Greece Superleague
Olympiacos F.C. MANAGER Gus Poyet
Olympiacos F.C. CHAMPIONS_LEAG, expected_answer: AEK Athens F.C. LEAGUE Superleague Greece
Superleague Greece CHAMPIONS Olympiacos F.C.
AEK Athens F.C. MANAGER Gus Poyet
Gus Poyet CLUB Real Zaragoza
Gus Poyet CLUB Chelsea F.C.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Browns Cambridge is a family friendly coffee shop near the Crowne Plaza Hotel. It serves English food and has a customer rating of 5 out of 5., expected_answer: Browns Cambridge is a coffee shop near Crowne Plaza Hotel. It serves English food. It is family friendly and has a 5 star rating.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: A student at Cornell University, a land-grant and research university in the state of New York, is dressed in the school colors of red and white as they take part in a university football game., expected_answer: The Administrative Science Quarterly is published by Cornell University, Ithaca, in the state of New York. Cornell University (nicknamed 'Cornell Big Red') is affiliated with the Association of Public and Land Grant Universities.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Punter is a high priced Chinese coffee shop near Café Sicilia, it is child friendly, and has an average customer rating., expected_answer: The Punter is a child friendly coffee shop with Chinese food near Café Sicilia,It has an average customer rating and its  price high range.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: coffee shop near ranch serves food and drinks in the moderate price range ., expected_answer: Wildwood is a moderately priced coffee shop serving English food. It is located near Ranch and has a low customer rating.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: candidate, district, incumbent, expected_answer: New Jersey 8 CANDIDATES Bill Pascrell (D) 62% Matthew Kirnan (R) 36%
New Jersey 8 INCUMBENT Bill Pascrell
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Fitzbillies is a kid friendly coffee shop that serves English food. It is located in the city centre and has a high customer rating. The price range is £20-25., expected_answer: Fitzbillies is a kid friendly English coffee shop with average prices and a high customer rating, located in the city centre.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The American Journal of Mathematics is a bimonthly publication in the mathematics academic discipline. Its abbreviation is Am. J. Math. and its ISSN number is 1080-6377., expected_answer: The American Journal of Mathematics is abbreviated to Am. J. Math. and comes under the discipline of Math. It is published bimonthly and has the ISSN number 1080-6377.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: lemon is an order in which roses are placed, expected_answer: Lemon is under the order of Rosids.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: coffee
shop
moderately, expected_answer: Cotto eatType coffee shop
Cotto priceRange less than £20
Cotto near The Portland Arms
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: Georgia 6 DEMOCRATIC
Georgia 6 PARTY democratic, expected_answer: Georgia 6 INCUMBENT John James Flynt, Jr.
John James Flynt, Jr. PARTY Democratic
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Bruno Junqueira FINISH_POSITION 2
Bruno Junqueira RACE_RESULT 0.8, expected_answer: Bruno Junqueira TEAM Newman/Haas Racing
[TABLECONTEXT] [TITLE] 2003 Grand Prix of Monterey
Bruno Junqueira LAPS 87
[TABLECONTEXT] DRIVERS Bruno Junqueira
87 TIME/RETIRED +0.8 secs
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: coffee
shop
welcome, expected_answer: Cocum eatType coffee shop
Cocum food Chinese
Cocum customer rating 5 out of 5
Cocum familyFriendly yes
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Stephen J. Solarz was first elected in 1974 as a member of the Democratic Party and is the incumbent for New York 13., expected_answer: The Democratic party incumbent Stephen J. Solarz get first elected to new york 13 in 1974.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: HOK SVE ARCHITECT 3Arena
3Arena ARCHITECT HOK SVE, expected_answer: 3Arena ARCHITECT "HOK SVE"
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Punter is a coffee shop with English food. It is moderately priced and has a 3 out of 5 customer rating. It is not kid friendly and is near Café Sicilia., expected_answer: An English coffee shop located near Café Sicilia, called The Punter, is has moderate price range, customer ratings of 3 out of 5, and is not kid friendly.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: Buzz Aldrin NATIONALITY United States, expected_answer: Buzz Aldrin NATIONALITY United States
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Wildwood eatType coffee shop
The Wildwood food Chinese
The Wildwood priceRange high
The Wildwood customer rating 1 out of 5
The Wildwood area near The Ranch, expected_answer: Wildwood eatType coffee shop
Wildwood food Chinese
Wildwood priceRange high
Wildwood customer rating 1 out of 5
Wildwood near Ranch
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: San Sebastián de los Reyes is in Spain., expected_answer: San Sebastián de los Reyes is in Spain.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Bakewell tart COUNTRY Derbyshire
Bakewell tart REGION Derbyshire Dales
Bakewell tart CONTAINS Frangipane
Bakewell tart VARIATION Bakewell pudding, expected_answer: Derbyshire Dales LEADER_NAME Patrick McLoughlin
Bakewell pudding DISH_VARIATION Bakewell tart
Bakewell tart REGION Derbyshire Dales
Derbyshire Dales ADMINISTRATIVE_COUNTY Derbyshire
Bakewell tart INGREDIENT Frangipane
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: eagle near café brazil, expected_answer: The Eagle is located near Café Brazil and is not family friendly.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Punter is a coffee shop that serves English food. It is not family friendly and is located near Café Sicilia. It has an average customer rating., expected_answer: The Punter is a non-family-friendly English coffee shop near Café Sicilia with an average customer rating and has an average customer rating.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Port Authority of New York and New Jersey is headquartered at 4 World Trade Center., expected_answer: Port Authority of New York and New Jersey headquarter is Four World Trade Center.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
Evaluating:   0%|          | 0/2395 [03:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [03:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:41<?, ?item/s]generated_answer: A street with buildings and a sign in the middle., expected_answer: 11 Diagonal Street was completed in 1983.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Golden Palace eatType coffee shop
The Golden Palace food English
The Golden Palace priceRange moderate
The Golden Palace customer rating 1 out of 5
The Golden Palace area riverside, expected_answer: The Golden Palace eatType coffee shop
The Golden Palace food English
The Golden Palace priceRange moderate
The Golden Palace customer rating 3 out of 5
The Golden Palace area riverside
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Fitzbillies is a coffee shop that serves English food. It is located in the city centre. It is moderately priced and kid friendly. It has a customer rating of 1 out of 5., expected_answer: With a rating of 1 out of 5, Fitzbillies is an English coffee shop with moderate prices. It is located in the city centre and is kid friendly.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Golden Palace is a moderately priced coffee shop., expected_answer: The Golden Palace is a coffee shop that offers a full breakfast at a moderate price.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Eagle is a cheap, kid friendly coffee shop in the city centre near Burger King.  They have Chinese food and a customer rating of 5 out of 5., expected_answer: The Eagle coffee shop specializes in providing Chinese food at cheap prices while garnering a customer service rating of 5 out of 5, located in the city centre, the Eagle is family friendly and is near the Burger King.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: The Punter is a customer rating high on the area riverside., expected_answer: If you want somewhere to take the kids on the riverside, come to The Punter - highly rated
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: The eagle eat type coffee shop, customer rating 3 out of 5, area riverside, family friendly yes, near burger king., expected_answer: The riverside area near Burger King has a coffee shop that is kids-friendly. It has a price range in The Eagle. I give the food a 3 out of 5.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: a food stall selling a variety of food including coffee at a local market during a food festival ., expected_answer: A kids friendly coffee shop called Cocum has English food. It has a customer rating of 3 out of 5 and has a moderate price range.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: adria, bartender, seattle, expected_answer: Adria FROM Seattle, WA
Adria AGE 25
Adria PROFESSION Bartender
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Cocum is a kid-friendly, cheap English coffee shop. It has an average customer rating and is not recommended for people who are allergic to peanuts., expected_answer: Cocum sells English food. His coffee shop is child friendly and his price range is cheap. He receives an average rating.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Eagle is a coffee shop with a moderate price range. It is near Burger King in the riverside area. It has a customer rating of 1 out of 5., expected_answer: Near Burger King by the riverside there is a coffee shop called The Eagle yes with a moderate price range and rating of 1 out of 5
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Golden Palace eatType coffee shop
The Golden Palace food coffee
The Golden Palace priceRange moderate
The Golden Palace area riverside
The Golden Palace food coffee
The Golden Palace food coffee shop
The Golden Palace food coffee shop take away, expected_answer: The Golden Palace eatType coffee shop
The Golden Palace priceRange moderate
The Golden Palace area riverside
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: high school football player running with the ball, expected_answer: Thomas Tyner attended Aloha High School.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Fitzbillies is a cheap coffee shop in the city centre that serves English food and has an average customer rating. It is not family friendly., expected_answer: There's a cheap English coffee shop that's not family-friendly in the city centre with an average rating called Fitzbillies.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: ashgabat international airport located in ashgabat with runway length 38000 feet and elevation 211, expected_answer: Ashgabat International Airport (located in Ashgabat) is elevated 211 metres above sea level and has a runway length of 3800.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Golden Palace is a Chinese coffee shop in the city centre. The price range is moderate and the customer rating is 3 out of 5., expected_answer: The Golden Palace is a Chinese coffee shop located in city centre. It is moderately priced and has a 3 out of 5 customer rating.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Eagle is a coffee shop in the riverside area near Burger King. It has a high customer rating and serves English food., expected_answer: The Eagle is a coffee shop in the riverside area, near Burger King that has a high customer rating. They serve English food at a £30  minimum, and aren't friendly to children.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: office of national drug control policy was created by president bill clinton in 1998 and was led by lee p brown who served from 1998 to 2001 ., expected_answer: Lee P. Brown was the third director of the Office of National Drug Control Policy.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Al Asad Airbase is operated by the United States Air Force and is located in Iraq. The runway length is 3078.48., expected_answer: Operated by the United States Air Force, Al Asad Airbase, in Iraq, has a runway length of 3078.48 metres.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Acharya Institute of Technology was established in 2000 and offers tennis, which is governed by the International Tennis Federation., expected_answer: The Acharya Insitute of Technology offers tennis and it was established in 2000. The tennis governing body is the International Tennis Federation.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: There is a coffee shop in the city centre called Fitzbillies, that serves English food., expected_answer: The Fitzbillies coffee shop which sells English food is located in the city centre.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: There is a coffee shop called Fitzbillies in the city centre that offers Chinese food for £20-25. It is not family friendly and has a high customer rating., expected_answer: Fitzbillies is a coffee shop that offers Chinese food in the 20 to 25 pound price range.  It has a high customer rating and is located in the city centre.  It is not kid-friendly.
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: The Eagle is a food and drink venue located near the area of Burger King and a riverside. The Eagle is a food and drink venue that is rated 5 out of 5 by its customers. The Eagle, expected_answer: There is a cheap coffee shop that serves English food  in the riverside area near Burger King named The Eagle. It was rated by customers 5 out of 5.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
Evaluating:   0%|          | 0/2395 [04:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [04:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:45<?, ?item/s]generated_answer: The Phoenix area city centre is the place where the airport is located., expected_answer: The City Centre has a famous average place called The Phoenix.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The journal AIDS is published by Lippincott Williams & Wilkins in the United Kingdom. The leader of the United Kingdom is Elizabeth II., expected_answer: The AIDS journal was published by Lippincott Williams &amp; Wilkins in the United Kingdom where Elizabeth II is the leader.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Browns Cambridge is a coffee shop serving English food near the Crowne Plaza Hotel in the riverside area. It has a low customer rating and is not child-friendly., expected_answer: Browns Cambridge is a English food, coffee shop that is not family-friendly near Crowne Plaza Hotel in riverside with a low customer rating.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: The Cricketers is a family-friendly coffee shop located near The Portland Arms that has an English menu and a high customer rating., expected_answer: A coffee shop with a high customer rating that serves English food is in near The Portland Arms.  It's called The Cricketers and it's kid-friendly.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: The Phoenix has a customer rating of 1 out of 5 and is located in the riverside area., expected_answer: In riverside is The Phoenix with a 1 out of 5 customer rating.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Punter is a coffee shop that serves Chinese food. It is near Café Sicilia and has a customer rating of high. It also has a price range of more than £30., expected_answer: The Punter is a coffee shop providing Chinese food in the more than £30 price range. It is near Café Sicilia. Its customer rating is high.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: The Eagle is a coffee shop in the city centre near Burger King. It is moderately priced and serves Chinese food. It is kid friendly and has a customer rating of 3 out of 5., expected_answer: There is a Chinese food coffee shop called The Eagle located in the center. of the city near Burger King. It is kid friendly and is moderately priced with a 3 out of 5 customer rating.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: There is a high priced Chinese coffee shop near The Portland Arms called Cotto. The customer rating is 1 out of 5 and is located in the city centre., expected_answer: Cotto is a coffee shop with Chinese food in the high price range with a customer rating of 1 out of 5. in the city centre area near The Portland Arms.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: The Eagle is a family friendly coffee shop located in the riverside area near Burger King.  It serves English food and has a high customer rating.  It has a price range of £20-25., expected_answer: The Eagle is a coffee shop providing average-priced English food, it is located by the riverside, near Burger King, kids-friendly and customer-rated high.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: Fitzbillies is a coffee shop that serves English food in the city centre. The price range is moderate. It is kid friendly and has a customer rating of 1 out of 5., expected_answer: Fitzbillies is a coffee shop in the city centre serving British food.  It's family friendly, moderately priced and has 1 out of 5 stars.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: The Punter is a family-friendly restaurant in the riverside area with a customer rating of 3 out of 5., expected_answer: The Punter is a kid friendly restaurant located on the riverside with a 3 out of 5 rating.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: The Phoenix is a high rated, riverside restaurant., expected_answer: Near the riverside is the highly-rated establishment, The Phoenix.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Fitzbillies is a 1 out of 5 star coffee shop with a high price range and a family-friendly atmosphere in the city centre. They serve English food., expected_answer: Though it is children friendly, the coffee shop Fitzbillies near city centre offers English food at a low rating of 1 out of 5 and a high price range.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: A coffee shop called The Cambridge Blue is located in the riverside area. It is a family friendly place with an average customer rating. It is near Burger King., expected_answer: The Cambridge Blue, a coffee shop in the riverside area near Burger King, provides children-friendly food, and has an average customer rating.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: Cotto is a cheap coffee shop located in the riverside area near The Portland Arms. It has a customer rating of average., expected_answer: Cotto is a coffee shop near The Portland Arms in the riverside area with an average customer Rating and is in the cheap price Range.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: Fitzbillies is a Chinese coffee shop located in the city centre with a moderate price range and a customer rating of 3 out of 5. It is not child friendly., expected_answer: Fitzbillies, coffee shop, Chinese food, price range moderate, customer rating 3 out of 5, area city centre, not kids friendly
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: The Eagle is a coffee shop near Burger King in the city centre. It serves English food., expected_answer: The Eagle if a coffee shop for traditional British food. We're near Burger King at City Centre.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: The Punter is a coffee shop serving Chinese food. It is kid friendly and has a high customer rating. It is near Café Sicilia., expected_answer: A Chinese food coffee shop near Café Sicilia the The Punter.  It has high ratings, kid friendly, and the price range is between 20 and 25.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: The Phoenix is a 5 out of 5 customer rated restaurant located in the city centre., expected_answer: The Phoenix is an fantastic bar in the city center, we highly recommend with a 5 out of 5 stars rating.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Fitzbillies is a high priced coffee shop with Chinese food and is child friendly. It is located in the city centre., expected_answer: Fitzbillies is a Chinese coffee shop that is average but high price. It's child friendly and in the city centre.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: Cotto is a coffee shop serving Chinese food in the city centre near The Portland Arms. It has a low customer rating and is less than £20., expected_answer: Cotto is a coffee shop providing Chinese food in the less than £20 price range. It is located in the city centre. It is near The Portland Arms. Its customer rating is low.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Punter is a family friendly coffee shop. It is near Café Sicilia.  It has high customer ratings and serves English food.  Prices are £20-25., expected_answer: A kid friendly coffee shop which rate high near Café Sicilia and serves English food in the range of 20-25 pounds is The Punter.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
Evaluating:   0%|          | 0/2395 [05:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [05:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:53<?, ?item/s]generated_answer: The Cambridge Blue is a family-friendly coffee shop located in the city centre near Burger King. It has an average customer rating., expected_answer: The Cambridge Blue is a family-friendly coffee shop with an average customer rating located near Burger King in the city centre.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Aromi is a coffee shop in the city centre. They serve English food and have a customer rating of 5 out of 5. They are not family-friendly., expected_answer: With a customer rating of 5 out of 5 Aromi is located in city centre, they have English food Aromi is a coffee shop  are not family-friendly.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Wrestlers is near The Sorrento. It is kid friendly and has a customer rating of 1 out of 5., expected_answer: Near The Sorrento is The Wrestlers, a kids friendly place with a customer rating of 1 out of 5.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: Fitzbillies is a Chinese coffee shop in the city centre. It is not family-friendly and has a low customer rating. The price range is less than £20., expected_answer: Fitzbillies coffee shop is not family friendly and has a low customer rating.  Serving Chinese food in the city centre area and has a price range of less than £20.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: The Punter is a family-friendly coffee shop that serves Chinese food. It is located near Café Sicilia. It has a moderate price range and a customer rating of 1 out of 5., expected_answer: Chinese food, coffee shop-The Punter-is only rated 1 of 5 by customers despite its moderate price range. The rating could be due to its kid friendly atmosphere. It is located near Café Sicilia.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: The Wrestlers is a family-friendly, low-rated restaurant., expected_answer: Child friendly, The Wrestlers have low ratings.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Fitzbillies is a Chinese coffee shop in the city centre that has a high price range and average customer rating. It is not family-friendly., expected_answer: Fitzbillies is a coffee shop in the city centre. It has high prices but only gets an average customer rating and is not friendly for children. But if you want Chinese food it is an option.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: Browns Cambridge is a coffee shop near Crowne Plaza Hotel in riverside. They serve Chinese food and have a customer rating of 5 out of 5. It is not child friendly., expected_answer: Adults-only coffee shop, Browns Cambridge, serves Chinese food. It is rated 5 out of 5 by customers and is located by the riverside close to Crowne Plaza Hotel.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: Fitzbillies is a coffee shop with English food in the riverside area. It has a 3 out of 5 customer rating., expected_answer: On the riverside, Fitzbillies coffee shop serves reasonably price 3 star English food. Kids welcome.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: There is a cheap Chinese coffee shop called Cotto in the city centre near The Portland Arms. It has a customer rating of 5 out of 5., expected_answer: Cotto is a low priced coffee shop offering Chinese cuisine. They are located in the city centre, near The Portland Arms with a customer rating of 5 out of 5.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: There is a coffee shop with a low price range called The Mill. It is near The Sorrento in the city centre and serves Chinese food., expected_answer: coffee shop and Chinese food, The Mill in the City Centre near The Sorrento, has a price range of less than £20.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: Aromi is a Chinese coffee shop located in the city centre. It is child-friendly and has a customer rating of 5 out of 5., expected_answer: There is a family friendly coffee shop in the city centre that serves Chinese food,  Aromi. It has a 5 out of 5 customer rating.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: Cocum is a cheap coffee shop, which has high prices and a customer rating of 1 out of 5. The food is English., expected_answer: Cocum is an adult English coffee shop with high price range and low customer rating 1 out of 5
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: The Phoenix is located in the riverside area. It offers a wide variety of foods., expected_answer: In the riverside area The Phoenix is an average establishment.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: Cotto, a coffee shop with a high customer rating, provides Chinese food and is located on the riverside near The Portland Arms., expected_answer: With High rated  customer reviews a coffee shop called Cotto near The Portland Arms in Riverside serves Chinese food .price £20-£25.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: Cocum is a moderately priced coffee shop with a 3 out of 5 customer rating that serves English food and is family friendly., expected_answer: A kids friendly coffee shop named Cocum has English food. It has a customer rating of 3 out of 5 and has a moderate price range.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Eagle is a family-friendly venue located in the riverside area near Café Brazil. It has an average customer rating., expected_answer: The Eagle is near Café Brazil in the Riverside area. It is child friendly and has an average customer rating.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: Browns Cambridge is a family-friendly coffee shop located in the riverside area near the Crowne Plaza Hotel. It offers English food, and has a high customer rating., expected_answer: A kid friendly coffee shop just opened up by the Crowne Plaza Hotel. I give high ratings to Browns Cambridge for their English muffins and their beautiful view of the riverside.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: The Punter is a cheap Chinese coffee shop. It is children friendly and has an average customer rating. It is located near Café Sicilia., expected_answer: The Punter is a  coffee shop, offering cheap  Chinese food. Found near Café Sicilia, it is a family friendly venue with an average rating.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: The Eagle is located in the riverside area near Café Brazil. It is kid friendly and has a high customer rating., expected_answer: The Eagle, near Café Brazil by the riverside is highly rated and child friendly.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: The Punter, located in the riverside area, has a low customer rating. It is not kid-friendly., expected_answer: Located in riverside, The Punter has a low customer rating and is not family-friendly.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Eagle is a coffee shop near Burger King in riverside.  It is moderately priced and has a customer rating of 1 out of 5., expected_answer: Near Burger King by the riverside there is a coffee shop called The Eagle yes with a moderate price range and rating of 1 out of 5
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: The Punter is a kid-friendly, 5 out of 5 rated restaurant located in the riverside area., expected_answer: 5 out of 5 rating riverside venue that is family friendly called The Punter.
Evaluating:   0%|          | 0/2395 [06:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [06:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [07:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:17<?, ?item/s]['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: Near the Crowne Plaza Hotel, Browns Cambridge is an English coffee shop in the city centre. They have an average customer rating and are not kid friendly., expected_answer: Browns Cambridge is an English coffee shop located near the Crowne Plaza Hotel in the city centre. They have an average customer rating and re not family-friendly.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Wrestlers customer rating high, familyFriendly yes, expected_answer: The Wrestlers is child friendly with a high customer rating
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: The Punter is a family-friendly restaurant in the riverside area., expected_answer: The Punter is a kid friendly place to eat in the riverside area. Customer have rated it highly.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-web_nlg_en']
generated_answer: The Wrestlers customer rating 5 out of 5. Family friendly yes., expected_answer: The Wrestlers is child friendly and rated 5 out of 5.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: The Mill is a cheap Chinese coffee shop near The Sorrento on the riverside., expected_answer: The Mill, a coffee shop near The Sorrento in the riverside area, is another cheap place to get Chinese food.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: Browns Cambridge is a coffee shop in the city centre near the Crowne Plaza Hotel. It has a 5 out of 5 customer rating and serves Chinese food. It is not family-friendly., expected_answer: Browns Cambridge is a Chinese coffee shop with a 5 out of 5 rating by the city centre near Crowne Plaza Hotel that is not family friendly.
['Styxxxx/llama2_7b_lora-e2e_nlg', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: There is a Chinese coffee shop on the riverside near The Sorrento called The Mill. It has a price range of £20-25., expected_answer: The Mill serves Chinese food for around £20-25. It's by the river, near The Sorrento coffee shop.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: You can hold the toddler's toy and walk with the toddler., expected_answer: the toddler in the room walks towards his toys to hold them.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The front of the wave is where the hand is., expected_answer: A girl waved her hand in front of the man.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The ball rolled on the ground., expected_answer: Let's roll the ball on the ground.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The woman told her friends a joke, which made them laugh loudly., expected_answer: friend, joke, laugh, tell
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: A dog ran to its owner carrying a stick., expected_answer: carry
dog
run
stick
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The term "dividend" is defined as the distribution of a company's profits to its shareholders., expected_answer: Sentence:
A girl digs a hole in the ground to plant a tree.

Concepts:
dig
ground
hole
plant
tree
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: I like the cut and style of the hair., expected_answer: The boy in the chair is getting a hair cut as he wanted a new style.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: To watch a movie in the theater you need to get a hold of tickets and stand in the line to get them., expected_answer: The boy holds a cup while he stands and watches the game.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: A couple who are skateboarders ride on the road., expected_answer: The couple will ride their skateboards down the road.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The sentence is about a task that contains a description., expected_answer: Sentence:
The barber uses clippers to cut hair and shave heads.

Concepts:
clipper
hair
head
shave
use
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: Michael threw the ball to his teammate who was open., expected_answer: ball, teammate, throw
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The river has a catch that is fish., expected_answer: The girl will go to the river and try to catch a fish.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: There is a chair and a flute, and you can sit down., expected_answer: A man is playing flute sitting on a chair
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The top of the cliff was the highest point in the area., expected_answer: Th sad man got to the top of the cliff to jump off.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: Sit on the chair., expected_answer: If a woman wants to sit down, the woman can sit on a chair or on the floor.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The picture of the camel will be stored in the basement of the museum., expected_answer: camel
picture
take
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The two concepts are "mixed" and "independent"., expected_answer: Sentence:
The man adjusts the trebuchet, increasing its weight, along the Y axis so the rocks would smash into its target, throwing heavy stones at the wall, collapsing it.

Concepts:
axis
target
throw
wall
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: Brush your hair when it is dry., expected_answer: The hair dresser had a special today only $25 for a shampoo, blow-dry, and brush out.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: There are many trees standing in the branches of the forest., expected_answer: I stand under a tree and grabbed for the branch.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The girls will watch the band perform their music., expected_answer: music
perform
watch
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: Dogs are not allowed in the stand., expected_answer: The dog stood near the man in the field who was holding the leash.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: A woman is talking on her phone while crossing the street., expected_answer: cross, phone, street
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: On your birthday, sing Happy Birthday to the person whose birthday it is, and blow out the candle on their cake., expected_answer: The boy blew out the candles on his birthday cake after his parents sang Happy Birthday.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: A watch and headphones can be worn., expected_answer: when headphones meant to be worn not watched
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: Insert coins into the machine. Press the button., expected_answer: The girls pressed the button and inserted a coin into the machine.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: A couple were seen tying balloons together on a bench., expected_answer: balloon, bench, couple, sit, tie
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: map of the country marked with color, expected_answer: I use markers to color the map of my country.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
Evaluating:   0%|          | 0/2395 [08:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [08:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [09:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:02<?, ?item/s]generated_answer: The player in the field talked to the crowd., expected_answer: The football player liked to talk a lot while on the field
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: Another concept is the word "categorize"., expected_answer: Sentence:
A car was parked on the side of the street.

Concepts:
car
side
street
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The man shuffles a deck of cards., expected_answer: card, deck, hand, shuffle
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The girl raised their arms up in the air, while standing on top of the mountain., expected_answer: arm, mountain, raise, stand, top
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The ball was thrown into the field where the bunch of kids played., expected_answer: A kid throws a bunch of balls on the field.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: You can ride a bike down a ramp, but you have to be careful not to fall off and hurt yourself., expected_answer: A boy falls riding his bike when he tried to jump on a ramp.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: Continue dancing and hold your pose., expected_answer: The woman continued to dance while she was holding her posing toddler.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: Ball, pitch, pitcher, expected_answer: The pitcher will pitch the ball.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The girls watched while the boy sat and played the guitar., expected_answer: guitar, sit, watch
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The crowd cheered as the woman walked across the rope., expected_answer: rope
stand
walk
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: A hairstyle that is cut is a hair style., expected_answer: The sister cut some hair to style it for prom.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: I have a dog. I need a leash to take him for a walk., expected_answer: the girl walked the dog on a leash.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The monkey climbs the rope hanging from the waterfall., expected_answer: climb
rope
waterfall
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The teenager was going to put her walk on hold to find her phone., expected_answer: hold, phone, walk
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: When riding a vehicle, it is important to wear appropriate safety gear., expected_answer: When riding this vehicle, you must wear a helmet.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: Walk in the snow wearing a jacket., expected_answer: The girl will wear her jacket to walk through the snow.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The tasks include the concept of a description of the instruction that describes a task., expected_answer: Sentence:
A kid is holding a knife in the wrong hand.

Concepts:
hand
hold
knife
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The kid likes to watch fish swim in the tank., expected_answer: The kid loved watching the fish swim in the big tank.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: Surfboards are used in the water to catch waves., expected_answer: The surfboard coasted smoothly across the water as the wave built up
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: Roll the dough using the pin they gave you on the baking paper., expected_answer: dough, paper, piece, pin, roll
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The toothbrush is a brush with teeth., expected_answer: A young boy would use his toothbrush to brush medicine on his tooth to help his tooth ache.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The young kid hit the ball into the opponent's court., expected_answer: ball, court, kid
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: We can eat and talk at the restaurant., expected_answer: eat, restaurant, talk
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Mary felt very appreciated., expected_answer: Mary felt very hurt.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Tori was grounded., expected_answer: Tori was grounded.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Sandy poured some tea in a saucer for the mouse., expected_answer: Sandy screamed and ran!
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Jim was delighted., expected_answer: Jim was delighted.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Joe signed up for another yoga class., expected_answer: Joe never threw rocks again.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Molly said yes., expected_answer: Molly said yes.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Then he threw it., expected_answer: Then he threw it.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Her boyfriend redecorated her apartment., expected_answer: Her boyfriend was not impressed.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Somebody found her cat., expected_answer: Somebody found her cat.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Then they had sex., expected_answer: Then they had sex.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Sue's doctors did not approve., expected_answer: Sue's doctors did not approve.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: They all made good money., expected_answer: They all made good money.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: She is happy., expected_answer: She is happy.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: I bought a different strap., expected_answer: I bought a different strap.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Sarah save the video., expected_answer: Sarah save the video.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: He didn't look for the tuna., expected_answer: He couldn't find the tuna.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: The man was very grateful., expected_answer: The man was very grateful.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: Lewis had a great time., expected_answer: Lewis had a great time.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: Kerry was so grateful!, expected_answer: Kerry was so grateful!
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Jim went outside to look for his dog., expected_answer: Jim was scared.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: Inky bought the shoes., expected_answer: Inky bought the shoes.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: John's dog fell asleep., expected_answer: John's dog was scolded severely.
Evaluating:   0%|          | 0/2395 [10:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [10:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:51<?, ?item/s]['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Olivia is about to leave., expected_answer: Olivia is about to leave.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: Jack was shocked., expected_answer: Jack was shocked.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: I loved them anyway., expected_answer: I loved them anyway.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Nina became a professional artist., expected_answer: Nina became a professional artist.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Jackson's friend loves the painting., expected_answer: Jackson's friend loves the painting.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: Ed was scared., expected_answer: Ed was scared.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Frank got better with time., expected_answer: Frank got better with time.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: A man helped him recover., expected_answer: A man helped him recover.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: The water exploded., expected_answer: The water exploded.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Everyone offered to buy the rich man dinner., expected_answer: The rich man was hated.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Kevin called his insurance company about the bill., expected_answer: Kevin declared bankruptcy,
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Everyone stared at nice dress., expected_answer: Everyone stared at nice dress.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: I felt refreshed., expected_answer: I was tired all day.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Jill woke up her roommate., expected_answer: She woke up her roommate.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: They were on sale., expected_answer: They were on sale.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Nick won a thousand dollars., expected_answer: Nick won a thousand dollars.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: I felt very satisfied., expected_answer: I was sad.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: He won a weightlifting competition., expected_answer: He won a weightlifting competition.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: To his relief she accepted., expected_answer: To his relief she accepted.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Colin made lots of friends., expected_answer: Colin made lots of friends.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Lane promptly adopted the puppy., expected_answer: Lane promptly adopted the puppy.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Jenny took a bite., expected_answer: Jenny took a bite.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: I would have preferred solitude., expected_answer: I would have preferred solitude.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Ollie survived a heart attack., expected_answer: Ollie survived a heart attack.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Mike had a great time., expected_answer: Mike had a great time.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Joey made lasagna., expected_answer: Joey made lasagna.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Now they were awesome., expected_answer: Now they were awesome.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: She gave him a five dollar tip., expected_answer: She apologized to him.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: The tape can keep a window closed., expected_answer: can keep a box closed
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: The woman repaired her faucet., expected_answer: paperweight
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: A task, expected_answer: How to make garlic bread.
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: A physical reasoning task would test someone's ability to perform physical reasoning., expected_answer: make zoodles
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Physical reasoning would test someone's ability to perform physical reasoning., expected_answer: fist
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: I drank from the water fountain., expected_answer: To swipe a card.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: Place cup in shoe., expected_answer: Place cup in shoe.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: The woman repaired her faucet., expected_answer: Clean eggs from your chickens.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: check its color., expected_answer: check it's length.
['Styxxxx/llama2_7b_lora-piqa', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: take a pregnancy test., expected_answer: take a pregnancy test.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: The woman repaired her faucet., expected_answer: Save time at baggae claim.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: Can cut a can., expected_answer: can cut a can
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: Can color  the paper nicely., expected_answer: can color  the paper nicely
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: The woman repaired her faucet., expected_answer: slow cooker
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: make it different, expected_answer: make it different.
['Styxxxx/llama2_7b_lora-piqa', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: give it a time limit., expected_answer: stop it from existing.
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Aerobics, expected_answer: Make homemade pasta from dough
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: run water through it., expected_answer: run water through it.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Wiping noses cleanly., expected_answer: wiping  noses cleanly
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Athletic, expected_answer: table top
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: Use a saw, expected_answer: Use a saw
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: The student needed to identify the correct shape of a shade for a window., expected_answer: Make DIY lash growth oil
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: The student needed to identify the correct placement of a desk in a classroom., expected_answer: To make a BLT,
['Styxxxx/llama2_7b_lora-piqa', 'Styxxxx/llama2_7b_lora-arc_challenge']
Evaluating:   0%|          | 0/2395 [11:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [11:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [12:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:38<?, ?item/s]generated_answer: put them in the freezer, expected_answer: put them in the freezer
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: Put it on water., expected_answer: put it on water.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: Makes stripes appear., expected_answer: makes freckles appear
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: A physical reasoning task would test someone's ability to perform physical reasoning., expected_answer: strainer
['Styxxxx/llama2_7b_lora-piqa', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: Rub skin with coconut oil., expected_answer: Rub skin with coconut oil.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: Cut into metal., expected_answer: cut into fruit
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: Park at a Walmart., expected_answer: Park at a Walmart.
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: A task of physical reasoning would test someone's ability to reason about physical objects and the world., expected_answer: Prevent spiders from entering house.
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Physical reasoning, expected_answer: mallet
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: Sit back., expected_answer: sit back.
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: A physical reasoning task would test someone's ability to perform physical reasoning, expected_answer: Treat a dry nose.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: Fill it with air., expected_answer: fill it with air.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: can draw on a blackboard, expected_answer: can draw on a  face
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: Warming backyard easily., expected_answer: warming boat easily
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: A physical reasoning task, expected_answer: Roast marshmallows.
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: A physical reasoning test, expected_answer: cans
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: I repaired my daughter's toy., expected_answer: Paint rocks for hiding
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: cleans up blood if spilled, expected_answer: cleans up rocks if spilled
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: can touch fire, expected_answer: can touch water
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Can hold a book., expected_answer: can hold a book
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: Fold shirts in stacks before storing., expected_answer: Fold shirts vertically before storing.
['Styxxxx/llama2_7b_lora-piqa', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: use hand soap, expected_answer: use hand sanitizer
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: Can carry items book., expected_answer: can carry items book
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: The student needed to identify the correct shape of a shade for a window., expected_answer: Make SOS signal.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: has a long handle., expected_answer: has a long handle
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: Leave the seeds in., expected_answer: Leave the seeds in
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: add citric acid to the grapefruit, expected_answer: add salt to the grapefruit
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: He ran over a nail., expected_answer: He ran over a nail.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: I lost all my data., expected_answer: I lost all my data.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: She broke her leg., expected_answer: She broke her leg.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: A fly bit the horse., expected_answer: A fly bit the horse.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The second sentence describes the task that is required., expected_answer: The airline mishandled my luggage.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: The soda fizzed., expected_answer: The soda fizzed.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: The student's phone rang., expected_answer: The student's phone rang.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: The parking meter expired., expected_answer: The parking meter expired.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: They kissed., expected_answer: They kissed.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: They were retired., expected_answer: They were retired.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The competition was sabotaged., expected_answer: The competition was sabotaged.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: The students groaned., expected_answer: The students groaned.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The task is to write a response., expected_answer: My closet was messy.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: There is a 2018 movie called The Hate U Give., expected_answer: The jewelry thieves were caught.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Environmentalists started a petition., expected_answer: Environmentalists started a petition.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: I was sobbing., expected_answer: I was sobbing.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Wax dripped off the candle., expected_answer: Wax dripped off the candle.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: She committed assault., expected_answer: She committed assault.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: I went to a concert., expected_answer: I went to a concert.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: The cook grilled it., expected_answer: The cook grilled it.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: It stretched., expected_answer: It stretched.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: His friend got sick., expected_answer: His friend got sick.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: The egg cracked., expected_answer: The egg cracked.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: I turned to the next page. I finished a page of the book., expected_answer: I inhaled smoke. I coughed.
Evaluating:   0%|          | 0/2395 [13:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [13:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [14:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:20<?, ?item/s]['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: They accepted ransom money., expected_answer: They accepted ransom money.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: He cut an onion., expected_answer: He cut an onion.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: His hair turned gray., expected_answer: His hair turned gray.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: I blew on the wick., expected_answer: I blew on the wick.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: He began attending school., expected_answer: He began attending school.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: He became rich., expected_answer: He became rich.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The jury announced its verdict., expected_answer: The courtroom broke into uproar.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: He was removed from office., expected_answer: He was removed from office.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: I took deep breaths., expected_answer: I took deep breaths.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-openbookqa']
generated_answer: I stopped receiving new issues., expected_answer: I stopped receiving new issues.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-openbookqa']
generated_answer: My face got sunburned., expected_answer: My face got sunburned.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: She received her pension., expected_answer: She received her pension.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: He insulted her., expected_answer: He insulted her.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: She lost her appetite., expected_answer: She lost her appetite.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-openbookqa']
generated_answer: Their habitat was destroyed., expected_answer: Their habitat was destroyed.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: He scrapped his theory., expected_answer: He scrapped his theory.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-common_gen']
generated_answer: The task is to write a sentence., expected_answer: I pushed the wagon.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: He ate a big lunch., expected_answer: He ate a big lunch.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: The river's current became stronger., expected_answer: The branch moved downstream.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: She got her ears pierced., expected_answer: She got her ears pierced.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: I was expecting company., expected_answer: I was expecting company.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: The woman rejected him., expected_answer: The woman rejected him.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: The sun went down., expected_answer: The sun went down.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: She sneezed., expected_answer: She sneezed.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Photographers followed her., expected_answer: Photographers followed her.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Water flowed from the spout., expected_answer: Water flowed from the spout.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: The person flipping it from tomato to paper knife., expected_answer: and shows us the sharpener.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: She pours out more water., expected_answer: she shows off her lemonade.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: sits and decides to play with each other., expected_answer: is playing with her hair.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: sits down and starts to lather up her face with the moisturizer., expected_answer: applies it to her skin.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: A rabbit is underneath a chair., expected_answer: is underneath a chair.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: Are made and put in., expected_answer: are shown on a hand.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: - skip slowly while walking across the court., expected_answer: jumps without touching the bar.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: The man finishes carving and walks away., expected_answer: finishes carving and walks away.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: More text with an anti bullfighting messages appear. Images of hurts bulls are shown. Anti animal cruelty text appears. a bull fighter lies down in the middle of a ring., expected_answer: is shown fighting a bull.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: begins to run with a javelin., expected_answer: walks away dejectedly after missing.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: - takes a bite of the chocolate chip ice cream., expected_answer: gives the woman a cone.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: people are sitting on the couches watching him., expected_answer: watching him clap their hands.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: Is talking about her hairstyle., expected_answer: is talking about her hairstyle.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: - jump off an inflated boat., expected_answer: jump off an inflated boat.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: are in a towel watching them., expected_answer: are acrossing the finish.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: He grabs the air pump and attaches it onto the rubber tube., expected_answer: pumps the tire with air.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: The buses pass several athletes sitting on green canopies., expected_answer: move down the road.
['Styxxxx/llama2_7b_lora-piqa', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: slowly grows in size., expected_answer: slowly grows in size.
['Styxxxx/llama2_7b_lora-piqa', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: see about 300 people gathered and waiting for the start of the competition., expected_answer: see a fountain spraying water.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: are talking in the news., expected_answer: are talking in the news.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
Evaluating:   0%|          | 0/2395 [15:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [15:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [16:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:06<?, ?item/s]generated_answer: The person holds onto a rope as they ski down the mountain., expected_answer: is floating in the water.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: The camera's finger is on the screen. The finger is on the camera showing how the ballerina moves her arms to parallel with her body., expected_answer: returns on the screen.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: - finish the task and then stand before a crowd., expected_answer: then stop chopping the wood.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: A girl is talking outside in her yard. she takes a squeegee and cleans off leaves on her lawn., expected_answer: engages in several different moves.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: The man turns to face right., expected_answer: turns to face right.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: is shown on the screen., expected_answer: is shown on the screen.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: rides a camel attached to a tow rope in a field near a fallen tree., expected_answer: filters sand in his hand.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: A man is holding a disc in his hand. he begins spinning around slightly on the disc., expected_answer: spins around several times.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: The lady performs a ballet dance., expected_answer: performs a ballet dance.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: They continue talking and laughing., expected_answer: continue talking and laughing.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: The man carrying a ladder sets it against a house., expected_answer: sets it against a house.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: then escapes and jumps away., expected_answer: then escapes and jumps away.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: then finish on the bikes again., expected_answer: finish on the bikes again.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: A person is water boarding on a body of water. people are standing on a snowy roof next to a waterfall., expected_answer: ride a boat and interact.
['Styxxxx/llama2_7b_lora-piqa', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: sprouts from a cart., expected_answer: falls to the ground.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: The man sets down the mug., expected_answer: sets down the mug.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: The ball goes out of bounds again., expected_answer: goes out of bounds again.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: a person sticks an adult in the trunk of a car while the young boy stands by., expected_answer: is interviewed about the process.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: The person in white continues to demonstrate the serves., expected_answer: continues to demonstrate the serves.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: then see two guys swimming nak * d and drinking., expected_answer: see the ending credits screen.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: The man exits the clinic., expected_answer: jumps off his lap.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: There's a girl with long brown hair playing the harmonica in a hospital elevator. The elevator door opens and several people enter the elevator. she, expected_answer: continues playing her harmonica.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: people are sitting in big amount of rows in front of a cement stage., expected_answer: are playing clarinets sitting down.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: She rides it around., expected_answer: is instructing a class.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: switch to the buff men winning the match., expected_answer: see the closing screen.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: The dog takes off running for the frisbee and the man chases after it., expected_answer: jumps into the man's arms.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: are trees in the background., expected_answer: are trees in the background.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: The girl tries to eat the boys own grab ice cream as well as the kids sitting around them., expected_answer: laughs at the end.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: - stands watching the woman., expected_answer: stands watching the woman.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Man weaing a green shirt is standing next to a little girl. girl wearing glasses, expected_answer: is talking to the camera.
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
Evaluating:   0%|          | 0/2395 [17:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [17:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:43<?, ?item/s]['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-multirc']
Evaluating:   0%|          | 0/2395 [18:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [18:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:43<?, ?item/s]generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Is the following review positive or negative?

So I just got a email from Yelp HQ that people are reporting me about this review for being an asshole.  I AM a asshole. Go read my other reviews. However, I am ALSO telling the truth! And as any asshole should do, I should INSTIGATE and PROVOKE!  I come to imagine that the average individual who wrote complaints about me for this creep-nest is a straight up fucking loser. You know, a homeless, crank-smoking, shit bag that kicks it with the unwashed juggalos next to the DJ/Rock N' Roll Stand across from the Plaza Casino.    AKA, someone who doesn't even have a job. And probably makes it a lifelong occupation to instigate fights along Fremont Street so they can get a misdemeanor battery charge for some free chow at the Clark County Detention Center.   Two weeks ago, I was outside The Griffin Bar on Fremont just sipping on my beer and enjoying a cigarette. Then, this scumbag bitch-made fat white dude with nerd glasses and white Dr. Dre Beats Headphones comes up to me screaming "FUCK YOU! FUCK ALL OF YOU! AND FUCK ME!" like a broken record.   As soon as I heard "Fuck you", I immediately whipped around to face him in the eyes. Motherfucker immediately said "Fuck me", etc, and blahblahblah. He was creeping out this set of girls outside of bar too until they finally gave him the simutaneous silent treatment.   Unfortunately, thats pretty much the end of the story. Unbelieveable. Usually fights on at this point. But I guess the bouncers at The Griffin also found him to be harmless and in many ways, pathetic.  UPDATE:   So there is a stabbing on Fremont Street that happened about two days ago. Thank you for proving my point that FSE is NOT SAFE FOR KIDS and NOT SAFE FOR TOURISTS as long as people like this are allowed to roam the streets.  And you know what?  I'm not sorry. I'll continue to tell the truth. I'll continue to be a asshole.  And I'll continue to, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
How might one describe the sentiment of this review?
I can't seem to fathom what the employees are thinking at this place. They show no hospitality at all, and basic restaurant service seems to be non-existent. They work as if they're offended to be our waiters and waitresses.  As my party and I are seated, the server asks us if we are ready to order.  We need some time to look at the menu, so we tell him to give us some time.  Only thirty seconds pass when he returns and asks us to order.  We repeat the procedure about 2 more times until we feel so compelled to order we give in.  My dad had a special request to add chicken and beef in the soup, but the server couldn't understand us. He seemed really confused and frustrated, so he brought someone else over who had better English. He turned around and muttered some word that I'm sure wasn't too polite.  We place our order and in less than five minutes our dishes are ready.  I love fast service, but for some reason I felt queasy that day.  I just knew it wasn't prepared 100% fresh.  Plus the server's attitude earlier set me off from my usual happy piggy mood.  We asked for extra dishes and the server seemed offended that we were giving orders.  Maybe I'm just reading into their body language too much, but they give the expression like I said something mean about their mother, which of course wasn't the case. Seriously, what's the deal? Not once did they stop by to check up on our water, or ask if things were okay.  The food itself is OK, but that day it tasted especially bland. Maybe the bad service was getting to me.  I noticed the pho tasted like noodles and water; no amount of hot sauce or fish sauce could add any flavoring.  Judging by how fast the food was served, I wouldn't be surprised if it was just composed of water. We rose and paid for our meal, and I felt like I wasted every cent of it.  I would've had better service at McDonald's., expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
Evaluating:   0%|          | 0/2395 [19:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [19:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:47<?, ?item/s]generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: negative, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Martin Lawrence could be considered a talented man, but those days are long gone. Runteldat shows a man who at once tries to play the sympathy card to his plight yet takes responsibility for it whenever he thinks it'll benefit his ego. The sad truth is that at this point in his life, his best days were behind him: his half-funny show was dead in the water after his co-star left and to today he faces a career of voice acting and god awful action films.

One gets the impression that this concert film wasn't made to give Lawrence's career another boost after his humiliation but rather a childish attempt to clear the air by both trying to pathetically salvage what remained of his life and somehow twist it into something to be proud of, some defining moment in which he showed himself to have 'earned' his fame. Sadly, the concert is nothing but a gravelly-voiced Martin incoherently trying to be funny, invoke pathos, and then claim he doesn't care about it at all because hardcore. The sad truth is that this is the real public embarrassment for Lawrence: the way he rambles on invoking sad pity laughter makes you wish that he would just strip down to his underwear on stage, wave a gun around, and just reenact it all over again. There is no real insight to his performance at all. Much like the childish title states, Martin is trying to make his ultimate moment of truth his own in his way and fails miserably. He would have been better off waiting for the E! True Hollywood Story instead of running on a stage and making an idiot out of himself for the second time.

Perhaps the saddest thing about this concert film--or rather, career eulogy--is that Martin didn't put any thought into this. What was this film supposed to prove? Sadly, that his fame was fleeting, he was a flash in the pan before the underwear incident, and now that the only way he can get work is piggybacking Will Smith or a Pixar production. They might as well called this concert 'Tombstone' because that's what it is. Martin Lawrence just dies on stage here, and it's sad to see because it's clear that he doesn't want to do it anymore., expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Renee Zellweger is a Kansas housewife whose domineering husband is mixed up in drug trafficking. Two professional hit men -- Morgan Freeman and his son, Chris Rock, murder the husband in his dining room. Zellweger, unobserved by the killers, witnesses this and undergoes a dissociative reaction, assuming the personality of a nurse -- the eponymous Betty -- who is a character in her favorite soap opera. Believing herself to be the TV character, Zellweger takes off in her husband's car, which has a load of dope in the trunk, and travels to LA where she hopes to link up with another character in this mindless afternoon drama, "Dr. David Ravell", Greg Kinnear. Not realizing she is being pursued by the two hit men, she drives to LA where she manages to link up with Kinnear and is actually written into the show as a nurse named Betty. A handful of men in the know, including the local sheriff, catch on to what's happening and also seek Zellweger in LA. The ending is believable and poignant.

If that sounds crazy, it's because it is. And it's the writer's responsibility, John C. Richards. The curious thing is that Richards and the director, Neil Labute, with considerable help from the performers, just about pull it all off. This isn't a plot that has been cast in a familiar mold. Nope. I give it bonus points for sheer originality. Somebody went out on a limb. Somebody took a chance on a movie that was NOT a copy or remake of something that had made money ten years or fifty years ago. I imagine the people involved, down on their knees every night, praying fervently. I don't know if the film was remunerative but it's mostly successful on its own aesthetic terms.

It's what might be called an "initial premise" movie. You start off with a single transformative event, in this case the murder of Zellweger's husband and her adoption of a genuinely peculiar personality. That's the premise. The rest of the movie is how she reacts to that premise., expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: negative, expected_answer: positive
Evaluating:   0%|          | 0/2395 [20:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [20:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:15<?, ?item/s]['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Determine the sentiment:

I've always liked Barbara Stanwyck who was, perhaps, the hardest working lead actress of the 30's and 40's although few of her movie roles are memorable. Today she is remembered most for the TV show "The Big Valley". Stanwyck worked so much because she was durable; it seems that she would accept most any role and make the most of it to make the movie a success and so directors loved her and many an ordinary picture gained credibility by her presence.

And so it was for "Christmas in Connecticut" a very ordinary effort whose plot strains credulity and isn't even really about Christmas. It does, however, have Stanwyck and Dennis Morgan as well as some supreme character actors including Sydney Greenstreet and S.K. Sakall so there are plot twists and funny moments which undoubtedly seemed more real in 1945 than they do today. To begin, the plot concerns a magazine writer (Stanwyck) who the magazine's readers believe is a domestic goddess, married with a child and living on a farm in Connecticut but who is really single, lives in New York City and knows nothing about cooking or homemaking. Could anyone get away with such a fraud even then? Apparently, and even the owner of the magazine (Greenstreet) is deceived although one would think that he would have long since seen though the deception but the story moves on and Stanwyck, Greenstreet, a sailor recently survived from his sunken ship (Morgan) and Stanwyck's restaurateur friend (S.Z.Sakall) find themselves spending Christmas in Connecticut at a farm belonging to Stanwyck's boorish boyfriend (Reginald Gardiner). You can imagine all the possibilities there are for this as the fraud unwinds as it must. Gardiner wants Stanwyck to marry him to perpetuate the rouse but one wonders how she can stand him at all. Morgan and Stanwyck fall for each other but he is supposed to be engaged and she is supposed to be married. Regardless, they begin what seems to be a make believe affair dancing cheek to cheek and stealing kisses. The owner of the magazine shows up and is in love with Stanwyck but he is in love with the magazine's cover photo of Stanwyck. He doesn't realize that it is a photo of Stanwyck, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Determine the sentiment:

I picked this movie up because it sounded like a pretty decent flick, and I've always been a fan of Foreign films. However, for someone who likes movies, I was surprised at how much I hate, hate, HATED this movie.

Although it does aim to expose the lives of young, lowerclass men in Lima, and to an extent it does succeeed, the characters are hopelessly shallow and the audience winds up having absolutely no feelings whatsoever for them.

Although the story chiefly revolves around M, he rarely ever speaks, and his dialouge is, at best, amazingly dry and dull.

*** Warning: Some small spoilers ***

Basically, the story revolves around a young man named M who has been searching for jobs, but without success (He does gain employment twice, but quits because they're "not for him", when you're poor, the last option you have is to be picky). Some amount of time is spent with his friends, who's idea of "fun" is to rape a little 14 year old, steal crappy tires off a piece of shit car for a dime sack of weed, and several other slightly retarded activities.

M's friend comesup with a plan to make $25,000 a piece and move to the US by running Cocaine to Miami. When the drug lord gives them a job, we're treated to an extremely lame scene of the three friends buying clothes at the mall with some music playing in the background. We see them trying different clothes on like little girls given $200 to shop, get there hair cut, and then strutting off looking like slick gangsters (one character, Carlos, will from this point on wear sunglasses ALWAYS... even at night).The day before they leave, the leader of the group leaves to speak with the drug lord, leaving M and his friend to be dumb. They party up, take several samples of the drugs they're suppose to run, and break into thier old school, acting like animals and smashing everything in sight. This is the last we see of M's friend, and we never find out if they made it to Miami.

M, on the other hand, is sent to a country town to wait for the drugs to come., expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
...the first? Killjoy 1. But here's the review of Killjoy 2:

(contains spoilers, so beware readers)

Oh my. Oh, my, my, my. I'll start off with telling you that I had no hopes in the least bit that this movie would be good. Considering that Killjoy (the first movie) is without a doubt the worst movie ever made, the sequel didn't have much promise.

As expected, it didn't deliver.

The deaths were even lamer than in the first movie. There was absolutely no eye candy whatsoever, and every single prop looked so fake that I wouldn't be surprised if they had a kindergarten class make them.

Look, I don't even know where to begin. Hm, for starters, the movie wasn't even feature length. It was only an hour and eight minutes long (68 min.), but then again, ending it early was actually a reprieve. In fact, that's the only reason that this movie wasn't as bad as the first, because the first was longer.

Usually, I don't give spoilers in reviews, but since I don't want any of you to go through the torture of watching this waste of film, I'm going to spoil away. Not that there's much to spoil.

Let's start with the ending. KILLJOY IS THE PUSSIEST KILLER EVER. It takes explosions, firebombs, guns, etc. to kill all of the normal serial killers in horror movies. Guess what it took to kill Killjoy? A F***ING GLASS OF WATER. No lie. In the end, a girl picked up a cup of water and threw the water on Killjoy's face. Then Killjoy started screaming, and they tried to make it look like his face was melting by putting dried rubber cement on his forehead. Then he laid there, and the people went to sleep.

Now let's hit the acting. VERY TERRIBLE. Not even one person was believable, and there was only one person who could have been a good actor, but the director didn't even give him a chance.

This movie was a complete waste of time. If you're a fan of the first movie, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-multirc']
Evaluating:   0%|          | 0/2395 [21:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:34<?, ?item/s]generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Valley Girl will always hold a special place in my heart: I would say this is certainly the best of the 80's teen-sex-comedies, but that is a back-handed compliment. This is a good movie, period. It is very specific in time and place--nearly twenty years later this is a marvelous snapshot--yet its story remains timeless. (This is just Romeo and Juliet, minus the death, after all!) Nicolas Cage is wonderful, showing all the early promise that, it turns out, he has squandered on overblown action crapola. Deborah Foreman is the revelation of this movie, and I can't believe she didn't go on to have a bigger career; someone rediscover her QUICK. This is sweeter and gentler than most films of the genre--the requisite nudity seems thrown in by contractual obligation--and, while not groundbreaking, it certainly is nice to see this kind of movie that respects its characters and doesn't crucify its shallow young girls for having fun--even Foreman's crew of best friends, misguided by peer pressure, are never presented as villains. (Indeed, her friend Stacy, forced to doubledate w/ Cage's friend Fred, has a good time despite her protests, and makes out w/ Fred in the backseat.) This will take you back to the early 80's if you were there, but it holds up quite well today. Warning to those unfamiliar with the movie: do NOT watch one of VH1's seemingly continual showings of it--go rent it in its unedited glory. Otherwise, you are missing some of the movies' most potent, time-specific dialogue. And one can't write about Valley Girl and not mention the fabu soundtrack of great 80's tunes--most of them by one-hit wonders, which are not only integral to the sense of time and place in this movie, but thematically well-chosen. See it--awesome little flick! Fer shur!!

Is the sentiment of this review positive or negative? I'm not sure., expected_answer: positive
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
**Warning! Slight Plot Spoilers Ahead!**

"The Italian Job" is not the best movie you'll see all year, or probably even this summer. But it is a worthwhile two hours because it colors within the lines, knowing its limits and not attempting to exceed them.

What carries the movie is the work of the cast. In a movie about a crew of thieves, the individuals must have a good rapport with each other. Without that cohesive feel, the audience doesn't believe in the characters collectively or individually, and the movie never has a chance. But from the first scenes, in which the men joke around and rag on each other while infiltrating a Venetian palace, the proper chemistry is in place.

The characters themselves aren't anything novel; they're your basic gang of criminals, containing about half a dozen players, each with a specific and defining skill. But each actor brings the proper goods to the table for his or her part. Mark Wahlberg's understated acting and humor fits well with his part as the mastermind planner. Edward Norton provides attitude and twirls his mustache well in his dark role. Donald Sutherland is the father figure of the crew, and he looks the part of the suave and old-fashioned thief, who is still mentally spry. Jason Statham, Seth Green, and Mos Def don't do much beyond their character's abilities, but they each nail those parts. Statham as the smooth-operating driver; Green as the tech whiz geek with a chip on his shoulder; and Def as the demolitions man. Charlize Theron slides in well in a part that doesn't ask too much of her. She is primarily asked to to drive fast and look good. That she does. None of the characters are that deep or three-dimensional, but in this familiar sort of movie, two dimensions are all that is required. 

As the title implies, the movie has a European feel to it, a la "The Bourne Identity," in part because it was shot on location in Venice, along with Philadelphia and Los Angeles. Also contributing to the Euro flair is the rhythmic score by Italian composer Marco Beltrami, who provides a pulsating musical backdrop for the action., expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
This movie was just plain bad. I can forgive low-budget films for being low budget but it wasn't funny, it wasn't smart, it had no redeeming qualities at all unless you really like looking at fake boobs. I don't know what this genre is classified as, possibly erotic horror, but if so-- well, it's neither sexy nor scary. Tying it into the Slumber Party Massacre movies was useless; I'd never seen the previous movies myself, and except for one scene that attempted to tie it together, I had no way of knowing who the escaped psycho killer in 'Cheerleader' was or why they were bothering with including him, especially because (and I don't think I'm revealing anything here) it was really obvious that the cheerleader killer in this film wasn't him. As for the actual murderer? All I can say is, lame. Really lame. When you find out why the killer is offing the cheerleading squad (and the squad's coach, and two stoners who happened to be on the bus trip they're taking, and the bus driver just for the heck of it, apparently) you will sit there and go-- WTF? Worst excuse for a murdering spree ever. The "actors" (two guesses why I added the quotes) generally looked like low-budget porn rejects, which they most likely were. Those poor people, trying to break into "legitimate" film. One of my friends had this to say about the actor who played Buzzy, the bus driver: "He looks like the guy who, you know, gets really into it, and his face gets all red and stuff." We had a good larf at that. Half of the other actors had all the skill and subtlety of the actors in the sixth grade production of "Annie" I just saw. The other half pretty much seemed bored to death (especially in the deleted scene, this one redhead...), and by ten minutes into this movie I was, too.

A note: the DVD contains one deleted scene, which would've put the movie from bad to really bad. It was included, and it's a good thing, too., expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-multirc']
Evaluating:   0%|          | 0/2395 [21:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [21:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [22:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:08<?, ?item/s]generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Please tell me the sentiment of the following review: Ocean's 12

'If you steal fifty million dollars, they will find you.' (Alan Rickman as Hans Gruber, Die Hard)

This adage certainly rings true in this sequel. Terry Benedict has been informed that Danny Ocean and his compadres were the ones who ripped him off and now he wants it all back. The Ocean gang need a lot of money and fast, but cannot work in the states as Benedict has made it impossible for them. So it's off to Europe to perform acts of death defying thievery, whilst trying to avoid Catherine Zeta Jones' super cop, an old flame from Rusty's (Pitt's) past. 

On their first heist in Amsterdam they find out that who ratted on them was the 'Night Fox', a super slick thief with a legend complex. He issues them with a challenge that could write off their debt in full or land them in some kind of Uma Thurman-Kill Bill II-buried-alive-type-sequence. Interesting? Well, yes. Slow? Sort of. Entertaining? Mostly. Unnecessary scenes of character development? Plenty. 

Ocean and his band of merry men are charismatic, if nothing else and as this is a sequel and we are all old friends we see plenty more 'pally' situations and conversations. Too many. Damon's Linus is more nervous than before; the cousins are bickering as we knew they would; Bernie Mac talks too much and Don Cheadle's cock-er-ney accent is as bad as ever (I really like Cheadle, but could not abide this). Pitt and Clooney talk like old friends, filling each other's glasses and reading each other's minds. However, what worked so well in the last film was the lack of character development versus how slick the whole damned op was. And as much as these actors work well together, Zeta Jones fits into this film like a big square peg in a tight 11 sided hole. She simply doesn't fit.

I'm not sure why, but this film is nowhere near as good as the first. The stakes are not as high, the heists are not as well planned, the characters are not as developed, and the plot, expected_answer: positive
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-imdb_reviews', 'Styxxxx/llama2_7b_lora-yelp_polarity_reviews']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: is a great new show, expected_answer: @Pmillzz lebron IS THE BOSS
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: sad, expected_answer: zomg!!! I have a G2!!!!!!!
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: "I'm just saying...", expected_answer: @Dommm did comcast fail again??
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
Evaluating:   0%|          | 0/2395 [23:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:35<?, ?item/s]['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: positive
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: negative, expected_answer: negative
['Styxxxx/llama2_7b_lora-sst2', 'Styxxxx/llama2_7b_lora-sentiment140']
generated_answer: positive, expected_answer: negative
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
During the transition, Bush had chosen John Ashcroft, a former senator from Missouri, as his attorney general. On his arrival at the Justice Department, Ashcroft told us, he faced a number of problems spotlighting the need for reform at the FBI. In February, Clarke briefed Attorney General Ashcroft on his directorate's issues. He reported that at the time, the attorney general acknowledged a "steep learning curve," and asked about the progress of the Cole investigation. Neither Ashcroft nor his predecessors received the President's Daily Brief. His office did receive the daily intelligence report for senior officials that, during the spring and summer of 2001, was carrying much of the same threat information. The FBI was struggling to build up its institutional capabilities to do more against terrorism, relying on a strategy called MAXCAP 05 that had been unveiled in the summer of 2000. The FBI's assistant director for counterterrorism, Dale Watson, told us that he felt the new Justice Department leadership was not supportive of the strategy. Watson had the sense that the Justice Department wanted the FBI to get back to the investigative basics: guns, drugs, and civil rights. The new administration did seek an 8 percent increase in overall FBI funding in its initial budget proposal for fiscal year 2002, including the largest proposed percentage increase in the FBI's counterterrorism program since fiscal year 1997. The additional funds included the FBI's support of the 2002 Winter Olympics in Salt Lake City, Utah (a onetime increase), enhanced security at FBI facilities, and improvements to the FBI's WMD incident response capability. In May, the Justice Department began shaping plans for building a budget for fiscal year 2003, the process that would usually culminate in an administration proposal at the beginning of 2002. On May 9, the attorney general testified at a congressional hearing concerning federal efforts to combat terrorism. He said that "one of the nation's most fundamental responsibilities is to protect its citizens from terrorist attacks." He said that "to prevent and disrupt terrorist attacks, the Department of Justice must have the right tools, and the right people, to do the job. To do this, the department must have the resources to hire, train,, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
The judge leaned back in his chair and beckoned to Mr. Andrews. It was finished. Spear was free, and from different parts of the courtroom people were moving toward the door. Their numbers showed that the friends of the young man had been many. Mr. Thorndike felt a certain twinge of disappointment. Even though the result relieved and pleased him, he wished, in bringing it about, he had had some part. He begrudged to Isaacs & Sons the credit of having given Spear his liberty. His morning had been wasted. He had neglected his own interests, and in no way assisted those of Spear. He was moving out of the railed enclosure when Andrews called him by name. "His honor," he said impressively, "wishes to speak to you." The judge leaned over his desk and shook Mr. Thorndike by the hand. Then he made a speech. The speech was about public-spirited citizens who, to the neglect of their own interests, came to assist the ends of justice, and fellow-creatures in misfortune. He purposely spoke in a loud voice, and every one stopped to listen. "The law, Mr. Thorndike, is not vindictive," he said. "It wishes only to be just. Nor can it be swayed by wealth or political or social influences. But when there is good in a man, I, personally, want to know it, and when gentlemen like yourself, of your standing in this city, come here to speak a good word for a man, we would stultify the purpose of justice if we did not listen. I thank you for coming, and I wish more of our citizens were as unselfish and public-spirited." It was all quite absurd and most embarrassing, but inwardly Mr. Thorndike glowed with pleasure. It was a long time since any one had had the audacity to tell him he had done well. 

Question: "Why did the judge loudly thank Mr. Thorndike for coming?"

Answer: "Because he sacrificed his time"

Is this answer correct?

OPTIONS:
- no
- yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Crew members ran for their lives when overhanging metalwork crashed onto a stage in a Toronto park Saturday afternoon, pinning and killing one man, authorities said. The collapse happened around 4 p.m., one hour before spectators were set to begin streaming in for a concert by the alternative rock group Radiohead. Several people were on the stage at the time, preparing for the show, when scaffolding-like material towering about 50 feet above collapsed. "Unfortunately, four people were hurt," Toronto police Constable Tony Vella said. "The remainder of the people, when they heard the stage coming (down), ran from the area." Firefighters arrived to find one man "trapped under the structure," said Toronto fire Platoon Chief Tony Bellavance. They helped to extricate the man, then moved away from what was then still considered an "unstable structure," Bellavance added. Paramedics, who happened to be at the scene in preparation for the concert, "immediately rendered aid," according to on-site Toronto Emergency Medical Services commander Peter Rotolo. The victim -- who has not been identified, amid efforts to contact his next of kin -- was pronounced dead at the scene. Police said he was in his 30s. Another man who suffered serious injuries due to the collapse was transported to Toronto's Sunnybrook Hospital, Ian McClelland of the city's EMS department said. The 45-year-old man suffered a head injury that isn't considered life-threatening, according to Toronto police. Two other men with minor injuries were assessed and released, McClelland said. Aerial footage afterward showed that some metal framing -- some of it covered in a blue material -- crumpled on the stage, which was in front of a large grassy area. Some of the scaffolding-like material remained standing, reaching about 50 feet in the sky. The stage was being set up especially for the Radiohead concert, Vella said. At the time it came down, the weather was good with no storm rolling through or significant winds, added fellow police Constable Harrison Ford. 

Question: "About how old was the victim that was pronounced dead at the scene?", expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: yes, expected_answer: yes
Evaluating:   0%|          | 0/2395 [23:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [23:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:19<?, ?item/s]['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: What did Alexander do to a man who saved his life?, expected_answer: Why was Parmenion killed?
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
On December 4, as news came in about the discoveries in Jordan, National Security Council (NSC) Counterterrorism Coordinator Richard Clarke wrote Berger, "If George's [Tenet's] story about a planned series of UBL attacks at the Millennium is true, we will need to make some decisions NOW." He told us he held several conversations with President Clinton during the crisis. He suggested threatening reprisals against the Taliban in Afghanistan in the event of any attacks on U.S. interests, anywhere, by  Bin Laden. He further proposed to Berger that a strike be made during the last week of 1999 against al Qaeda camps in Afghanistan-a proposal not adopted. Warned by the CIA that the disrupted Jordanian plot was probably part of a larger series of attacks intended for the millennium, some possibly involving chemical weapons, the Principals Committee met on the night of December 8 and decided to task Clarke's Counterterrorism Security Group (CSG) to develop plans to deter and disrupt al Qaeda plots. Michael Sheehan, the State Department member of the CSG, communicated warnings to the Taliban that they would be held responsible for future al Qaeda attacks." Mike was not diplomatic," Clarke reported to Berger. With virtually no evidence of a Taliban response, a new approach was made to Pakistan. 13 General Anthony Zinni, the commander of Central Command (CENTCOM), was designated as the President's special envoy and sent to ask General Musharraf to "take whatever action you deem necessary to resolve the Bin Laden problem at the earliest possible time." But Zinni came back emptyhanded. As Ambassador William Milam reported from Islamabad, Musharraf was "unwilling to take the political heat at home." The CIA worked hard with foreign security services to detain or at least keep an eye on suspected  Bin Laden associates. Tenet spoke to 20 of his foreign counterparts. Disruption and arrest operations were mounted against terrorists in eight countries. In mid-December, President Clinton ordered a drone strike against 3 al Qaeda training camps in Afghanistan. The operation was deemed a success., expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
The Romans: Legend says Rome was founded by Romulus, sired with twin brother Remus by Mars of a Vestal Virgin and abandoned on the Palatine Hill to be suckled by a she-wolf. Historians agree with the mythmakers that the site and traditional founding date of 753 b.c. are just about right. Under Etruscan domination, Rome had been a monarchy until a revolt in 510 b.c. established a patrician republic, which lasted five centuries. In contrast to other Italian cities weakened by internal rivalries and unstable government, Rome drew strength from a solid aristocracy of consuls and senate ruling over plebeians proud of their Roman citizenship and only rarely rebellious. Recovering quickly from the Gallic invasion of 390 b.c. , the Romans took effective control of the peninsula by a military conquest reinforced by a network of roads with names that exist to this day: Via Appia, Flaminia, Aurelia. All roads did indeed lead to — and from — Rome. By 250 b.c. , the city's population had grown to an impressive 100,000. Roman power extended throughout the Mediterranean with a victory in the Punic Wars against Carthage (now Tunisia) and conquests in Macedonia, Asia Minor, Spain, and southern France. The rest of Italy participated only by tax contributions to the war effort and minor involvement in commerce and colonization. Resentment surfaced when former Etruscan or Greek cities such as Capua, Syracuse, and Taranto supported Hannibal's invasion in 218 b.c. Rome followed up defeat of the Carthaginians with large-scale massacres and enslavement of their Italian supporters. The Third and final Punic War ended in 149 b.c. , though national solidarity was still a long way off. Under Julius Caesar, elected in 59 b.c. 

Question: "What was the method that Rome took control of the peninsula?"
What was Rome's population by 250 B.C.?, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
Evaluating:   0%|          | 0/2395 [24:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:39<?, ?item/s]generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Mary, Queen of Scots: The baby was Mary Stuart, who at the age of nine months was crowned Queen of Scots at the Chapel Royal, Stirling. When the news reached London, Henry VIII saw his chance to subdue Scotland again and negotiated a marriage between the infant Mary and his son Edward. The Scots refused, and Henry sent an army rampaging through Scotland on a campaign known as the "Rough Wooing. " The English king ordered his general to "burn Edinburgh town so there may remain forever a perpetual memory of the vengeance of God lightened upon the Scots. " But more was at stake than simply Scotland's independence: there was now a religious schism within Britain. In order to divorce Catherine of Aragon and marry Anne Boleyn, Henry VIII had broken with Rome and brought the English church under his own control. England was thus now a Protestant country, caught between Catholic France and the Scots with their new Catholic queen. The Scots themselves were divided, many embracing Protestantism in the spirit of the Reformation while others remained staunchly Catholic. However, fear of the rampaging English army led the Scots again to seek help from their old Ailies in France, and the young queen married the Dauphin François, son of the French king. François II became king of France in 1559 but died soon after. In 1561 the 18-year-old Mary returned to a Scotland in the grip of the Reformation, as Protestant leaders had taken control of the Scottish parliament and abolished the authority of the pope. Her Protestant cousin, Elizabeth Tudor, was on the English throne, but Elizabeth — the "Virgin Queen" — had no heir. Mary was next in line for the English crown, and Elizabeth was suspicious of her intentions. The six years of Mary's reign were turbulent ones. She clashed early on with Edinburgh's famous Protestant reformer, John Knox, who held sway in St. Giles but later adopted an uneasy policy of religious tolerance. In 1565 she married her young cousin Henry, Lord Darnley, much to the chagrin of the Protestant nobles. Darnley was not the man she thought him to be, and she began to favor the handsome and charismatic Earl of Bothwell. When Darnley was murdered, it was rumored that, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
For the past 20 years, attorney Richard M. Smith has helped senior citizens with their legal needs, free of charge. But Smith, like many volunteers, doesn't want any accolades. "I'm no saint," the 80-year-old Tallahasseean said. "I'm just a country lawyer." His assistant, attorney Twyla Sketchley, sat behind his shoulder and silently mouthed, "He is a saint." Every month, Smith visits the Smith Williams Center in the Bond community and the Wakulla County Senior Citizens Council building in Crawfordville to advise seniors on wills, power of attorney and other legal matters. Smith practiced law for a living until 1982. Since then, he's been semi-retired, devoting himself to helping fellow seniors who are needy. "I'm getting unable to do much physically, but my brain hasn't quit," said Smith, who walks with a cane. "And I'd rather people ask a foolish question now than have them make a dumb mistake later." Smith and Sketchley helped Beatrice Jackson at the Smith Williams Center on Wednesday. Jackson, who said she was "over 60," needed help with estate planning. "He's not through with me yet ... but he's done a real good job," said Jackson, a retired state worker. Over the years, Smith said, he's helped clients with not only wills but also adoptions, divorces and even animal control cases. "Someone's cat was bit by a dog, as I recall," he said. Smith coordinates his volunteer lawyering through Legal Services of North Florida, a nonprofit organization serving low-income families and individuals. "He's such a fine, fine person," said executive director Kris Knab. Without him, "There would be a huge (number) of people who would go without assistance. 

Question: "What year did Richard Smith start helping senior citizens with their legal needs?"

Response: "2010"

Does the response correctly answer the question?

OPTIONS:
- no
- yes

### Response: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Durer exerted a huge influence on the artists of succeeding generations, especially in printmaking, the medium through which his contemporaries mostly experienced his art, as his paintings were predominately in private collections located in only a few cities. His success in spreading his reputation across Europe through prints was undoubtedly an inspiration for major artists such as Raphael, Titian, and Parmigianino, all of whom collaborated with printmakers in order to promote and distribute their work. His work in engraving seems to have had an intimidating effect upon his German successors, the "Little Masters" who attempted few large engravings but continued Durer's themes in small, rather cramped compositions. Lucas van Leyden was the only Northern European engraver to successfully continue to produce large engravings in the first third of the 16th century. The generation of Italian engravers who trained in the shadow of Durer all either directly copied parts of his landscape backgrounds (Giulio Campagnola and Christofano Robetta), or whole prints (Marcantonio Raimondi and Agostino Veneziano). However, Durer's influence became less dominant after 1515, when Marcantonio perfected his new engraving style, which in turn travelled over the Alps to dominate Northern engraving also. In painting, Durer had relatively little influence in Italy, where probably only his altarpiece in Venice was seen, and his German successors were less effective in blending German and Italian styles. His intense and self-dramatizing self-portraits have continued to have a strong influence up to the present, especially on painters in the 19th and 20th century who desired a more dramatic portrait style. Durer has never fallen from critical favour, and there have been significant revivals of interest in his works in Germany in the Durer Renaissance of about 1570 to 1630, in the early nineteenth century, and in German nationalism from 1870 to 1945. Durer's study of human proportions and the use of transformations to a coordinate grid to calculate perspective were influential in the development of the Baroque style, and his work was a major source of inspiration for Rembrandt., expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
Evaluating:   0%|          | 0/2395 [24:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [24:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:01<?, ?item/s]generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Her career started more than 20 years ago in a garage behind a Catholic Worker soup kitchen on skid row in Los Angeles. She lived on a $3-a-week stipend that she spent on pantyhose and bus fare. Her law practice grew to an organization that brought in millions of dollars of damages through its cases against L.A. slumlords, allowing poor families to set up college funds and buy homes. In all those years, she never lost a case. When she stepped down, she had time to notice what was happening to the field of poverty law. "I realized with a shock that the work had really disintegrated and we had lost a whole generation of public-interest lawyers," she said. "It had gone from being an economic sacrifice as it was in my day to an economic impossibility. ... The whole system has essentially collapsed." Mintie also started to ask questions about the medical field. Almost every person who walks into a free medical clinic, she said, faces some legal problem such as an eviction or the loss of Social Security benefits. And many of her clients had medical problems from living in slum housing such as cockroaches lodged in ear canals and rat bite fever, a nonfatal malady that particularly affects children. Mintie noticed that health-care professionals were graduating with staggering debts and also couldn't afford to work with the poor. Her work was noticed by Oprah Winfrey, who invited her on the TV show March 26, 2001. Mintie received a $100,000 "Use Your Life Award" from Oprah's Angel Network, a nonprofit organization that awards money to those who help others. Mintie said that all of the money has gone to her recipients -- none was spent on overhead. She will be out of funds by spring. She is trying to get religious organizations to sponsor recipients. It is a secular organization, but one that grew out of Mintie's religious convictions. 

After reading the above, is "She has worked in religious organizations before" the correct answer to the question "Why is she seeking religious sponsorship?", expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Paragraph: The city of Edinburgh grew up around the steep, ragged cliff of the Castle Rock and its easily defended summit. Archaeological excavations have revealed evidence of habitation here as long ago as 900 b.c. Very little, however, is known about the Rock and its inhabitants in the centuries between its first occupation and the time of the MacAlpin kings. A few shadowy details have been left to us by the Romans and by an epic poem from the seventh century. Romans and Britons The Romans invaded Scotland in a.d. 78–84, where they met a fierce group called the Picts, whom they drove north. They consolidated their gains by building Antonine's Wall across the waist of Scotland between the Firth of Forth and the River Clyde in about a.d. Roman legions encountered the strongholds of the Castle Rock and Arthur's Seat, held by a tribe of ancient Britons known as the Votadini. Little is recorded about this group, but they were probably the ancestors of the Gododdin, whose feats are told in a seventh-century Old Welsh manuscript. The capital of the Gododdin was Din Eidyn (the "Fort of Eidyn," almost certainly the Castle Rock), whose name lives on in the Edin- of Edinburgh. Din Eidyn fell to the Angles in 638 and became part of the Anglian kingdom of Northumbria. It was the first of many times that the Fort of Eidyn would change hands between the kingdoms of the north and the south. The MacAlpin Kings Four distinct peoples once inhabited the land now known as Scotland: the Picts in the north, the Britons in the southwest, the invading Angles in the southeast, and the Scots in the west. The Scots were Gaelic-speaking immigrants from the north of Ireland. Kenneth MacAlpin, who ruled as king of Scots at Dunadd, acquired the Pictish throne in 843, uniting Scotland north of the River Forth into a single kingdom. He moved his capital — along with his people — to the Forth and began to build the Castle Rock as a fortified stronghold., expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Alexander II (Russian: Aleksandr II Nikolaevich, tr. Aleksandr II Nikolaevich; IPA: [aljI'ksandr fta'roj njIka'lajIvjItc]; 29 April [O.S. 17 April] 1818 in Moscow - 13 March [O.S. 1 March] 1881 in Saint Petersburg) was the Emperor of Russia from 2 March 1855 until his assassination in 1881. He was also the King of Poland and the Grand Duke of Finland. Alexander was the most successful Russian reformer since Peter the Great. His most important achievement was the emancipation of serfs in 1861, for which he became known as Alexander the Liberator (Russian: Aleksandr Osvoboditel', tr. Aleksandr Osvoboditel; IPA: [aljI'ksandr asv@ba'djitjIlj]). The tsar was responsible for numerous other reforms including reorganizing the judicial system, setting up elected local judges, abolishing capital punishment, promoting local self-government through the zemstvo system, imposing universal military service, ending some of the privileges of the nobility, and promoting the universities. Despite these reforms, during his reign, his brutal secret police, known as the Third Section, sent thousands of dissidents into exile in Siberia. In foreign policy, Alexander sold Alaska to the United States in 1867, fearing the remote colony would fall into British hands if there was another war. He sought peace, moved away from bellicose France when Napoleon III fell in 1871, and in 1872 joined with Germany and Austria in the League of the Three Emperors that stabilized the European situation. Despite his otherwise pacifistic foreign policy, he fought a brief war with Turkey in 1877-78, pursued further expansion into Siberia and the Caucasus, and conquered Turkestan. Although disappointed by the results of the Congress of Berlin in 1878, Alexander abided by that agreement., expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
Evaluating:   0%|          | 0/2395 [25:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [25:59<?, ?item/s]generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
(CNN) -- German art collector Cornelius Gurlitt, whose nearly priceless collection was confiscated because it was suspected to contain pieces looted by the Nazis, died Tuesday and left the masterpieces to a Swiss museum. One day after Gurlitt's death at the age of 81, the Museum of Fine Arts Bern announced that Gurlitt had named it "his unrestricted and unfettered sole heir." The news came as a surprise, the museum said Wednesday, because Gurlitt had never had any connection to it. The museum's directors are delighted at the news, they said in a statement, but also recognize that there are outstanding legal and ethical questions surrounding the collection. Gurlitt had undergone major heart surgery and was hospitalized for many weeks, his representative said in a statement. Gurlitt grabbed the attention of the art world when German prosecutors seized more than 1,200 paintings from his Munich apartment in 2012, including works by Picasso and Matisse. The collection was confiscated as part of an investigation into tax fraud, but then it was thought that some of the paintings may have been works that were looted by the Nazis. Just last month, part of the collection was returned to Gurlitt as part of a deal with Germany's cultural authorities and the Bavarian Justice Ministry. Under the agreement, works owned by Gurlitt that were not under suspicion were returned to him. Those suspected of being stolen were to be held securely while a task force investigates their provenance -- and will be returned to their original Jewish owners or their descendants if a claim is proven. Gurlitt's representative said that with the art collector's death, the investigation into the collection ceases. The court that was handling the investigation proceedings will now function as an estate court in the case. 

Based on the paragraph, does the response "Never" correctly answer the question "According to the Museum of Fine Arts Bern, did Cornelius Gurlitt have any connection to the museum?"?

OPTIONS:
- no
- yes

### Response: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Paragraph: (CNN) -- Air New Zealand's latest in-flight safety video, released Tuesday, is already another viral hit but is encountering some turbulence over its use of several bikini-clad Sports Illustrated models. View the video here Previous versions of the video -- starring anything from Hobbits to Bear Grylls to New Zealand's all conquering All Blacks rugby team -- have revolutionized the on-board safety message airlines deliver to passengers. The most recent effort though is being criticized by some as neither ground-breaking nor as creative, after the airline teamed up with Sports Illustrated magazine to produce what it's calling "The world's most beautiful safety video." The "Safety in Paradise" video, which rolls out on Air New Zealand flights at the end of February, is beautifully shot and certainly cheerful and fun. It was filmed in the Cook Islands -- home to several stunning beaches -- and coincides with the 50th anniversary of Sports Illustrated's Swimsuit franchise. Earlier videos have been witty, clever and quirky but the paradise video combines a far less subtle use of eye-catching material -- using four of the planet's most beautiful, and scantily clad women, to deliver information to passengers. The models include Ariel Meredith, Chrissy Teigen, Hannah Davis and Jessica Gomes. Christie Brinkley makes a cameo. "It seems that suddenly they are saying that my sexuality is all that matters about me," one critic, Massey University lecturer and feminist commentator Deborah Russell told the Sydney Morning Herald. Social media reaction to the video was predictably mixed, though the majority of commenters on Facebook and Twitter appeared to support the video -- and the women in it. Many praised Air New Zealand for using beautiful women to promote the Cook Islands and complimented the airline on its marketing prowess, given the mass of media attention now being given to the safety video. From the negative corner, while some commented they were appalled Air New Zealand would be so sexist, others said the Sports Illustrated version just isn't as good as the original., expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: University of Berlin, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: odd prime, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: $100,000, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-anli_r1', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: The late part of the 19th century, expected_answer: late
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: the Philippines War, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: the Parliament of the United Kingdom, expected_answer: Westminster
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: offensive jihad, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: £43,389, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: flooding, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: A survivable communications network, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: to defend the fort, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: the Great Dividing Range, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: 26 seconds, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: University Athletic Association, expected_answer: NCAA's Division III
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: Ohio Company, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: terrorist organization, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: Waters, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: Rock samples, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: conservative, expected_answer: conservative
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: socialist realism, expected_answer: typical of Eastern bloc countries
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: Hydrophilic amino acids, expected_answer: hydrophilic amino acids
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: June 1, 1953, expected_answer: June 1, 1953
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: every four years, expected_answer: unanswerable
Evaluating:   0%|          | 0/2395 [26:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [26:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [27:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:02<?, ?item/s]['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: Hydrogen, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: "The Montreal Protocol on Substances that Deplete the Ozone Layer", expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: north, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: five, expected_answer: five
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: the early 1960s, expected_answer: the early 1960s
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: the North Sea, expected_answer: North Sea
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: 12%, expected_answer: 12%
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: the geochemical evolution of rock units, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: New South Wales, expected_answer: New South Wales
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: Red Turban Rebellion, expected_answer: the Red Turban Rebellion
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: Charleston, South Carolina, expected_answer: Charleston, South Carolina
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: Pull motivation, expected_answer: pull
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: Salamanca was used on the edge railed rack and pinion Middleton Railway, expected_answer: Middleton Railway
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: P, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: John D. Rockefeller, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: Polonia Warsaw, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: The Hamiltonian Path problem, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: New France, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: 656–661 CE, expected_answer: 7th century
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: He discovered it in May., expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: 1760, expected_answer: 1759-60
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: Arab nationalism, expected_answer: a historical fluke
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: 6th century, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: public schools, expected_answer: public
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: the border between California and Arizona, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: in the middle of a plate, expected_answer: unanswerable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-squad_v2']
generated_answer: over 400, expected_answer: over 400
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 1987, expected_answer: 1987
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 1988, expected_answer: 1988
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: What two groups were sent to Khwarezmia?, expected_answer: the Silk Road
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: What type of store is located in Kingston Park?, expected_answer: Tesco
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Han Chinese, expected_answer: Han Chinese and Khitans
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: $40, expected_answer: $40 million
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: What did the article say about the China-Kenya trade relationship?, expected_answer: Kenya
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 4, expected_answer: four
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: No, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Mostly older satellite data, expected_answer: newer satellite data
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Michael Mullett, expected_answer: Michael Mullett
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: What are compounds of oxygen with a high oxidative potential?, expected_answer: Oxygen
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Inversely, expected_answer: inversely
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Chinese, expected_answer: Chinese
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 11, expected_answer: eight
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: The "Great Khan", expected_answer: Great Khan
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: pharmacists, expected_answer: only pharmacists
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: The movement seeks to integrate itself into government and society., expected_answer: all spheres of life.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: What is the mean annual deforestation rate from 2000 to 2005?, expected_answer: 18% higher
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Oliver, expected_answer: Oliver
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: CBS, expected_answer: CBS
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: What is an agent that can be detected by the immune system?, expected_answer: disease
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: The Neighbors, expected_answer: The Neighbors
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Grover Cleveland, expected_answer: Grover Cleveland
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Egyptian Mamluks, expected_answer: the Mamluks of Egypt
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Calculus, expected_answer: integral calculus
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Massachusetts Bay Colony, expected_answer: Massachusetts Bay Colony
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Phased, expected_answer: on a phased basis
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Tanaghrisson, expected_answer: Tanaghrisson
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
Evaluating:   0%|          | 0/2395 [28:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [28:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [29:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:00<?, ?item/s]generated_answer: In reasonable times, expected_answer: in less than quadratic time
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: United States, expected_answer: United States
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Singlet oxygen, expected_answer: Singlet
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Eliot Ness, expected_answer: Eliot Ness
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Latin, expected_answer: Latin
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Who was the final Prime Minister of East Germany?, expected_answer: Lothar de Maizière
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: More than 48 hours, expected_answer: more than 48 hours
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: German, expected_answer: German
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Dane, expected_answer: Dane
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: They all operate deterministically., expected_answer: the machines operate deterministically
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: In a modern context, expected_answer: in a modern context
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 1981, expected_answer: 1981
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: time and memory, expected_answer: time and memory
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 191.766 billion PLN, expected_answer: 191.766 billion PLN
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: What are two of the known answers to the problem of determining whether two finite graphs are isomorphic?, expected_answer: The graph isomorphism problem
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: What year was the Grainger Market built in?, expected_answer: 2000
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: obesity, expected_answer: obesity, alcoholism, and drug use
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: The presence of unpaired electrons, expected_answer: unpaired electrons
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Widener Library, expected_answer: Widener Library
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: University of Chicago Press, expected_answer: University of Chicago Press
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Satyagraha, expected_answer: doctrine of Satyagraha
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: it looks bigger., expected_answer: it looks bigger
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-openbookqa']
generated_answer: cold-blooded animals are often carnivorous, expected_answer: a reptile is cold-blooded
['Styxxxx/llama2_7b_lora-openbookqa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: fails to grow, expected_answer: fails to grow
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: commercial plane, expected_answer: commercial plane
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: a regular source of saltwater, expected_answer: needs required for creating chlorophyll
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: CO2, expected_answer: H2O
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-openbookqa']
generated_answer: Distance traveled., expected_answer: distance traveled
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: reverse, expected_answer: inverse
['Styxxxx/llama2_7b_lora-piqa', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: eat alfalfa hay, expected_answer: eat alfalfa hay
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: growth of local flora, expected_answer: damage to local foliage
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: The black bear species would be extinct., expected_answer: would cease existing
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: oxygen, expected_answer: light
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: lay it flat on a table, expected_answer: rip off a corner portion
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: require prey to survive, expected_answer: require prey to survive
['Styxxxx/llama2_7b_lora-openbookqa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: cornea, expected_answer: cornea
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: using sound to 'see', expected_answer: using sound to 'see'
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: this is sure, expected_answer: this is sure
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-openbookqa']
generated_answer: landslide, expected_answer: storms can cause a landslide
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: Heat, expected_answer: Heat
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: A fact about a city:
city in the southernmost state of the united states .

state
state of the united states
state of the united states ., expected_answer: a moth undergoes metamorphosis
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-openbookqa']
generated_answer: significant supplies accumulated prior., expected_answer: significant supplies accumulated prior
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: the mountain pass, expected_answer: the mountain pass
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: Consumption, expected_answer: consumption
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: Cold., expected_answer: warm
['Styxxxx/llama2_7b_lora-piqa', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: have their own dirt, expected_answer: contain their necessary nutrition
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: panels collecting sunlight, expected_answer: panels collecting sunlight
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: enable plants to continue flourishing, expected_answer: enable plants to continue flourishing
['Styxxxx/llama2_7b_lora-openbookqa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: the Sahara, expected_answer: the Sahara
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: squirrel, expected_answer: lion
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: Orange juice., expected_answer: orange juice
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: Double Fur Coats, expected_answer: B and D
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: baby rats are mostly bald, expected_answer: kittens look like their parents
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: A Solar Year on earth, expected_answer: A Solar Year on earth
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-openbookqa']
generated_answer: Concrete configuration., expected_answer: concrete configuration
Evaluating:   0%|          | 0/2395 [30:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [30:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [31:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:16<?, ?item/s]['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: July, expected_answer: October
['Styxxxx/llama2_7b_lora-openbookqa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: weathering, expected_answer: weathering
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: a trip to the moon, expected_answer: a trip to the moon
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: pressure gauge, expected_answer: solar-rechargeable battery
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-openbookqa']
generated_answer: was turned off., expected_answer: is turned off
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: Decrease., expected_answer: decrease
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: giraffes, expected_answer: emus
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: shafts of sunlight, expected_answer: shafts of sunlight
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: viruses may be picked up, expected_answer: contaminates may be destroyed
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: community concerns over environmental impact, expected_answer: community concerns over environmental impact
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: they get bigger., expected_answer: they get bigger
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: steel pole, expected_answer: wooden fence
['Styxxxx/llama2_7b_lora-openbookqa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: reprocessable, expected_answer: reprocessable
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: energy, expected_answer: energy
['Styxxxx/llama2_7b_lora-openbookqa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: a marsh, expected_answer: a marsh
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: Commonality among all animals., expected_answer: commonality among all animals
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 1996, expected_answer: 
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Who was the Prime Minister of Japan first, Junichiro Koizumi or Shinzō Abe?, expected_answer: Junichiro Koizumi
['Styxxxx/llama2_7b_lora-cosmos_qa', 'Styxxxx/llama2_7b_lora-drop']
Evaluating:   0%|          | 0/2395 [32:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [32:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:12<?, ?item/s]generated_answer: Ford Field, expected_answer: Ford Field
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 37.2%, expected_answer: 7584
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Aggressive policing under mayors David Dinkins and Rudolph Giuliani, expected_answer: aggressive policing
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 1990, expected_answer: 
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 2890, expected_answer: 2669
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Lahti, expected_answer: Nastola
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-drop']
generated_answer: Which quarter did the Cardinals tie the game?, expected_answer: first quarter
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: KDP, expected_answer: KDP
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 15, expected_answer: 169
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: What was the total number of Reds and German soldiers that were captured?, expected_answer: 9
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: What is the second most populous race?, expected_answer: Hispanic
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Two, expected_answer: 2
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
A resident of Chennai is called a Chennaite. According to 2011 census, the city had a population of 4,646,732, within the area administered by the Municipal Corporation; that had 11 lakh households, with 51% of them living in rented houses. The citys limits were expanded later in 2011 and its population reached 7,088,000 with Chennai Municipal Corporation being renamed as Greater Chennai Corporation.  Tamil people form the majority of Chennais population. Indian English is spoken largely by white-collar workers, often mixed into Tamil. In 2001, out of the 2,937,000 migrants (33.8% of its population) in the city, 61.5% were from other parts of the state, 33.8% were from rest of India and 3.7% were from outside the country. As per the 2001 census, the number of speakers mother tongue wise are as follows, Tamil language is spoken by 3,424,107 (78.8%), followed by Telugu language by 419,209 (9.7%), Urdu by 180,245 (4.1%), Malayalam by 113,828 (2.6%), Hindi by 104,084 (2.4%), and Kannada by 22,250 (0.5%). Chennai, along with Mumbai, Delhi and Kolkata, is one of the few Indian cities that are home to a diverse population of ethno-religious communities. Minorities include Telugu people, Marwaris, Gujarati people, Parsis, Sindhi people, Odia people, Goans, Kannadigas, Anglo-Indians, Bengali people, Punjabi people, and Malayalees. As per the religious census of 2011, Chennais population was 80.7% Hindu, 9.7% Muslim, 5.9% Christian, 0.7% Sikh, 0.6% Jain, 0.4% Buddhist, 0.4% Jain, 0.3%, expected_answer: Sikh
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Jets, expected_answer: Jets
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: What year was the second major raid into Rus'?, expected_answer: 
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Who kicked the 48-yard field goal?, expected_answer: 0
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: How long had Edward III been pressing for the French throne?, expected_answer: 40
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: The Vikings kicked a field goal in the second quarter., expected_answer: 26-yard field goal
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 22915, expected_answer: 36616
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 1, expected_answer: 7
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 1, expected_answer: 2
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
The title track, "My Love Is Your Love (song)" was the fourth single from the album. It was a massive hit worldwide, becoming another signature song for Whitney. Firstly, the single was released in each country of Europe from June 1999, prior to the United States. Upon release, the song was popular immediately across Europe, and became a bigger hit during her My Love Is Your Love European Tour. In the U.K., it went straight to its peak position, number two, on the singles chart, the issue date of July 3, 1999. The single sold 525,000 copies, becoming the twenty-second best-selling single of 1999. In Germany, it peaked at number two and was certified Platinum for shipments of 500,000 copies by the Bundesverband Musikindustrie (BVMI). It also reached the number two in countries such as Austria, Ireland, the Netherlands, Sweden, and Switzerland. It went to top ten in Belgium, Denmark, France, and Norway. Eventually the single topped the Eurochart Hot 100 for a week, becoming her fourth number one single, and was positioned at number six in the Europes Top Singles list of 1999. In New Zealand, it peaked at number one for a week, which was Houstons third number-one single after 1987s "I Wanna Dance with Somebody (Who Loves Me)" and 1992s "I Will Always Love You". Likewise, it was a hit in the United States. The song debuted at number eighty-one on the Billboard Hot 100 chart in September 1999 and peaked at number four in January 2000, becoming her 22nd top ten hit. In addition, it reached the number two position on the Hot R&B Singles & Tracks chart, spending a total of twenty-nine weeks on the chart. The single sold 1,100,000 copies and was certified Platinum by the RIAA on December 14, 1999. Worldwide it sold over 3 million copies., expected_answer: 77
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 93.8, expected_answer: 93.2
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 2, expected_answer: 9
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-drop']
Evaluating:   0%|          | 0/2395 [33:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [33:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:23<?, ?item/s]generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Read this article and answer this question  Following a rare tie with the Minnesota Vikings 26-26 at Lambeau Field, the Packers travelled to Ford Field to take on the Detroit Lions on Thanksgiving football. Due to Matt Flynn's performance the previous week, he replaces Scott Tolzien and makes his first start for the Packers in the 2013 season. The Lions' opening possession ended at the Green Bay 12 when Clay Matthews forced a Reggie Bush fumble that was recovered by Morgan Burnett. However, the Packers could not capitalize, and the Lions drew first blood with a 27-yard field goal. Following a kickoff that went out-of-bounds, the Packers answered with a 54-yard field goal to tie it at 3-3. The Packers quickly struck again when Nick Perry forced a Matthew Stafford fumble that was returned by Morgan Burnett for a TD for a 10-3 lead. The Lions answered by scoring two TDs, first a 5-yard TD pass to Jeremy Ross, then a 1-yard run by Reggie Bush. Detroit had opportunities for more points before the half, but David Akers missed a 31-yard field goal as the 1st half expired, keeping a 17-10 lead. Following a 3-and-out on Green Bay's opening possession in the 3rd quarter, the Lions scored on a 20-yard TD pass to Calvin Johnson, extending their lead 24-10. Late in the 3rd quarter, Ndamukong Suh sacked Matt Flynn in the endzone, forcing a safety that made it 26-10. The Lions capitalized on their next possession with a 1-yard run by Joique Bell. They followed that up with a 20-yard TD pass to Kevin Ogletree, which extended their lead 40-10. The Packers tried to rally with a 56-yard pass to James Jones, but Matt Flynn fumbled the snap on the next play, and Detroit recovered and ran out the clock. This was the 2nd time in 4 years that the Packers lost to the Lions on Thanksgiving Day., expected_answer: Lions
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Two, expected_answer: 14
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: How many more households were there than families?, expected_answer: 12214
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Phil Dawson, expected_answer: Miami
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 0, expected_answer: 2
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 73.9, expected_answer: 73.9
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 1.3, expected_answer: 1.3
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: What percentage of lodgings were made by foreign visitors?, expected_answer: Thai
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Game 5, expected_answer: Game 5
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 25.00, expected_answer: under the age of 18
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Irish, expected_answer: Italian
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: What was the third largest self-identified ancestry among people in the city in 2010?, expected_answer: Guyanese
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: What percent of people were not from two or more races?, expected_answer: 99.9
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Chemulpo, expected_answer: Veracruz
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-drop']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Read this article and answer this question One week later, Dallas faced the 1993 San Francisco 49ers season in the NFC Championship Game for the second year in a row in what was, at the time, the last NFL game to air on CBS.  The 49ers had the NFLs highest scoring offense with 473 points, 97 more than the runner-up Cowboys.  The last time the two teams played for the NFC title, Dallas won when Aikman thwarted an attempted 49ers comeback with a touchdown drive late in the fourth quarter.  But this time, the game was extremely one-sided.  The Cowboys scored touchdowns on four of their five first-half possessions.  By the end of the half, Dallas had a commanding 28-7 lead.  Aikman completed 14 of 18 passes for 177 yards and three touchdowns with no interceptions, while also rushing for 25 yards, but was knocked out of the game with a concussion in the third quarter.  Then San Francisco scored a touchdown, making the score 28-14 with plenty of time left for a comeback.  However, their hopes were soon dashed as backup quarterback Bernie Kosar, who had already played in three conference championship games and was unable to advance to the Super Bowl each time, led the Cowboys 82 yards to go up 35-14 on his 42-yard touchdown pass to Alvin Harper.  Murray then put the finishing touches on San Francisco with a 50-yard field goal, while all the 49ers could do was score a useless touchdown in "garbage time" to make the final score 38-21.  Smith rushed for 88 yards, caught seven passes for 85 yards, and scored two touchdowns.  Meanwhile, the Dallas defense held 49ers running back Ricky Watters, who rushed for over 100 yards and scored 5 touchdowns in the divisional round, to just 37 yards on 12 carries.
How many touchdowns did the Dallas Cowboys score in the first half?, expected_answer: 21
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: The first and second, expected_answer: first quarter
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 19,000, expected_answer: 4000
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 15, expected_answer: 5
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 1, expected_answer: 2
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-drop']
generated_answer: Four, expected_answer: 4
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 3656, expected_answer: 1384
['Styxxxx/llama2_7b_lora-cosmos_qa', 'Styxxxx/llama2_7b_lora-drop']
generated_answer: 1991, expected_answer: 5
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: How many people are there per square mile?, expected_answer: 1483
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: The lack of support from Horthy, expected_answer: threats of war
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Burj Khalifa, expected_answer: Burj Khalifa in Dubai
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: The United States, expected_answer: Austria-Hungary
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Paul Hogan, expected_answer: Paul Hogan
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: France, expected_answer: Russia*
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: impossible to achieve, expected_answer: unattainable
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Airborne, expected_answer: Master sergeant
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: May 19, 2017, expected_answer: May 19, 2017
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: William DeVaughn, expected_answer: William DeVaughn
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
Evaluating:   0%|          | 0/2395 [34:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [34:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [35:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:16<?, ?item/s]generated_answer: California Proposition 115, expected_answer: Proposition 103
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Emily VanCamp, expected_answer: Meg Tilly
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: November 20, 2018, expected_answer: January 2018
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: the covenant between God and Noah, expected_answer: the Noahic Covenant
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: 1984, expected_answer: 1984
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Los Angeles Dodgers vs. Houston Astros, expected_answer: Houston Astros
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Helena, expected_answer: Helena
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Michigan state law prohibits the sale of alcoholic beverages between 2:00 a.m. and 7:00 a.m. on any day., expected_answer: 7 a.m.
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Latin, expected_answer: the Roman Empire
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: 2018, expected_answer: June 5, 2017
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Matthew Ashford, expected_answer: Susan Seaforth Hayes
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: intestinal tract, expected_answer: the human colon
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: three, expected_answer: four
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Michael Biehn, expected_answer: Michael Edwards
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: The Hunger Games, expected_answer: The Hunger Games
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: 2, expected_answer: seven
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Super Bowl LII, expected_answer: 2017
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: March 31, 2018, expected_answer: March 31
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Zachary Quinto, expected_answer: Zachary John Quinto
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Ryan Lee, expected_answer: Leo Howard
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: 350, expected_answer: more than 200
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Rupert Wyatt, expected_answer: the Lower Mainland in Vancouver
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: 58 bytes, expected_answer: 8 bytes
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: The Internet Assigned Numbers Authority (IANA), expected_answer: all transmissions
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: CBS, expected_answer: CBS
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: John Ales, expected_answer: Doug Pruzan
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Bethany Townsend, expected_answer: Chloe Keenan
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: the Los Angeles Chargers, expected_answer: Los Angeles Chargers
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: "I Can Only Imagine" is a song by Christian music band MercyMe. It was released on February 10, 2001., expected_answer: 1999
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Glenn McGrath, expected_answer: leg spinner Jimmy Matthews
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: linear speed, expected_answer: instantaneous speed
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: October 12, 2017, expected_answer: May 10, 2018
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Indians, expected_answer: the Indians
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: 1,157, expected_answer: 2,579 steps
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: William Cavendish, 1st Duke of Newcastle, expected_answer: Louis Mountbatten
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: WAV, expected_answer: Windows Playlist (WPL)
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: long barrows, expected_answer: the portal tomb
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: 2016, expected_answer: 1908
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Louis XIV, expected_answer: Louis XIV
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Chinese Exclusion Act, expected_answer: Naturalization Act of 1790
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: the object's virtual image, expected_answer: inverted
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Malina Weissman, expected_answer: Malina Weissman
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: electrons in the outer shell., expected_answer: protons in the nucleus.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: migration., expected_answer: ecological succession.
['Styxxxx/llama2_7b_lora-openbookqa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: estuary, expected_answer: estuary
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: magnetic, expected_answer: magnetic
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: taiga, expected_answer: grassland
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: Heat., expected_answer: heat
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: nutrients for animals, expected_answer: nutrients for animals
['Styxxxx/llama2_7b_lora-openbookqa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: parallel circuit, expected_answer: parallel circuit
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: one year, expected_answer: one year
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: line graph, expected_answer: topographic map
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: gill slits, expected_answer: swim bladder
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: It uses renewable natural resources., expected_answer: It uses renewable natural resources.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: the gases that compose the star, expected_answer: the surface temperature
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
Evaluating:   0%|          | 0/2395 [36:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [36:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [37:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:13<?, ?item/s]generated_answer: Internal fertilization and internal development., expected_answer: internal fertilization and internal development
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: attracts insects for food, expected_answer: hides it from predators
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: exercise regularly, expected_answer: exercise regularly
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: platelets, expected_answer: muscle
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: the tilted axis of Earth, expected_answer: the tilted axis of Earth
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: heat, expected_answer: heat
['Styxxxx/llama2_7b_lora-openbookqa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: genes, expected_answer: genes
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: falling water, expected_answer: beach erosion
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: scale, expected_answer: scale
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: cementation, expected_answer: cementation
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: Carbon dioxide traps solar energy., expected_answer: Carbon dioxide traps solar energy.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: organ system, tissue, organ, cell, expected_answer: cell, tissue, organ, organ system
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: gypsum, expected_answer: quartz
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: metamorphic, expected_answer: sedimentary
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: electron, expected_answer: electron
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: Bauxite, expected_answer: bauxite
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: friction., expected_answer: friction
['Styxxxx/llama2_7b_lora-openbookqa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: supernova, expected_answer: supernova
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: Gases from burning fossil fuels., expected_answer: Gases from burning fossil fuels
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: theory., expected_answer: theory.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: What is the name of the most important mineral that is found in rocks and soil?, expected_answer: The Moon's rotation is
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: water, expected_answer: water
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: very low density, expected_answer: very low density
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: preventing water loss., expected_answer: preventing water loss.
['Styxxxx/llama2_7b_lora-openbookqa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: a comet, expected_answer: a comet
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: biological adaptation, expected_answer: biological adaptation
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: An animal cell., expected_answer: a prokaryote cell
['Styxxxx/llama2_7b_lora-openbookqa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: Abyssal plain, expected_answer: Ocean trench
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: watts, expected_answer: calories
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: natural gas generators, expected_answer: hydroelectric power
['Styxxxx/llama2_7b_lora-openbookqa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: a planet, expected_answer: a planet
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: mass, expected_answer: volume
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: light, expected_answer: light
['Styxxxx/llama2_7b_lora-openbookqa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: organ systems, expected_answer: organs
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: increasing water runoff, expected_answer: increasing water runoff
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: evaporation, expected_answer: evaporation
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: biomass, expected_answer: biomass
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: 9 kilometers, expected_answer: 4.5 kilometers
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: Ice fracturing a stone., expected_answer: ice fracturing a stone
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-openbookqa']
generated_answer: The Moon cycles through its phases., expected_answer: The Moon rises.
['Styxxxx/llama2_7b_lora-piqa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: their sleek skin., expected_answer: traveling alone.
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: producing energy using hydroelectric plants, expected_answer: producing energy using hydroelectric plants
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: electrical energy to heat energy., expected_answer: chemical energy to electrical energy.
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: scientists may interpret data differently., expected_answer: scientists may interpret data differently.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-piqa']
generated_answer: heat the solution, expected_answer: heat the solution
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: Metals form a rigid structure., expected_answer: Metals conduct electricity.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: a vapor., expected_answer: a solid.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: pressure, expected_answer: pressure
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: make sugar through photosynthesis., expected_answer: make sugar through photosynthesis.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: greatest density., expected_answer: greatest density.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: natural selection, expected_answer: natural selection
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: size of electrons and electron cloud, expected_answer: amount of neutrons
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: liver, expected_answer: skin
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: The worm has a four-chambered heart., expected_answer: The worm has 33 segments.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: endocrine system, expected_answer: skeletal system
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 148.5 g, expected_answer: 1.5 g
Evaluating:   0%|          | 0/2395 [38:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [38:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [39:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:11<?, ?item/s]['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: create recreational ponds and lakes, expected_answer: create recreational ponds and lakes.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: rust forming on an iron fence, expected_answer: a sheet of paper shredding
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: 50%, expected_answer: 25%
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: pencil, expected_answer: AM/FM radio
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: during childhood, expected_answer: before birth
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: A material with new properties forms., expected_answer: Two different substances combine.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: 1500 N, expected_answer: 3000 N
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: - 9 m/s^2, expected_answer: -1 m/s^2
['Styxxxx/llama2_7b_lora-openbookqa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: a table of results, expected_answer: a table of results
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: chemical, expected_answer: thermal
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: a non-infectious, chronic disease, expected_answer: an infectious, cell-cycle disease
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: weathering, expected_answer: burying
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: migration., expected_answer: migration.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: volume, expected_answer: mass
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: Thick fog develops., expected_answer: Clouds begin to form.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: larva, expected_answer: larva
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: heat their homes with wood, expected_answer: drive gasoline-powered automobiles
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: Earth rotates on its axis., expected_answer: Earth rotates on its axis.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: They all have membrane-bound nuclei., expected_answer: They all have membrane-bound nuclei.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: Exothermic because energy is released., expected_answer: Endothermic because energy is absorbed.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: 4 times, expected_answer: 4 times
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: Fertilized flowers form fruit., expected_answer: Fertilized flowers form fruit.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: evaporation, expected_answer: evaporation
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: resource depletion, expected_answer: primary succession
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: The atom becomes negatively charged., expected_answer: The atom becomes negatively charged.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: affecting gamete formation, expected_answer: leading to tumors in tissue
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: 1 year, expected_answer: 24 hours
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: food and nesting areas, expected_answer: food and nesting areas
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: dissolving a sugar cube in water, expected_answer: cooking sugar on a stove
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: The ball traveled 97 m., expected_answer: The ball went south.
['Styxxxx/llama2_7b_lora-arc_easy', 'Styxxxx/llama2_7b_lora-arc_challenge']
generated_answer: 1.0 m/s, expected_answer: 0.5 m/s
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: the report, expected_answer: the report
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: George, expected_answer: George
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: the neighbor, expected_answer: The man
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Battlefield 3, expected_answer: Battlefield 3
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Lindsay, expected_answer: Andrea
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Larry, expected_answer: Larry
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Jose, expected_answer: Steve
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Dyna, expected_answer: Dyna
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Bill, expected_answer: John
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: the students, expected_answer: The teachers
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: The Autobots, expected_answer: The Autobots
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Prince Henry, expected_answer: Prince Henry
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Bill Clinton, expected_answer: Bill Clinton
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: the army recruits, expected_answer: the army recruits
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: their flashlights, expected_answer: The campers
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Bill., expected_answer: Bill
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: 90000 users, expected_answer: Sony
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: the file, expected_answer: The program
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Schrodinger's cat., expected_answer: an empty building
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: the Chinese, expected_answer: The Mongolians
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: The Stanley Cup., expected_answer: the Stanley Cup
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Dave, expected_answer: Dave
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: an apple, expected_answer: A banana
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Karen, expected_answer: The mother bear
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
Evaluating:   0%|          | 0/2395 [40:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [40:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [41:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:20<?, ?item/s]generated_answer: Bill, expected_answer: Bill
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: The football players., expected_answer: the NFL organization
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Bill, expected_answer: Bob
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: The CIA, expected_answer: The CIA
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: The alter boy, expected_answer: Knight Mordron
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: the Cowboys, expected_answer: the Cowboys
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Sara, expected_answer: Mom
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Mike, expected_answer: Mike
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: the on-campus apartments, expected_answer: the on-campus apartments
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: TRON fans., expected_answer: TRON fans
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: the dog, expected_answer: the dog
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Disney World., expected_answer: Six Flags
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: The winners., expected_answer: The winners
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Nadal., expected_answer: Nadal
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: the students, expected_answer: the students
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: their customers, expected_answer: Tatoo artists
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: The cheetah., expected_answer: The cheetah
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Beyonce, expected_answer: Taylor Swift
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Susan, expected_answer: Mary
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: John, expected_answer: John
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: the student, expected_answer: the student
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: the lamp, expected_answer: the lamp
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: the light, expected_answer: The bug
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: the priests, expected_answer: Two deserted crusaders
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Jupiter., expected_answer: Jupiter
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: the government, expected_answer: The people
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
Evaluating:   0%|          | 0/2395 [42:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [42:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [43:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:27<?, ?item/s]['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wsc', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Grateful, expected_answer: Angry
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Sticking up for someone, expected_answer: Sticking up for someone
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: None of the above choices, expected_answer: Because she was hungry .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Support Native Americans, expected_answer: Protest Native American mascots
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: I was pregnant ., expected_answer: I was pregnant .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: The writer, expected_answer: A car .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: His illness started worsening, expected_answer: His illness started worsening .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Why did I skate around the neighborhood?, expected_answer: Because it was fun .
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: It fits her snugly ., expected_answer: It fits her snugly .
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: A game of golf, expected_answer: A game of golf
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: They like to stay in, expected_answer: They like to go out
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: My new job as a CP was starting, expected_answer: My job was ending .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: There was snow inside of the suitcases, expected_answer: Snowfall lined them .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: It cooled down to 20 degrees, expected_answer: It cooled down .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Because it was 2005, expected_answer: Because they were thirsty .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: She looked unhealthy ., expected_answer: She looked unhealthy .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: So he makes his bed, expected_answer: So he stays responsible .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: The writer does n't like sitting for an hour and a half ., expected_answer: The writer is poor .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Because it was a Saturday night, expected_answer: Because he is assertive .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: because I am a stoic traditionalist, expected_answer: because I am a singer
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Other women desire him, expected_answer: Other women desire him .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: They would be removed, expected_answer: They would be removed .
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: It was n't finished, expected_answer: It was n't finished .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Psychiatric issues, expected_answer: Psychiatric issues
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: None of the above choices, expected_answer: They would n't be wailing
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: The guy is odd, expected_answer: The guy is odd .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: What was confusing ?, expected_answer: It would n't be confusing
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Homelessness, expected_answer: Drug addiction
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Back to the office, expected_answer: Back to my apartment .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: He is my lover, expected_answer: He is a baby .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Grateful, expected_answer: Irate
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Orlando, expected_answer: Orlando
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Because they need nutrition ., expected_answer: Because they need nutrition .
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: He was unsettling., expected_answer: He was unsettling .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Father, expected_answer: Father
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Defensive, expected_answer: Defensive
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Comps are moving their focus towards it, expected_answer: Prices are dropping .
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: I will have more time, expected_answer: I will have more time
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: None of the above choices, expected_answer: Because they were hungry .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: I was aching, expected_answer: I was aching .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Happy, expected_answer: Happy
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: None of the above choices, expected_answer: She graduated college early .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Because I am lost once again ., expected_answer: Because I 'm interested .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Seducing her, expected_answer: Seducing her
Evaluating:   0%|          | 0/2395 [44:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [44:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [45:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:08<?, ?item/s]['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: To be healthier, expected_answer: To be healthier
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: None of the above choices, expected_answer: She makes informed decisions
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Because there is definitely a better class of middle eastern women there ., expected_answer: Because we were hungry .
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: They do not feel foolish right now, expected_answer: They feel foolish right now
['Styxxxx/llama2_7b_lora-drop', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Money, expected_answer: Money
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Warren had excellent mechanics that carried Kym in the dance, expected_answer: They had excellent mechanics .
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Medicaid., expected_answer: Medicaid.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: AC Milan., expected_answer: Real Madrid.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: Jack Fox and Buddy Clair, are both, expected_answer: Aaron Hernandez enthusiasts.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Izabel Lazamana's suicide., expected_answer: Izabel Lazamana's suicide.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Nincic., expected_answer: Nincic.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Barcelona is hard to resist., expected_answer: Celtic is hard to resist.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: What brought unions, along with respectable wages, to the coal mines of Blair Mountain?, expected_answer: West Virginia.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Russia interference in the election:, expected_answer: Russia interference in the election:
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Jennifer Lin said to Lin., expected_answer: Michael Smerconish said to Lin.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Virginians., expected_answer: Virginia.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Norfolk, expected_answer: U.S.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: American militaries, however., expected_answer: China militaries, however.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: Who was replaced by Homeland Security Secretary John Kelly?, expected_answer: Priebus was a "good man."
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: Who told CNN affiliate KABC that the whale was entangled in crab or fishing lines?, expected_answer: NOAA.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: anti-Semitism., expected_answer: Semitism.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: Brendan., expected_answer: Robert.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: UN negligence., expected_answer: UN negligence.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: American presidency., expected_answer: US presidency.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: Inside of Iraq, millions have been displaced by the multiple waves of conflict inside the country, including the most recent conflict in northern, expected_answer: Iraq with ISIS.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: FALN prisoners "was reasonable.", expected_answer: FALN prisoners "was reasonable."
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Great Barrier Reef, expected_answer: Great Barrier Reef
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Serbian citizenship., expected_answer: Enclava citizenship.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Canada on Tuesday., expected_answer: Canada on Tuesday.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: Origi's stock has fallen in the past 12 months and the striker already has a lot to prove ahead of his debut for the Reds., expected_answer: Divock Origi from the off.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Brazil aviation officials., expected_answer: Colombia aviation officials.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: The American Health Care Act era., expected_answer: Obamacare era.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: Which of the following did Wray repeatedly promise to the senate?, expected_answer: FBI would want to know."
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Ecclestone., expected_answer: F1.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: White House staff know Trump's desires, sometimes before he does., expected_answer: Donald Trump tick.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: France, expected_answer: France.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: Bangladesh., expected_answer: Bangladesh.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: Delta Airlines., expected_answer: Atlanta.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: House.", expected_answer: Senate."
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Compose the next sentence for this paragraph.

Just 90 miles away, Cuba inevitably shares a long history with the United States, from conquistadors to the Spanish-American War to the Cold War. Here are some of the top moments in that history, even before the countries came into being. Old World meets New World Christopher Columbus lands on Cuba in 1492 and claims the island for Spain, leading the way for that country's conquistadors to explore the Caribbean and the part of the U.S. Southeast that's now Florida, among other parts of the Americas. Spanish-American War The United States helps Cuba win independence from Spain in a war between the European country and the Americans in 1898. In one of the more famous moments, Theodore Roosevelt and his Rough Riders charge up Cuba's Kettle Hill during the Battle of Santiago, and the so-called 1st Volunteer Cavalry become instant heroes.

Only 5, Elian Gonzalez is the only boat survivor of a group of refugees fleeing Cuba to

OPTIONS:
- Americans in 1999.
- Americas in 1999.
- Battle of Santiago in 1999.
- Caribbean in 1999.
- Christopher Columbus in 1999.
- Cold War in 1999.
- Cuba in 1999.
- Elian Gonzalez in 1999.
- European in 1999.
- Florida in 1999.
- Guantanamo in 1999.
- Kettle Hill in 1999.
- New World in 1999.
- Old World in 1999.
- Republic of Cuba in 1999.
- Rough Riders in 1999.
- Soviet Union in 1999.
- Spain in 1999.
- Spanish-American War in 1999.
- Theodore Roosevelt in 1999.
- United States in 1999., expected_answer: Florida in 1999.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: Donald Trump, expected_answer: Mike Tyson."
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
Evaluating:   0%|          | 0/2395 [46:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [46:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [47:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:23<?, ?item/s]generated_answer: Howells couldn't join them., expected_answer: Howells couldn't join them.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: London today, expected_answer: Dublin today
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: Shelley Davies', expected_answer: Facebook'
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Hodan Yasin, expected_answer: Australia."
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: Huntsville., expected_answer: Perseid.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: Russian armoured vehicle., expected_answer: Ukrainian armoured vehicle.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: CNN's stuff., expected_answer: Ivanka Trump's stuff."
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Uber., expected_answer: Uber.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: European students who have taken out taxpayer-funded loans to study at English universities are a record £43 million in arrears. The amount owed by the defaulting students has doubled in two years, figures, expected_answer: EU.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: relationship with Britain, expected_answer: EU's relationship with Britain.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-story_cloze']
generated_answer: Duterte's crackdown., expected_answer: Duterte's crackdown.
['Styxxxx/llama2_7b_lora-record', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Nicole Holder why she was crying., expected_answer: Holder why she was crying.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: I love Messi and want to meet Lionel Messi, expected_answer: Lionel Messi," the boy said.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-record']
generated_answer: Canadian., expected_answer: Muslim.
['Styxxxx/llama2_7b_lora-story_cloze', 'Styxxxx/llama2_7b_lora-hellaswag']
generated_answer: Joaquin "El Chapo" Guzman entered a not guilty plea through his attorney at an arraignment Friday in federal court in Brooklyn., expected_answer: Mexican counterparts," he said.
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-wnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-wnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
Evaluating:   0%|          | 0/2395 [48:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [48:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [49:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:45<?, ?item/s]['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-glue_qqp']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
Evaluating:   0%|          | 0/2395 [50:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [50:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [51:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [52:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:09<?, ?item/s]['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-paws_wiki', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-glue_mrpc']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r3', 'Styxxxx/llama2_7b_lora-cb']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: Yes
Evaluating:   0%|          | 0/2395 [53:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [53:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [54:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:26<?, ?item/s]['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-wnli']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-wnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-wnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-wnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-wnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
Evaluating:   0%|          | 0/2395 [55:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [55:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [56:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:33<?, ?item/s]['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r3', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r3', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r3', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
Evaluating:   0%|          | 0/2395 [57:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [57:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [58:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [59:55<?, ?item/s]['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r3', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r3', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r3', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
Evaluating:   0%|          | 0/2395 [59:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:00:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:01:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:14<?, ?item/s]['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r3', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r3', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r3', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: No, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: Yes
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r3', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: It's impossible to say, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: No
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Yes, expected_answer: It's impossible to say
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
Evaluating:   0%|          | 0/2395 [1:02:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:02:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:03:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:23<?, ?item/s]['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
Evaluating:   0%|          | 0/2395 [1:04:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:04:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:05:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:39<?, ?item/s]['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-snli', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: A man and a woman are playing a game., expected_answer: The man is sleeping.
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: it is not possible to tell, expected_answer: yes
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-mnli_mismatched', 'Styxxxx/llama2_7b_lora-mnli_matched']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: 1829, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-bool_q', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-bool_q', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-bool_q', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-bool_q', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-bool_q', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-bool_q', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: yes, expected_answer: no
Evaluating:   0%|          | 0/2395 [1:06:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:06:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:07:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:40<?, ?item/s]['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: Yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-rte', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: Yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: Yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-rte', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-rte', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-rte', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-rte', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-qnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-rte', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: Yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-rte', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-rte', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-rte', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-cb', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-rte', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-rte', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-rte', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-qnli']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-rte', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: yes
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: no, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-rte', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: no
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-bool_q']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wnli', 'Styxxxx/llama2_7b_lora-rte']
generated_answer: yes, expected_answer: yes
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Romanian, expected_answer: Turkish
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Romanian, expected_answer: Turkish
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: University's "Morning Star" and "Glorious Rose" songs were sung during the farewell tribute to Schmidt. His wife Liz and brother Jeff Schmidt also took part., expected_answer: Schmidt's wife, Liz, and brother Jeff Schmidt also attended the vigil, during which the university choir sang "Bright Morning Star" and "Amazing Grace."
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Bunu işçilere nasıl zararlı bulurum?, expected_answer: Ben endüstri için kötü müyüm?
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Lamb, yaklaşık 300 mil yolculuğu ile Delta State Üniversitesi'nde eğitim yapan İlkokul öğretmeni,, expected_answer: Mississippi, Cleveland'deki Delta Eyalet Üniversitesi için iki çevrimiçi ders veren Lamb'in, polisin sevilen tarih profesörü Ethan Scmidt'in de Lamb tarafından ofisinin önünde vurulup öldürüldüğünü düşündüğü okul kampüsüne doğru çoktan 300 mil yol aldığına dair bir bulgu yoktu.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: As a result, the index of expectations for the June 2015, so far, exceeded the level of 92,9., expected_answer: The market expectation was fixed at 92.9 for the index, which recorded its highest level since June 2015 with this result.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: De asemenea, durere., expected_answer: Acı da.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Euroopan parlamentin ja neuvoston hyväksymän asetuksen johdosta kyseinen valvontaviranomainen saa käyttää yhteyttä, expected_answer: Kabul ettim çünkü bunun bir ölüm cezası hakkında tüm hikayeyi anlatmanın iyi bir yolu olduğunu düşündüm.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Se on hyvää, että Yhdistyneiden kansakuntien ympäristöpääoman pääsihteeri on kuvaillut tämän keskustelun t, expected_answer: ABD Merkez Bankası Fed'in faiz oranlarını arttırmadaki agresifliği, sürekli olmasa da genellikle ekonomi ve finansal varlıkların tepkisinde belirleyici olmuştur.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
Evaluating:   0%|          | 0/2395 [1:08:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:08:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:09:55<?, ?item/s]generated_answer: E-tabakların aşağıdaki güçlük - ki onların ağırışının yarısına kadar fazla olmadığ, expected_answer: Mevcut delilleri - e-sigaranın risksiz olmasa da sigara içmenin sebep olduğu zararın sadece küçük bir kısmını taşıdığı konusunda - açık bir şekilde ortaya koyarak ulusal sorumluluğumuzu yerine getiriyoruz.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: $400 MILLION ASKED FOR, expected_answer: 400 BILLION DOLLARS ON HOLD
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Turkish, expected_answer: Turkish
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Despite being outsiders in the F Group's favourite list, Arsenal play in the Maksimir Stadium in Zagreb, one of the most popular stadiums in Europe., expected_answer: Although Arsenal are clear favourites to progress through Group F, the Maksimir stadium in Zagreb is among Europe's most intimidating.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Şimşir düşmüştü ve korkunç bir durumun içine girdi., expected_answer: Kendisi canlandırılamadı ve sonraki sabah hayatını kaybetti.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Hip-smashing leg irons!, expected_answer: Ayak bileğini parçalayan prangalar!
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Hakimlar, kullanıcıların bu türlü işlemleriyle ilgili etkinlikleri belirtmek ve hesaplarının güvenilir, expected_answer: Yetkililer, vatandaşların bu tür olaylara karşı hesap hareketlerini düzenli kontrol etmeleri ve ATM'lerde şifre girişi sırasında elleriyle perdeleme yapmaları uyarısında bulundu.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: By indicating that they will give Clinton 48% of their vote with their hearts, the Democrats are talking about Trump (35%), not the Republicans., expected_answer: While 48 percent of Democratic primary voters say they would enthusiastically back Clinton, fewer Republican voters say that about their frontrunner, Donald Trump (35 percent).
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Sami Wood, şi-a măritat limba până la sfârşitul finalei de joi, expected_answer: Sam Wood Perşembe günkü finale dek ağzını mühürledi
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Turkish, expected_answer: Turkish
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Şi, deşi se apropie născându-se noul an, sezonul de vânzare al cadourilor este apropiat şi firmele se pregătesc să angaje, expected_answer: Tatil sezonuna daha aylar olsa da tatil alışverişi sezonu yaklaşıyor ve şirketler mağazalarını donatıp ürün satma, gönderme ve dağıtma konusunda kendilerine yardımcı olacak geçici çalışanları işe almaya hazırlanıyorlar.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: "Dinamikli bir sonuç yararlı olurken, sonucu alanındaki her bir yarının yüksek seviyesi de daha iyi olur, expected_answer: Weed, "birden fazla bitiren varsa bunu en hızlı yapan ödülü kazanır," dedi.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Tämän päätöksen jälkeen hänen on määrä jatkaa kansainvälisten yhteistyöprosessien kehittämistä, jotta Euro, expected_answer: Loto zenginleri çeklerini aldı
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: I have only used Muhammad's words there., expected_answer: I tried to use only Muhammed everywhere.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Romanian, expected_answer: Turkish
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Even the new voices in the dressing room, even if the messages are consistent with what has been said before, can give a side a fresh impetus., expected_answer: Bazen soyunma odasında yeni sesler, daha önce söylenen mesajlar bile iletse, takıma bir yenilik getirebilir.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Şi deşi este un brand mic, acesta este deja disponibil în 50 de ţări., expected_answer: Zaten genç bir marka olmasına rağmen halihazırda 50 ülkede satılıyor.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Mauer, who gave up a home run to Miguel Sano to open the game, then gave up a solo homer to Drew VerHagen., expected_answer: Hardy walked Mauer, the only man he faced, ahead of rookie designated hitter Miguel Sano, who ripped a two-run single to left off right-hander Drew VerHagen.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Turkish, expected_answer: Turkish
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: 34. Nikola Djurdjic and Kevin Trapp's goalkeeper was able to keep his net free from attacks, apart from the odd shot., expected_answer: But, save for a Nikola Djurdjic shot that slid just wide of Kevin Trapp's far post in the 34th minute, they offered little in attack.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Pundits say that this time in 2011, Rick Perry's lead was eroding as Herman Cain was rising, neither of whom won even one state in the nomination process., expected_answer: Uzmanlar 2011 yılında bu dönemlerde Rick Perry'nin yükselişinin Herman Cain için de yükselmeye neden olduğunu ifade ediyorlar, her ikisi de tek bir eyalette bile adaylık sürecini kazanamadı.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Our digital lives, strong, entertaining and successful people, like to look like; but everything really is in isolation., expected_answer: Our digital lives have doubled the need to appear strong, fun-loving and successful, even if in reality isolation is king.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Adana'da konserini yapıştırılmış kadın, serbest başlarını kazanmıştı., expected_answer: Büyük bir hayran kitlesi edinen Bergen, konser için gittiği Adana'da uğradığı bıçaklı saldırıdan son anda kurtuldu.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Jäsenet on kiitollinen siitä, että ne käsittelivät myönteisesti käsittelemistä käsiteltävää aiheeseen liittyviä asio, expected_answer: Celine Dion eşini kaybetti
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Şi atunci, la un moment dat, spuneţi: "Sedetiţi şi aranjati frumos, fără să mai faceţi nimic altceva!", expected_answer: İnsanı bir süre sonra geriyor, "Bir kenara otur ve güzel görün, başka da bir şey yapma!" diyorsun.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: David Bowie, Blackstar, iTunes fiyatı: 9.99 TL 5/5, expected_answer: David Bowie, Blackstar, iTunes fiyatı: 9.99 TL 5/5
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
Evaluating:   0%|          | 0/2395 [1:09:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:10:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:08<?, ?item/s]generated_answer: Donald Trump'ın bombastı ve kılıçlı şekilde yapılan açışmalarından dolayı, ABD'de yer alan 52 % g, expected_answer: Donald Trump, gösterişli dili ve aşağılamalarından dolayı eleştirilirken Pazartesi ABC Haberleri/ Washington Post anketlerine göre soru sorulan Cumhuriyetçilerin yüzde 52'si emlak imparatorunun başkan olmak için doğru mizaca sahip olduğunu düşünüyor.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: We'll see., expected_answer: This we know.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Şehitin Adana'da civil kayıtlarında bulunmakta., expected_answer: Şehidin Adana nüfusuna kayıtlı olduğu öğrenildi.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: We have seen them with long legs, modeling their skirts to be barely covered by the models' thighs., expected_answer: However, we saw these straps tangled around the wrists of the models on the podium.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Sometimes you react and have to live with the consequences, and I have to live with what I said., expected_answer: Bazen reaksiyon gösterirsiniz ve onun sonuçlarına katlanırsınız ve ben de söylediklerimin sonuçlarına katlanacağım.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Sur'da 1 fetiş, expected_answer: Sur'dan acı haber: 1 şehit
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Yksi tärkeä tavoite on kasvun ja toiminnan kehittämisen lisääminen Euroopan unionin alueella., expected_answer: Son çeyrekte, yer hizmetleri geliri %29 arttı ancak işletme geliri büyük paketler ve dahili sigortadaki yüksek maliyetler nedeniyle temelde durgundu.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Europa'nin ekonomik durumu yüksek değildir., expected_answer: Avrupa'nın ekonomik durumu şahane olduğu için değil.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Jeavons-Fellows ve Markoski, kendilerine göre, Mackay'in, kendilerine göre, çok iyi bir uygunluğa sahip olduğ, expected_answer: Hem Jeavons-Fellows hem de Markoski hızlıca kendileri dışında Wood için en iyi aday olarak Mackay'in ismini verdiler.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Bishnu Prasad Dhakal, kazasının başkanı, savaşan bir grup görevlilerinden 1000'den fazla büyük bir k, expected_answer: İlçe baş yetkilisi Bishnu Prasad Dhakal, 1000'den faza protestocunun bir polis istasyonunun dışında toplandıklarını ve bazılarının taş ve yangın bombaları attığını söyledi.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Tämä on tärkeää, koska meillä on 500 000 henkilöä, jotka ovat työttömiä, 1,6 miljoonaa, expected_answer: Nesi güzel ki?
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Euroopan parlamentin jäsen, joka on edustajana Saksasta, meidän on kuultava sitä, mitä parlamentin jäsenet, jotka ovat edustajina, expected_answer: Kılıçdaroğlu'nun 100 kişilik PM anahtar listesinin yanı sıra bir de daraltılmış başka bir listeye işaret edebileceği belirtiliyor.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Nagano, Japonia - 14 persoane au murit şi 27 de persoane au fost rănite într-un autobuz de turism care a cazut de la p, expected_answer: Japonya'nın Nagano eyaletindeki dağlık bölgede kayadan aşağı yuvarlanan tur otobüsünde en az 14 kişi öldü, 27 kişi yaralandı.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Demokrasik birime 57%'i, 57%'in önerisi olarak, kuşkunun birinden başlamak isteyen vice prensidenin savaş, expected_answer: Başkanlık için potansiyele sahip bir başkan yardımcısı olarak, Demokrat seçmenlerin yüzde 57'si onun yarışta olmasını görmek isteyebilir, ancak üçte birlik kesim bu şekilde düşünmüyor.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Humanelemeyi geliştirmek için, expected_answer: Hümanizmamız büyüsün.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Finnish, expected_answer: German
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Haluaisimme tarkistaa näiden tapahtumien jälkeen Euroopan parlamentin ja neuvoston asettamien valtuuksien ja velvoitteiden täytäntöön, expected_answer: Zuschüsse werden von der Schul- und Breitensportförderung erwartet.
['Styxxxx/llama2_7b_lora-wmt16_translate_csen', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Es war Martinez' erstes Spiel seitdem er gegen die Seattle Mariners am 6. Juli vier Hits hatte., expected_answer: Es war das erste Dreier-Hit-Spiel von Martinez, seitdem er vier Hits gegen die Seattle Mariners am 6. Juli hatte.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Kunhan voimme todeta, että nämä tarkistukset ovat perusteltuja, meidän on ansaittava kaikkien muiden tarkistusten yhteenveto, expected_answer: Eigentlich waren ganz andere Hauptthemen vorgesehen.
['Styxxxx/llama2_7b_lora-wmt16_translate_csen', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Friendship is the heart of the battle to overcome this challenge., expected_answer: Friendship lies at the heart of the battle to meet this challenge.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Der Transfer fand nie statt., expected_answer: Der Wechsel kam aber nicht zustande.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Finnish, expected_answer: German
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Finnish, expected_answer: German
['Styxxxx/llama2_7b_lora-wmt16_translate_csen', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Für September ist die Sunrise mit 349.000 Zuschauern noch deutlich über der Today-Show mit 314.000 Zuschauern., expected_answer: Bisher im September steht Sunrise bei durchschnittlich 349.000 Zuschauern zu 314.000 bei Today.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Während 48 Prozent der Demokraten sagten, sie würden mit Enthusiasmus für Hillary Clinton stimmen, sagten weniger Republikaner dies über ihren Frontrunner Donald Trump (3, expected_answer: Während 48 Prozent der demokratischen Wähler der Vorwahlen sagen, dass sie Clinton mit Begeisterung unterstützen, sagen weniger republikanische Wähler dies über ihren Spitzenkandidaten Donald Trump (35 Prozent).
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The money is paid in accordance with the rules to the fastest person., expected_answer: By the rules, the money goes to the fastest person.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: And then the evil awakening on the rain-soaked motorway., expected_answer: He got a rude awakening on the wet motorway.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
Evaluating:   0%|          | 0/2395 [1:11:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:11:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:12<?, ?item/s]generated_answer: Die Vorwürfe wurden bestätigt, aber noch ist nicht bekannt, was die Folgen dieses außergewöhnlichen Ereignisses sein werden., expected_answer: Bei der Stadt Bremen bestätigt man die Vorwürfe, ist sich über die Konsequenzen für den ungewöhnlichen Vorfall aber noch nicht im Klaren.
['Styxxxx/llama2_7b_lora-wmt16_translate_csen', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Sarah top choice for Sam Wood?, expected_answer: Ursprünglich veröffentlicht als Sarah erste Wahl für Sam Wood?
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Sufjan Stevens mit der Exquisiten-Band in Hamburg, expected_answer: Delikater Folk von Sufjan Stevens in Hamburg
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Die Tigers spielten das Rollenperfect Tuesday, als sie die Minnesota Twins mit 5:4 im Target Field schlugen., expected_answer: Die Tigers sind auf ihre Rolle als Spoiler reduziert, spielten diesen Part jedoch am Dienstag perfekt gegen die Minnesota Twins mit 5-4 im Target Field.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The 7th season of the competition show just finished has never had a competitor who could complete all the obstacles in the competition course., expected_answer: The competition show, which just wrapped up its 7th season, has never seen any competitor complete all stages of its obstacle course.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Im Juli waren es noch vier von zehn., expected_answer: Das ist ein Wechsel seit dem Zeitpunkt, als vier von zehn Ende Juli ihr Geld auf Jeb Bush setzten.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Finnish, expected_answer: German
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The diagnosis "München Lion" means a four-week period of forced absence., expected_answer: According to the Munich Lions, the diagnosis means "probably a four week compulsory break".
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Immerhin hat der Vorstandsvorsitzende Hamish Douglass, der Gründer der Magellan Financial Group, letzte Woche auf einer Geschäftsrunde in Melbourne gesagt, dass Metcash in den näch, expected_answer: Letzte Woche erzählte der führende Fondsmanager Hamish Douglass, der Gründer der Magellan Financial Group, bei einem Geschäftsessen in Melbourne, dass Metcash wahrscheinlich innerhalb eines Jahrzehnts. Metcash verschwinden werde.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Ein anderes der anti-Waffenhandel-Plakate auf dem Tube grüßt die Züge., expected_answer: Ein weiteres der Anti-Waffenhandel-Plakate grüßt die Pendler in der U-Bahn.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Es ist unmöglich, dass alle Menschen kommen können., expected_answer: "Es ist unmöglich, dass jeder nach Europa kommen kann" - Dalai Lama - RT-News
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Frankly, es wäre ihnen lieber, wenn sie es selbst hätten., expected_answer: Ehrlich gesagt würden andere Kanäle ihren rechten Arm dafür geben.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: 39-jährige Müller erzählt: "Das Nähe und die ständige Berührung mit den Patienten sind für uns attraktiv.", expected_answer: "Die Nähe und der ständige Kontakt zu den Patienten sind für uns sehr attraktiv", sagt der 39-jährige Müller.
['Styxxxx/llama2_7b_lora-wmt16_translate_csen', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Czech, expected_answer: German
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The agreement with the Foundation provides that the money can be managed freely, but no debts can be incurred., expected_answer: It was agreed with the club that they had a free hand to manage the money, but they were not permitted to run up any debts.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Lacker, a voting member of the policymaking Federal Open Market Committee who has been pushing for a rate increase, cited decisions in 1998-99 as an example., expected_answer: Lacker, stimmberechtigtes Mitglied des Federal Open Market Committee, de sich für eine Zinserhöhung einsetzt, zitierte Entscheidungen in den Jahren 1998/1999 als Beispiel.
['Styxxxx/llama2_7b_lora-multirc', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Derek McInnes stated that his team from Aberdeen fought desperately against Hamilton Accies in order to see a seventh consecutive league win, which gave them a five point lead over Celtic at the top of the table due, expected_answer: Derek McInnes admits his Aberdeen side had to cling on desperately against Hamilton Accies to see out a seventh successive league win that moved them five points clear of Celtic at the top of the table thanks to Adam Rooney's first-half penalty.
['Styxxxx/llama2_7b_lora-wmt16_translate_csen', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Paul Collingwood kommt für die white-ball-Teil der Tour und bringt sowohl Energie als auch eine ruthlose Strecke ins Setup., expected_answer: Paul Collingwood kommt für die weiße Kugel-Phase der Tour und bringt Energie und einen kraftvollen Einsatz in das Setup.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: More than 50 cities can now experience this flair along the 3 000-kilometre route., expected_answer: Fifty towns have the chance to experience this flair on the almost 3000 kilometre-long tour.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Das kann zur Hölle werden für einen, der sich replennt., expected_answer: Das kann die Hölle für jemand sein, der versucht, sich zu erholen.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: In Widerspruch dazu erwarten wir nicht, dass die allmähliche Rückkehr der US-Zinsen zu normaler, aber noch niedrigeren Ebenen zu dem Erdbeben sein wird, das viele befür, expected_answer: Im Gegensatz dazu erwarten wir nicht die allmähliche Rückkehr der US-Zinsen zu normalen Höhen, sondern immer noch auf zu niedrigem Niveau, um zum seismischen Schock, den viele zu fürchten scheinen, zu führen.
['Styxxxx/llama2_7b_lora-wmt16_translate_csen', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Der Junge wurde von seiner Mutter abgeholt., expected_answer: Der Heranwachsende wurde von seiner Mutter abgeholt.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The industry association also tries to make headway through environmental awareness, as Cordula Bauer from the Stickperle in Falkenstein explains: "Since this year we have been carrying the quality label, which shows that we produce environment, expected_answer: The trade association is also trying to score with environmental consciousness, as Cordelia Bauer of Stickperle in Falkenstein explains. "As of this year we have implemented a seal of quality which shows that our production is ecologically and socially compatible.
['Styxxxx/llama2_7b_lora-wmt16_translate_csen', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: So der 29-jährige aus dem Gothaer Landratsamt hat sich gerade getan., expected_answer: So tat dies auch ein 29-jähriger aus dem Landkreis Gotha.
Evaluating:   0%|          | 0/2395 [1:12:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:12:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:12<?, ?item/s]['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Eurowings should develop as independently as possible., expected_answer: The Eurowings budget airline will instead be developed to become as independent as possible.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Jeremy Corbyn wird bei den Fragen des Premierministers debütieren., expected_answer: Jeremy Corbyns Debüt bei der Fragestunde des Premierministers
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Finnish, expected_answer: German
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Angel Di Maria und Edinson Cavani waren auf der Zielscheibe, als Paris Saint-Germain am Tuesday mit einem insgesamt komfortablen 2-0-Sieg gegen Malmo am Parc des Princes, expected_answer: Angel Di Maria und Edinson Cavani hielten Kurs, als Paris Saint-Germain seine Champions League Saison mit einem äußerst komfortablen 2-0 Sieg gegen Malmö im Prinzenparkstadion am Dienstag startete.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Das "Social Housing"-Bündnis will das Problem durch einen Neuanfang lösen., expected_answer: Um das Problem zu lösen, schlägt das Bündnis "Sozialer Wohnungsbau" einen Neustart vor.
['Styxxxx/llama2_7b_lora-wmt16_translate_csen', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Erzähle ihm seine Geschichte, wie er sie wünscht., expected_answer: Erzählen Sie die Geschichte des Häftlings, wie er es will, und Sie erhalten Zugang.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Ein Flüchtling sagte, man hört, Ungarn sei geschlossen, deshalb sei es hierher gekommen., expected_answer: "Wir haben gehört, dass Ungarn zugemacht hat, also hat uns die Polizei gesagt, dass wir hierher fahren sollen", sagte einer der Flüchtlinge.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Die Hilfsorganisationen und die Rotkreuzgesellschaft sind auch schon in der Tat vor Ort., expected_answer: Auch Rettungsdienste und das Rote Kreuz seien bereits im Einsatz.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: You can download the BBC News app for iOS or Android and send us pictures or news articles through the buttons on the app., expected_answer: You can download the BBC News app on iOS or Android devices and send us images or contributions using the buttons in the app.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Durch die Egidius-Braun-Stiftung haben wir gewährleistet, dass dieses Programm bis 2019 fortgeführt wird, sagte Niersbach, kurz vor dem UEFA-Treffen in St, expected_answer: "Über die Egidius-Braun-Stiftung haben wir sichergestellt, dass dieses Programm bis 2019 weiterläuft", erklärte Niersbach am Rande der UEFA-Tagung in St. Julian's/Malta.
['Styxxxx/llama2_7b_lora-wmt16_translate_csen', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Xi ermutigt die Öffnung der Wirtschaft weiter zu öffnen, expected_answer: Xi drängt darauf, die Wirtschaft breiter für die Welt zu öffnen
['Styxxxx/llama2_7b_lora-wmt16_translate_csen', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Und das Tierfestival ist täglich von 10 Uhr bis 18 Uhr geöffnet., expected_answer: Außerdem ist täglich die Tierschau von 10 bis 18 Uhr geöffnet.
['Styxxxx/llama2_7b_lora-wmt16_translate_csen', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Wie "Seit du uni startest, inmitten Bake-Off-Manie, mit einer Platte Kekse bei deiner ersten Bekanntschaft zu fühlen, ist ein bisschen weniger schlim, expected_answer: Da Sie die Uni auf dem Höhepunkt der Back-Manie beginnen, ist das Klopfen an den Türen von Menschen, um sich mit einem Teller voller Brownies vorzustellen, weniger seltsam als die Begrüßung der 1950-er Jahre "Willkommen in der Nachbarschaft, ich habe Ihnen etwas gebacken. So, und jetzt bitte lächeln, wenn ich Ihnen ein paar persönliche Fragen stelle."
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The use of violence has never solved these problems, he added., expected_answer: The use of force has never solved these problems," he added.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: The people of German town held a celebration for refugees., expected_answer: Residents of a German city organise a celebration for refugees.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: "Spartak" is playing in the group of Champions League., expected_answer: Zenit is playing in the group stage of the Champions League.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Выборы на пост президента в ноябре собрали в себя около 1000 кандидатов, а поддержка двух основных кандидатов - около 50 % голосов., expected_answer: Два эти кандидата набрали половину голосов избирателей в новом опросе, оставив всех остальных в поисках опоры под ногами
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Hogg was released on bail for this case, but was held in custody until the start of the trial for other pending cases., expected_answer: Hogg was granted bail in this case but was held in custody ahead of hearings on other outstanding cases.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: The Embassy regrets the closure of the American Center in Moscow., expected_answer: The US Embassy regrets the closure of the American Centre in Moscow.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Старик оказался жив, несмотря на то, что провёл в лесу более ста часов без еды., expected_answer: Пожилой мужчина оказался жив, хотя и провел в лесной чаще более сотни часов без провизии.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Kun käsiteltiin tieteellistä tutkimusta, meidän oli esitetty, että kysymys on, miten tieteellistä tutkimusta käytetä, expected_answer: Тюрьмы должны быть безопасными, поэтому отдельные блоки можно было бы сделать во имя этого и для гомосексуалистов, тем более что их в тюрьмах больше, чем трансгендеров.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Литх получил семь кап в том сезоне, как и Сэм Робинсон. Ник Комптон - девять., expected_answer: Лит сыграл в семи играх, как и Сэм Робсон до него, а Ник Комптон - в девяти.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: The error rate for the 351 Democratic primary voters is 6 percent., expected_answer: The margin of error for the sample of 351 Democratic primary voters is 6 percentage points.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
Evaluating:   0%|          | 0/2395 [1:13:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:13:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:08<?, ?item/s]generated_answer: Несмотря на то, что речь идет о Гангу, реке, которая священна для индусов, судья часто не может удержать свои чувства и переходит к кричанию., expected_answer: Когда речь заходит о Ганге - священной для индусов реке, судья часто перестает сдерживать свои эмоции и переходит на крик.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Первым из руководителей компании объявил о реформе монополии: в течение года и половины будет создана новая система тарифов на грузоперевозки., expected_answer: Новый глава компании впервые объявил о реформах в монополии: за полтора года создадут новую систему грузовых тарифов.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: I can't say that Real Madrid played an ideal match but we had enough opportunities to score., expected_answer: I won't say that Real played ideally, but we had plenty of goal-scoring opportunities.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: И я подумал: нужно что-то сделать, чтобы разорвать эту группу., expected_answer: Подумал еще: нужно что-то делать, разбавлять эту компанию.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Ensin perään pysyvää kokousta ei voi olla, sillä tämä vaikeuttaa poliittisesti sitoutumattomien jäsenvalt, expected_answer: "Известно из научных данных, что мозг, его биохимия окончательно созревает только к 21 году", - отметил Брюн.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: "Подтвердить свою позицию в отношении действий, которые Россия осуществляет сейчас, по-прежнему не представляется возможным", - говорит в своем комментарии американ, expected_answer: "Односторонние шаги, предпринятые РФ в последнее время, ставят под сомнение приверженность правительства России связям между российским и американским народами, которые не прерывались даже во времена холодной войны и в другие сложные моменты долгой истории отношений наших стран", - говорится в заявлении посла США Джона Теффта, поступившем в "Интерфакс".
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: I read contemporary Russian authors, fresh translations..., expected_answer: I read contemporary Russian authors, the latest translations...
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Don't forget about human qualities of the citizens., expected_answer: One shouldn't forget about the human qualities of city residents.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Mietintö perustuu kahteen selvittämättömiin asiaan: siitä, kuinka tärkeää on, että jokaisella kansalla on oikeus, expected_answer: Единственный кандидат, который его обходит?
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Russian, expected_answer: Russian
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Mrs Robertson added: "When the girl discovered the photographs on her phone, she called her mother, trembled and cried., expected_answer: Ms Robertson added: "When the girl found the messages on the phone she shouted her mother and was shaking and crying.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Частичная задержка платежей в Китае и небольшие задержки в Германии и Франции вынудили HP уменьшить свою ожидаемую прибы, expected_answer: Отчисления в результате предполагаемого сокращения рабочих мест составят примерно 2,7 млрд. долларов США, начиная с четвертого квартала, говорится в заявлении Hewlett-Packard.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: He matures unevenly., expected_answer: The individual develops irregularly.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Selvitystiedot saatavat olla todennäköisesti hyvin käyttökelpoisia lopullisen päätöksen tekoon., expected_answer: Евроньюс: Ваша партия проголосовала в поддержку соглашения между господином Ципрасом и кредиторами страны.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Согласно заявлению его адвоката, никакой доказательств, что его клиент был в зале на цели сбыта, нет., expected_answer: Несмотря на то, что Максимовичу грозит пожизненный срок за попытку присвоения наркотических веществ в количестве, достаточном для продажи, адвокат Максимовича утверждает, что доказательства того, что последний пытался заполучить всю партию, отсутствуют, и что мужчина мог находиться в кафе без какого-либо умысла.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Tämän perusteella voimme sanoa, että ei ole ollut ongelmaa, koska tämä järjestelmä on perustettu Euroopan unionin s, expected_answer: Среди сторонников Клинтон более половины говорит, что они бы выбрали Байдена вторым, это больше, чем у Сандерса.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Russian, expected_answer: Russian
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Первое, что я помню, это, что нам было очень жаль, что мы не смогли набрать в сумме 30 очков., expected_answer: Игра "Бронкос", вероятно, была хороша, я еще не видел ее, но какой был счет? 16-12?
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Russian, expected_answer: Russian
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
Evaluating:   0%|          | 0/2395 [1:14:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:14:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:04<?, ?item/s]generated_answer: Согласно Хойко Маасу, ожидается, что авторы нетерпимых постов будут получать предупреждения об удалении своих записей., expected_answer: По словам Хайко Мааса, предполагается, что авторы нетолерантных постов будут получать уведомления с указанием причины удаления их записи.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Of course, you all think we all think that £150 a year is a huge sum of money, but for people for whom £150 a year is a lot of money, I'm interested to know why they think it, expected_answer: Of course you all think, we all think, £150 a year is great value, but for people for whom £150 is a lot of money I wonder if they do because they don't consume a lot of the BBC.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Russian, expected_answer: Russian
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Жена Шмидта, Лиз, и брат Шмидта Джефф также присутствовали на похоронах, во время которых университетский хор спел «Золотой утренний з, expected_answer: Жена Шмидта Лиз и брат Джефф Шмидт также присутствовали на церемонии, во время которой университетский хор пел Bright Morning Star и Amazing Grace.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Foreigners also have their Corbines and Najjlas Farajis., expected_answer: Foreigners have their Corbyns and Nigel Farages too.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Coley's team-mate Darren Bent has been given a day off while I'm not too fussed about the Australia trip, and we'll all be back in the same boat at the weekend., expected_answer: Colly's Durham team-mate Ben Stokes is rested for the one-dayers, Root was given a similar break against Australia and I for one have no issue with this.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: The University of Delaware professor, who also is the school's geography and social science department chair, called 911 around 10 a.m., expected_answer: Police in Gautier, Miss. said Lamb, a geography and social science education instructor at Delta State University, called 911 around 10 a.m.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Глава правления JD Sports Питер Коугли сказал, что повышение минимальной заработной платы в Великобритании может привести к "большему доступу к день, expected_answer: Исполнительный директор JD Sports Питер Каугилл говорит, что повышение минимальной зарплаты для британских рабочих означает "больше покупательной способности в карманах потенциальных потребителей".
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Author: Rupert Steiner, Daily Mail City Editor, expected_answer: By Rupert Steiner, Chief City Correspondent for the Daily Mail
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Russian, expected_answer: Russian
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Tämän vuoksi meidän on tarkistettava poliittiset keskustelumme ja uudistettava järjestelmämme., expected_answer: Да, это очень маленький процент, но проблема существует, так же как и вопрос об обеспечении в тюрьмах безопасности для гомосексуалистов, - говорит Алексеев.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Ирина Леонова, живущая в браке с популярным актёром Евгением Цыгановым, родила седьмого ребёнка., expected_answer: Гражданская супруга популярного российского актера Евгения Цыганова Ирина Леонова родила седьмого ребенка.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Russian, expected_answer: Russian
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Президент университета Уильям Лафорж заявил, что он не знал о конфликте между Ламбом и Шмидтом, но "очевидно, что в уме Ламба, expected_answer: Президент университета Уильям Лафорж сообщил, что ему ничего не известно о конфликте между Ламбом и Шмидтом, но "очевидно, у мистера Ламба было что-то на уме".
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Plus you know that vacation is coming soon..., expected_answer: Also, you know that your break is coming up soon...
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Thanks to the efforts of the administration and the support of the regional government, funds were found for the purchase of furniture and equipment, the program "People's Initiatives" also helped., expected_answer: Thanks to the efforts of the administration and assistance from the regional government, the money to purchase furniture and equipment was found, and the People's Initiative also helped out with this.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Вы не можете увидеть их бросаться в ноги, чтобы помочь "Социальным Селиттам", у которых энергия может быть лучше направлена на предотвращение выхода, expected_answer: Тяжело видеть их лезущими из кожи вон, чтобы помочь "селфи-бритам", чья энергия могла бы быть потрачена на предотвращения выхода Шотландии из Великобритании - чего они тоже не хотят, потому что у большинства имеются аналогичные сепаратистские тенденции.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Он имеет ясные связи с Сербией., expected_answer: У последнего имеются связи с Сербией.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Lamb said to the dispatcher, "I need police to come to my house.", expected_answer: Lamb told the dispatcher that police needed to send officers over to his home.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
Evaluating:   0%|          | 0/2395 [1:15:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:15:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:15<?, ?item/s]generated_answer: Однако, если вы хотите сделать это с самого начала, то следуйте нашим простым инструкциям., expected_answer: Все три женщины приходят в лирическое настроение, рассказывая, почему Вуд идеальный мужчина, упоминая при этом о его чувстве юмора, целеустремленности, семейных ценностях, жизнерадостности как о причинах, по которым каждая из них была бы счастлива стать его спутницей.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Как рассказывать своему опыту, фотографии и видео с BBC News?, expected_answer: Как поделиться историями, фотографиями и видео с помощью BBC News
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Они бы лучше отдали больше мячей, но команда выиграла., expected_answer: Я бы лучше пропустил побольше, но команда выиграла.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Juttujen julkaiseminen on hyvin tärkeä tehtävä., expected_answer: Sinun roolisi uutisten syntymisessä on merkittävä.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Finnish, expected_answer: Finnish
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Ennen kuin ampui naisensa ja kolme lastaan kiväärillä, Brian Short ampui itsensä auton keulaan., expected_answer: Ammuttuaan ensiksi haulikolla vaimonsa ja kolme lastaan Brian Short surmasi itsensä talon autotalliin.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The British are using more and more agency labour, Veronique Laury says, expected_answer: Britons are increasingly employing handymen says Veronique Laury
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The violence took place on Tuesday evening in Rupandehi, about 300 kilometres from the capital, Katmandu., expected_answer: The violence occurred Tuesday evening in the district of Rupandehi, about 175 miles west of Kathmandu, the capital.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Fordin uusi nelivetoinen RS:n ylittää sadan kilometrin tuntivauhdissa 4,7 sekuntia, 2,3 litran 350 hevos, expected_answer: Fordin uusi nelivetoinen RS kiihtyy 2,3-litraisen, 350-hevosvoimaisen moottorinsa ansiosta 4,7 sekunnissa nollasta sataan ja huippunopeutta sillä on 266 kilometriä tunnissa.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Palola arvioi, että Suomen teollisuuden keskusliitto EK ei ole valmis keskustelemaan., expected_answer: Palola arvioi, että Elinkeinoelämän keskusliitolla (EK) ei sen sijaan ole valmiutta keskusteluihin.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: We do not have time for monologues., expected_answer: There is no time for monologues.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: That is why you will not be able to get rid of the iPhone programs, expected_answer: This is why you cannot get rid of useless iPhone applications
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Sosiaalidemokraattisen puolueen johtaja Antti Rinne ilmoittaa, että hän on valmis keskustelemaan Sipilän kanssa., expected_answer: SDP:n puheenjohtaja Antti Rinne (sd.) taas ilmoittaa haastavansa Sipilän vuoropuheluun.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Clinton's popularity has fallen in the wake of the CBS News Poll survey carried out last month, and Sanders has risen a little., expected_answer: Since last month's CBS News Poll, Clinton has lost ground among a number of demographic groups, while Sanders has made some gains.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: In my view, he has always seemed to fit the international game of cricket, whether as a player or a coach, and he has the same kind of intelligence as Mahela., expected_answer: I always felt he was born to be involved in international cricket, be it playing or coaching, and like Mahela has nous that can be tapped.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Konstaapeli Lachlan Perhavec ei ollut kovin kiinnostunut sairastuttuaan kylmäksi, joten hän käytti tarkoitu, expected_answer: Konstaapeli Lachlan Perhavecia virkapuvun kastelu ei houkutellut, joten hän valitsi turvallisemman taktiikan – neuvottelun.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Finnish, expected_answer: Finnish
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Apilan Pallosalama kykenee myös osallistumaan etupäässä ja voittaa heitä ajavan ajamisen, lupaa valmentaja., expected_answer: Apilan Pallosalama pystyy kunnossa ollessaan tulemaan myös keulasta, ja lähdemme ajamaan sillä voitosta, valmentaja lupaa.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Helsingin päiväkodit osittain suljettuina., expected_answer: Helsingin päiväkodit osittain kiinni
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Päästään aloittamaan minun sanoin, etten päästä sisään panssarivaunua, koska se oli BMP-3 -jalkaväk, expected_answer: Aloitetaan siitä, että en mennyt sisälle taistelupanssarivaunuun, vaan se oli rynnäkköpanssarivaunu BMP-3.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Finnish, expected_answer: Finnish
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Sen sijaan 350 mailia eteläkaakkoisempana Cape Verde -saarilla sijaitsevassa laajassa matalapaineistossa on 60 prosentin toden, expected_answer: Laajasta matalapaineen alueesta noin 560 kilometrin päässä Cape Verde -saarten eteläisimmistä osista voi 60 prosentin todennäköisyydellä kehittyä trooppinen sykloni seuraavien 48 tunnin kuluessa, tiedotti Yhdysvaltojen kansallinen hurrikaanikeskus (National Hurricane Center) tiistaina.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Rocky sai suuren määrän ääniä, vaikka hän menetti mestaruusottelun., expected_answer: Rocky sai suurta sympatiaa, vaikka lopulta hävisi titteliottelun.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: It was reported on the web site of MTV on Tuesday evening., expected_answer: It was reported by MTV on its website oon Tuesday evening.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Goran sanoo olevansa hyvä mies, joka on todella hyvässä hengessä., expected_answer: Goran korostaa olevansa mukava ja hyväsydäminen mies.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
Evaluating:   0%|          | 0/2395 [1:16:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:16:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:26<?, ?item/s]generated_answer: Niinistö: Syyrian tilanne kuvaa Ukrainaa ja itämeren aluetta., expected_answer: Niinistö: Syyrian tilanne heijastuu Ukrainaan ja Itämeren alueelle
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: It is some 200 metres from the border, so it would be effective, he says., expected_answer: The location is about 200 metres from the border, so it would be functional also in that sense, says Nousiainen.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Arsenal is clearly the favourite to take over the F group but Maksimir Stadium in Zagreb is one of the most frightening in Europe., expected_answer: Although Arsenal are clear favourites to progress through Group F, the Maksimir stadium in Zagreb is among Europe's most intimidating.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Vähemmän tukikäyttöä ja suurempi bubbeli, expected_answer: Suurempi kupla ja enemmän velkaa
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Jotkut ovat yrittäneet luokitella hänet flip-flopperiksi., expected_answer: Jotkut ovat yrittäneet leimata hänet tuuliviiriksi.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: You should remember that you are still guests in a foreign land and that you will remain so for a long time., expected_answer: You should remember you are still in a foreign country and you will be guests here for quite some time.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Fedin poliittiset päättäjät miettelevät yhä kovempaa kasvua, jotta maailman talous saadaan jälleen kasvamaan., expected_answer: Keskuspankin päättäjille markkinoiden myllerrys on lisätekijä monimutkaisessa yhtälössä, joka kertoo koska korkotasoa tulee nostaa.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Metalworkers got a 16% pay rise., expected_answer: The metal workers got a 16 percent raise.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Tigers were awarded three runs in the first two innings against the right-handed bowler who had just returned to the field after recovering from an injury. The player had been out of action for a month with a back injury., expected_answer: The Tigers posted three runs in the first two innings against the veteran right-hander, who came off the disabled list before the game after missing more than a month because of lower back inflammation.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Fedin ensimmäinen kerta, jolloin se nostaa jäsenvaltioiden pankkien keskuspankin korkoa, oli kesäkuussa 20, expected_answer: Edellisen kerran Fed nosti niin sanottua Fed funds -ohjauskorkoaan vuoden 2006 kesäkuussa.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The findings of Premier Injuries Ltd, which examined the injury history of Wilshere, show that he has had 23 different injuries since he made his debut six years ago., expected_answer: Research by Premier Injuries Ltd records 23 different Wilshere ailments since he made his debut six years ago.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Pojat nousivat tavallisen katon päälle, toinen ei päässyt laskemaan, ja ystävät lähtivät karkuun., expected_answer: Pojat kiipesivät katolle, yksi ei päässyt alas, kaverit livistivät paikalta
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Finnish, expected_answer: Finnish
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: If you are ever on the receiving end of racism, then you should blame yourselves., expected_answer: If they end up as target for someone's racism, you have to blame yourselves for that.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Mikko's wife Nina Mikkonen sells the equipment that were once the state-of-the-art tools for professionals on the Huuto.net site., expected_answer: Mikkonen's partner Nina Mikkonen is selling the equipment, once cutting-edge among the professionals of the field, at Huuto.net.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Amerikan ninjatodistajien kisa on saanut jatkoa, ja se alkaa kuvata kesällä 2016., expected_answer: American Ninja Warrior palaa kahdeksannelle kaudelle, jonka kuvaukset aloitetaan keväällä 2016.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Tällä kertaa 6. syyskuuta mennessä on saatu täysin erillisiä yksin tulleita alle 18-vuotiasta lasta koskevia turvapa, expected_answer: Tänä vuonna 6.9. mennessä meille on tullut yhteensä 586 yksin tulleen alaikäisen turvapaikkahakemusta.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: That is a reduction of about 130 staff., expected_answer: In practice, this means that there is a need to cut about 130 employees.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: You are, of course, always the same man. Although you are wearing the costume of a top designer for the first time this season, you are still castigating., expected_answer: Even if you had posed in top designers’ outfits during the previous season, the new season always starts with castings.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Puolivuotiskertomuksen mukaan vuoden 2005 keskimääräinen palkkataso nousti 2,3 prosenttia ja tulevaisu, expected_answer: Punnan arvo nousee Iso-Britannian palkkakasvun kiihtyessä
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Olen tehnyt 50 ostotarjousta viime vuosina., expected_answer: Minulle on tehty yrityksestä 50 ostotarjousta viimeisten kymmenen vuoden aikana.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Kolmas aihe käsitteli ainoastaan entisen komission puheenjohtajan José Manuel Barroson mainintoa., expected_answer: Kolmannessa aiheessa oli vain sitaatti entiseltä Euroopan komission puheenjohtajalta Jose Manuel Barrosolta.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: McInnes says: “There is no team which has won anything, whether it is a league or a cup, which has not also won games in this way.”, expected_answer: McInnes said: "There's not a team out there who has won anything, whether it's cups or leagues, who haven't won games like that."
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Sarah on todella maailmanmallisia, hän on niin paljon mielenkiintoinen, että haluaisin pitää hänet sängyssäni., expected_answer: ”Sarah on todella maanläheinen, hänen seurassaan on hauska olla”, Markoski lisäsi.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Member after the merger, expected_answer: Member after a merger
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
Evaluating:   0%|          | 0/2395 [1:17:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:17:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:32<?, ?item/s]generated_answer: Kristiano Ronaldo teki La Ligan viikonlopun aikana viisi maalia ja jatkoi myös Eurooppa-liigassa., expected_answer: Cristiano Ronaldo iski viisi maalia Espanjan liigassa viikonloppuna ja jatkoi tehtailuaan myös Mestarien liigassa.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Toiset taksikuskit, expected_answer: Ihan tavallinen taksikuski
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Finnish, expected_answer: Finnish
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Apoi, trebuie să alege unul dintre cele patru filme disponibile pe platformă, să descărca textele pe care copilul va citi și apoi copilul va fi înregistrat, expected_answer: Ulterior, trebuie să aleagă unul dintre cele patru filme disponibile pe platformă, să descarce textele pe care copilul urmează să le citească iar apoi, copilul se va înregistra interpretând propria versiune de dublaj.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: În consecinţă, am ajuns la o transiţie de la desperare la un punct de vedere mai practic, dar încă rămâne scopul., expected_answer: Deci trecem de la disperarea intrarii la o pozitie mai pragmatica, dar obiectivul ramane.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: 55 per cent of Democratic voters consider Hillary Clinton to be the candidate with the best chance of winning the general election; but that figure has dropped from 78 per cent last month., expected_answer: Fifty-five percent of Democratic voters see Clinton as the candidate with the best chance of winning the general election; however that figure is down from 78 percent last month.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Hopes he will be able to play again this season., expected_answer: Sper să poată juca din nou sezonul acesta.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Immediately after impact, the escorts called for another transport to take over the detainees., expected_answer: Immediately after the impact, the prisoners' escort called for another transport to take the prisoners.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Romanian, expected_answer: Romanian
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: He has issued a very simple and very timely message: try to find a solution that does not threaten the party., expected_answer: He sent a very simple and timely message under current circumstances: try to find a solution in order not to jeopardize the party.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Romanian, expected_answer: Romanian
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Jucătorul de la Steaua dă lecţii lui Gigi Becali: Decizia pe care a luat-o, expected_answer: Un fotbalist de la Steaua ii da lectii lui Gigi Becali: Ce decizie a luat
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Di Maria scored in less than four minutes from the start of his debut Champions League match for Paris Saint-Germain, putting the French champions in front despite missing a series of chances before Cavani's goal in the 61st, expected_answer: Di Maria scored less than four minutes into his Champions League debut as a PSG player to set the French champions on their way, but they missed a succession of opportunities before finally extending their advantage when Cavani headed home in the 61st minute.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Debra Aho Williamson, social media analyst at eMarketer, said it is hard to imagine a single button can transmit such a complex range of negative emotions., expected_answer: Debra Aho Williamson, an eMarketer social media analyst, said it is hard to imagine that one button can transmit a comprehensive range of negative emotions.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: The prime minister continues his exchange of replies with Hungarian authorities., expected_answer: The Prime Minister continuous the verbal disagreement with the Hungarian authorities.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Există puţină noveţă în faptul că IT este în dezvoltare permanentă în ţară., expected_answer: Nu mai este deloc o noutate ca zona IT este intr-o continua ascensiune în tara.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Recent, o banca prominentă din România a angajat un actor pentru a-l reprezenta într-un anunţ video., expected_answer: Iar, de curând, o cunoscută bancă din România a angajat un actor care să-l joace într-un clip publicitar.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Ei ole ollut keskustelua maiden välistä yhteistyötä varten, vaan keskustelua sellaisten maiden kanssa, joiden kanssa meid, expected_answer: Diseară voi merge acasă și voi dormi liniștit.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Colegiul de lider al MDC, Innocent Gonese, a declarat că zece politicieni din opoziție au primit mesaje de text pe telefoanele lor mobilă, prin care li, expected_answer: Șeful grupului parlamentar Movement for Democratic Change (MDC), Innocent Gonese, a declarat că șapte politicieni din opoziție au primit mesaje text pe telefoanele mobile, fiind avertizați să nu perturbe discursul domnului Mugabe.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Jucătorii de rugby români au debutul lor pe 23 septembrie împotriva Franței, expected_answer: Rugbiștii români debutează pe 23 septembrie, contra Franței
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: But now it is stagnating a little and you can see a decline (in growth)., expected_answer: But now that is plateauing a bit, you might see (growth) fall away.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: The last Al Qaeda leader, Osama bin Laden, was a "disinherited" son, disowned by his family in the 1990s., expected_answer: Al Qaida's late leader Osama bin Laden was a renegade son disowned by the family in the 1990s.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Ciclistul a fost transportat la Spitalul Regal de la Melbourne cu răni grave după ce a fost lovit de un automobil pe autostrada Murray Valley, într-o dimineaţă de, expected_answer: Biciclistul a fost transportat cu elicopterul la Royal Melbourne Hospital, fiind rănit grav după ce a fost lovit sâmbătă dimineață de o mașină pe autostrada Murray Valley.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: A movement of public sentiment is taking place in both directions., expected_answer: It's a wave of public emotion that goes both ways.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
Evaluating:   0%|          | 0/2395 [1:18:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:18:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:36<?, ?item/s]generated_answer: As a result of the investigation, it emerged that the representatives of a company specialising in security services had created a criminal circuit, formed by a number of commercial companies, through which fictitious transactions had been recorded., expected_answer: The investigation revealed that, in order to evade the payment of taxes to the state budget, representatives of a company specialising in providing security services have created a criminal circuit, formed of several companies, through which fictitious transactions were performed.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Glencore a anunţat în seara trecută vânzarea acţionarilor cu un valoare de 2,5 miliarde de dolari ca parte din planurile sale de reducere, expected_answer: Glencore a dezvăluit vânzarea de acțiuni în valoare de 2,5 miliarde dolari ca parte din planuri mai ample pentru a-și acoperi aproape o treime din datoria de 30 miliarde de dolari.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Potrivit statisticilor făcute după 100 de ediţii ale Salonului Profesional de Carieră, care au fost organizate până acum, majoritatea societăţ, expected_answer: Potrivit statisticilor realizate în urma celor 100 de editii de pana acum ale Targului de Cariere, cele mai multe companii sunt interesate, pe langa recrutarea efectiva, sa isi dezvolte un brand de angajator puternic în randul tinerilor: 97% dintre reprezentantii lor au declarat ca doresc sa revina la editiile viitoare, în timp ce 94% declara ca recomanda TdC ca solutie de recrutare și employer branding.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Doresc jucătorilor succes și cred că vom face tot ceea ce putem pentru a face bine la acest eveniment., expected_answer: Le doresc succes sportivilor și am convingerea că vom fi la înățimea evenimentului.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Romanian, expected_answer: Romanian
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Cu toate acestea, echipa de cercetare a comparat, de asemenea, rezultatele mediane cu cele două tipuri de chirurgie., expected_answer: Echipa de cercetare a comparat de asemenea rezultatele medii asociate cu cele două tipuri de intervenție chirurgicală.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Romanian, expected_answer: Romanian
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Olemme jo järjestäneet kaksi edellistä keskustelua, jotka on kuitenkin johtanut vain vähäistä vastustusta., expected_answer: De câteva decenii, familia Binladin are o relație apropiată cu familia regală a Arabiei Saudite și derulează proiecte majore de construcție.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: După această experienţă, soţia şi eu nu vrem să ne punem picioarele într-o astfel de localitate., expected_answer: Dupa experienta traita nici eu nici sotia mea nu mai vrem sa mai calcam vreodata în orasul dumneavoastra.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Moeen Ali se dezvoltă ca un spinner cu mâna, iar Adil Rashid, chiar dacă nu este un factor necunoscut la nivel de Test, reprezintă o op, expected_answer: Moeen Ali evoluează ca spinner iar Adil Rashid, chiar dacă este necunoscut la nivelul de testare, reprezintă o opțiune pentru atac.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: Career Fair, 100 editions, expected_answer: Career Fair, 100 editions
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: O cercetare publicată de Consortiul de comerţ britanic a arătat că aproximativ £ 1 din fiecare £ 5 se folosea pe Internet., expected_answer: Un studiu publicat de British Retail Consortium a determinat că cel puțin 1 £ din fiecare 5 £ este cheltuită online.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: I remember that, in 2010, St George was criticised for being a boring team while Wayne said that he didn't care how black his nails were., expected_answer: I remember in 2010 St George was criticised a lot for being a boring team and Wayne said he didn't give a rat's arse.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Un nou sondaj CBS/NYT din luni a arătat că doar aproximativ jumătate din votanții care susțin Trump declară că au pus în mișcare votul., expected_answer: Un nou sondaj realizat marți de CBS/NYT arată că peste jumătate dintre alegătorii care îl susțin pe Trump declară că nu își schimbă opțiunea de vot.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Cele mai multe lucruri pe care le-am învăţat pot fi redactate în opt reguli simple., expected_answer: Majoritatea lucrurilor pe care le-am învățat pot fi rezumate sub forma a opt reguli simple.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Sunt chiar mai mulţi care nu au fost încă integraţi, creând probleme majore sociale în Franţa, Germania şi Marea Britanie., expected_answer: A ramas o parte neintegrata care creeaza probleme sociale majore în Franta, în Germania, în Marea Britanie.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: I think Nick a crescut rapid în faţa publicului, cum arată, de exemplu, Federer şi Murray, şi este crescut în ochii publicului şi a făcut unele gre, expected_answer: Și cred că Nick a urcat foarte repede, așa cum au afirmat oameni precum Federer și Murray, el se maturizează sub privirile publicului și a făcut niște greșeli îngrozitoare și merită să fie criticat, însă noi încercăm să îl susținem, încercăm să îl ajutăm să înțeleagă consecințele faptelor lui și cred că are nevoie de un timp în care nu se află în centrul atenției pentru a putea să reflecteze, lucru bun atât pentru echipă cât și pentru el.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Victor Piturca quit the Romanian national team in the autumn of last year, even though the side had good results in the Euro 2016 qualifiers., expected_answer: Victor Piturca resigned from the Romanian national team last fall, although the team perform well in the Euro 2016 qualifiers.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Compania de construcţii este deținută de familia fostului lider al reţelei teroriste Al-Qaida, Osama bin Laden., expected_answer: Firma de constructii este detinuta de familia fostului lider al retelei teroriste Al-Qaida, Osama bin Laden.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Romanian, expected_answer: Romanian
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: That's not possible in the face of such a wave, because some countries don't face it., expected_answer: We cannot continue like this when we are faced with this migration wave, because some countries cannot handle it.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Romanian, expected_answer: Romanian
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
Evaluating:   0%|          | 0/2395 [1:19:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:42<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:19:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:39<?, ?item/s]generated_answer: FedEx a raportat rezultatele de la nivel de afaceri deficite pentru ultimul trimestru, iar marele grup de transport a redus prognozaa sa de profit anual pentru, expected_answer: FedEx a declarat rezultate dezamăgitoare pentru ultimul trimestru, gigantul din domeniul livrărilor reducând estimările profitului pentru tot anul ca urmare a cererii scăzute pentru servicii de transport și a costurilor crescute pentru divizia sa de transport terestru.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: În motivarea sa, judecătorul își exprimă opiniile asupra reacţiei defiante a acestora, dar şi a celor care i-au susţinut,, expected_answer: În motivare judecătorul vorbește despre reacția sfidătoare a inculpaților, dar și a celor care i-au susținut, precizând că astfel de atitudini creează un puternic sentiment de indignare în rândul opiniei publice.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Ed Miliband knew his enemies., expected_answer: For all his foolishness Ed Miliband knew who his enemies were.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: The Democratic candidates or possible candidates are doing well on a number of key characteristics with respect to their primary voters., expected_answer: The Democratic candidates, or potential candidates, perform well on some key characteristics among their party's primary voters.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: Romanian, expected_answer: Romanian
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Concesionarul va fi obligat să folosească clădirea în mod continuu şi consistent şi să acopere toate costurile de reabilitare, conform proiectului tehn, expected_answer: Concesionarul va trebuie să exploateze continuu și în permanență clădirea și să acopere în întregime costurile de reabilitare a imobilului, în conformitate cu proiectul tehnic ce urmează a fi întocmit.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt16_translate_tren']
generated_answer: În următoarele decenii, depopularea, sărăcia, schimbările climatice, depletarea resurselor, etc. vor spinge milioane de migratori des, expected_answer: În următoarele decenii, suprapopularea, sărăcia, schimbarea climei, epuizarea resurselor etc. vor împinge milioane de migranți disperați, din Asia și mai ales din Africa, spre o viață mai bună.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Damage was limited, although water caused some damage., expected_answer: The damage was fairly limited all in all, although the water caused some harm.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: "We do not want to pay that price", she said., expected_answer: "We don't want to charge that," she said.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: Jump spectaculaire avec un parachute de type wingsuit sur Bogota, expected_answer: Spectaculaire saut en "wingsuit" au-dessus de Bogota
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Le monumental "Lieux de mémoire" (places of memory), dont son nom est associé, a également contribué à cette image confuse., expected_answer: A cette image incertaine le monument des "Lieux de mémoire", auquel il a attaché son nom, a aussi contribué.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Des centaines de soldats et de policiers ont gardé la mairie quand Morsi est arrivé dans une petite délégation à 11 heures locales., expected_answer: Des centaines de soldats et policiers gardaient le bâtiment lorsque M. Morsi est arrivé peu après 11 heures, heure locale, suivi d'un petit convoi.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: In 2012, the Canadian border services agents in the Quebec region seized a total of 1653 narcotics., expected_answer: In 2012 the Border Services Agency for the province of Quebec made 1,653 seizures of narcotics.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: Une grande demeure du XVIIIe siècle, construite en 1850, à Québec, a été consumée par les flammes le vendredi après-midi., expected_answer: Une maison historique construite en 1850 été la proie des flammes dans le Vieux-Québec vendredi midi.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: Je n'ai pas l'impression d'avoir tout à fait prévu., expected_answer: Je ne sais pas si c'est ce à quoi je m'attendais.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Les jeunes filles qui fleurissent tôt ont besoin de se rassurer en savoir que, même si le processus se produit avant la date prévue, il s'agit d'une partie normale de la vie, expected_answer: Les filles dont la puberté est précoce doivent être rassurées sur le fait que, même lorsque ça arrive plus tôt que prévu, le processus fait partie de la vie.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: Aux APHP, les autorités préfèrent employer le terme "transformation" ou "change en continuité" au terme "fermeture"., expected_answer: Même si, à l'APHP, on préfère employer le terme de "transformation" ou de "changement dans la continuité".
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: Vivre ensemble est la mission à relever de la Commission scolaire Marguerite-Bourgeoys (CSMB)., expected_answer: Vivre ensemble en français, le défi de la commission scolaire Marguerite-Bourgeoys
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Ranskalaisten ja saksalaisten joukkojen välillä on aina ollut erimielisyyksiä, jotka ovat johtaneet kuuluisiin sotil, expected_answer: À travers l’Europe, les partis qui s'opposent à l'UE ou qui militent pour l'abandon de l'euro en tant que devise commune, gagnent du terrain.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Nous habillons nos chiens l'année dernière et à mon étonnement, nous n'étions pas seuls., expected_answer: Nous avons déguisé nos chiens l'année dernière et, à mon grand étonnement, ils n'étaient pas les seuls.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: Finnish, expected_answer: French
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: At least four people would be injured., expected_answer: Reports say at least four people were slightly injured.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: Les opérations ont lieu dans une école, une mairie ou une maison; après l'opération, les patients se lèvent et marchent vers l'espace de récupération pour laisser place à la procha, expected_answer: Les opérations sont en général pratiquées dans une école, une mairie ou une maison ; après l'intervention, le patient se lève et se rend dans la salle de réveil pour laisser sa place à la personne suivante.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
Evaluating:   0%|          | 0/2395 [1:20:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:20:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:41<?, ?item/s]generated_answer: L’après-midi, les sites de suivi des serveurs ont noté que le site de la NSA était inaccessible pendant au moins six heures, et le site continue d’être inaccessible pour certains utilisateurs., expected_answer: Plus tôt ce soir, les trackers de serveurs en ligne ont noté que le site de la NSA avait été en panne pendant au moins 6 heures, et certains utilisateurs ne peuvent toujours pas accéder au site.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: Following the departure of all the industries (big water consumers) and the great decline in the population, water consumption has considerably decreased everywhere on the territory., expected_answer: Following the departure of all the industries (major consumers of water) and the big decline in the population, the use of water throughout the district has considerably reduced.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: Ensuite, la colline de Rumyoni restera seule., expected_answer: Il ne restera plus que la colline de Runyonyi.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The National Security Agency, working in the shadows, said Friday that a bug was to blame for the outage of its public website for a few hours, and not hackers as some had claimed online., expected_answer: The shadowy National Security Agency said late Friday that it was a glitch that brought down its public website for a few hours, not hackers as some claimed online.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: Il ne respecte pas les conditions de sa libération sous caution., expected_answer: Il continue à enfreindre les conditions de sa mise en liberté sous caution.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: L'idée est de repeindre tous les feux de circulation de Bruxelles, à un coût estimé à un million d'euros., expected_answer: L'idée est, à terme, de repeindre tous les feux de signalisation bruxellois, pour un coût estimé d'environ un million d'euros.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: L'Aviation civile a commencé à limiter l'utilisation des appareils électroniques par les passagers en 1966 en réponse aux rapports d'interférence avec l'équipement de, expected_answer: La FAA a commencé à limiter l'utilisation des appareils électroniques en 1996 suite aux rapports sur la présence d'interférences avec les instruments de navigation et de communication lorsque les passagers transportaient des radios FM, le gadget high-tech d'alors.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: They want the government to give priority to new commercial links with countries such as China, India and Brazil rather than getting bogged down in the long and arduous process of European institutional reform., expected_answer: They want to see the Government prioritise new trading links with the likes of China, India and Brazil, rather than getting bogged down in the long and arduous process of reforming the EU's arcane institutions.
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: Miller added that the direct link to Bulgaria, a member of the European Union, means that the geopolitical risks associated with transit countries are eliminated "forever.", expected_answer: Miller said the direct connection to Bulgaria, a member of the European Union, means geopolitical risks associated with transit countries are eliminated "forever."
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: La douleur immense qui m'envahit a bien écarté, bien entendu, mais il est encore très présent., expected_answer: La peine immense qui m'a alors envahie s'est bien sûr atténuée mais il est toujours près de moi.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: French, expected_answer: French
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: The experts think that obesity could be a trigger for precocious puberty., expected_answer: Experts think the obesity epidemic might be one trigger of early puberty
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: Je ne pouvais pas croire qu'elle était là., expected_answer: Je n'ai d'abord pas cru qu'elle était là-haut.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Vuonna 2002 otettiin käyttöön Euroopan unionin käytännön yhteensovittaminen -järjestelmä, jossa kaikki jäsenval, expected_answer: Pourquoi une Écosse indépendante devrait-elle suivre les instructions de l'Europe, en fait ?
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: I would ask, for example, about the definition of resilience., expected_answer: For example, I think about the definition of resilience.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Dans l'action initiale, la Congrégation du Saint-Sacrement a accepté de conclure hors de la justice avant que les audiences préliminaires ne soient menées., expected_answer: Dans le cas du premier recours, la congrégation de Sainte-Croix avait accepté de régler à l'amiable avant que des auditions soient menées sur le fond.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Les clients empruntent des biens qu'ils possèdent déjà, et le monétisation de biens personnels ne conduit pas à augmenter la dette des ménages, affirme-t-elle., expected_answer: « Les clients hypothèquent des biens qu'ils possèdent déjà, et le fait de monétiser leurs biens personnels n'augmente pas l'endettement des ménages », dit-elle.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: «C’est pourquoi, nous développons nos projets de façon qu’ils puissent s’identifier à tout cela», précise la présidente de Vision Diversité, Aïda Kamar., expected_answer: "Donc, on crée des projets de façon à ce qu'ils s'identifient à tout ça ", explique la présidente de Vision diversité, Aïda Kamar.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: En ce qui concerne les attitudes des Américains, la semaine dernière, le taux d'approbation de Barack Obama s'est abaissé sous la barre des 45 %, ce, expected_answer: Pourtant, alors que l'indice d'opinions favorables a plongé sous les 45 % cette semaine, il est encore plus difficile de revenir à l'année 2008 à travers ce livre.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Les données présentées à la dernière session du Parlement indiquent que, parmi les 1 218 militaires démissionnés pour raisons médicales, 199 n'avaient pas atteint le minimum, expected_answer: Des données présentées l'an dernier au Parlement indiquent que parmi les 1218 soldats libérés pour des raisons médicales, 199 n'avaient pas atteint la durée de service requise pour obtenir des prestations de retraite.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: Finnish, expected_answer: French
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
Evaluating:   0%|          | 0/2395 [1:21:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:21:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:12<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:30<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:44<?, ?item/s]generated_answer: Il ne peut pas justifier les conclusions d'un rapport qui dit que les efforts du gouvernement à cacher les médias sont les plus agressifs ... depuis la présidence de Nixon., expected_answer: Elle ne peut pas justifier les conclusions d'un rapport qui dit que les efforts de la Maison-Blanche pour réduire les médias au silence sont les « plus agressives... depuis l'administration de Nixon ».
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: L’austérité imposée par Berlin et la Banque centrale européenne, associée à la tenue de la monnaie unique, a conduit de nombreux Européens à penser que le projet européen a marché, expected_answer: L'austérité imposée par Berlin et la Banque centrale européenne, associée au carcan pesant sur les économies nationales par l'intermédiaire de l'adhésion à la monnaie unique, a conduit de nombreuses personnes à penser que le Projet Europe est allé trop loin.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: His salary is only a symbolic dollar., expected_answer: His fixed salary is a nominal $1.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Nous sommes ravis de travailler en partenariat avec le gouvernement britannique afin d'examiner les options pour faire venir le train à grande vitesse en Écosse, créer des avantages pour tous et compl, expected_answer: « Nous sommes donc excités à l'idée de travailler en partenariat avec le gouvernement britannique afin d'examiner les options visant à amener le réseau de train à grande vitesse jusqu'en Écosse, créant un avantage pour tous et complétant la ligne Glasgow-Édimbourg que le gouvernement écossais est déjà en train de planifier.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: «Ils ont absolument l’impression que leur fils a été assassiné», a déclaré à FoxNews.com Benjamin Crump, un avocat représentant Kenneth et Jacquelyn Johnson., expected_answer: « Ils sont absolument certains que leur fils a été assassiné », a déclaré Benjamin Crump, l'avocat représentant Kenneth et Jacquelyn Johnson, sur FoxNews.com.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: On oltava huomio kiinnittää erityistä huomiota siihen, että sääntelyn tarkoituksena ei ole tehdä kaikilta ihmis, expected_answer: Après avoir jeté l'éponge avec fracas en janvier pour la reprise partielle du site Goodyear d'Amiens-Nord promis à la fermeture, Maurice Taylor, le PDG du pneumaticien américain Titan, se déclare, aujourd'hui, prêt à sauver 333 emplois sur les 1 137 que compte l'usine.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: Alors que le nombre de clients Cogeco Câble s'est accru de 5 546 pour l'exercice 2013,, expected_answer: Toutefois, pour l'année financière 2013, le nombre de clients de Cogeco Câble est en hausse 5546.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: Other states are hoping to sell the concept to people who are sceptical by allowing the machines to do more, rather than less., expected_answer: Other places are hoping to sell the concept to a wary public by having the devices do more, not less.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Vielä kerran: teidän on annettava kunnioitettavat ja kohtelut jäsenvaltioiden ja EU:n sisäisiä tapahtumia koskevat, expected_answer: Il se rend en uniforme nazi au supermarché, avant d'en être chassé
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt14_enfr']
generated_answer: The single market has caused general discontent among businesses, with companies saying that the cost of complying with EU regulations is disproportionate to the benefits of participating in the European Union – 40 per cent of large companies, expected_answer: There was general discontent with the Single Market, with businesses saying that the costs of Brussels regulation now outweighed the benefits of being part of Europe's trading area - even 40 per cent of large businesses, traditionally the most pro-European of companies, agreed.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Kiinteistöjen käyttöön liittyvässä selvityksessä käsiteltiin myös kiinteistöjen käyttöä, kuten kaupallisia, expected_answer: Les passagers qui essayaient d'éviter ces frais mettaient autant de choses qu'ils pouvaient dans les bagages à main rangés dans les compartiments supérieurs, ainsi il n'y avait souvent plus de place dans ces compartiments.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Fils de fonctionnaire des douanes, il est né le 24 octobre 1953 à La Ferté-Saint-Aubin, où il a passé toute son enfance., expected_answer: L'homme au visage ouvert, crâne dégarni et lunettes d'intellectuel, né le 24 octobre 1953 à la Ferté-Saint-Aubin est titulaire d'un CAP de pâtisserie.
['Styxxxx/llama2_7b_lora-wmt14_enfr', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: « Mon mari et moi avons acheté une maison il y a quelques semaines, et tous mes gains sont donc bloqués là-dedans, » explique Mrs Amirthalinga., expected_answer: « Mon mari et moi venons d'acheter une maison donc tout mon argent est parti dedans », déclare Mme Amirthalinga.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Russian, expected_answer: Czech
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: "The Alps are still very important.", expected_answer: "Albums still matter," he said.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: We need to restrain the use of force., expected_answer: We have to reduce the use of force.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Mám čtyři děti, jsem špatným objektem pro zaměstnavatele., expected_answer: Se čtyřmi dětmi nejsem pro zaměstnavatele zrovna terno.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Tohle jsme spravedliví, upřímní lidé, nikoli nepřátelé lidu, jako jsem byl v očích komandérky nadučitele., expected_answer: To je práce pro poctivé a slušné lidi, ne pro nepřítele lidu, jakým jsem v očích soudruha náčelníka byl.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Umělecky se vyrovnal mně i díky tomu, že jsem mu předal tři nové písně., expected_answer: Také mne štvalo to jeho povýšené tykání.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: To je nic velkého., expected_answer: Nejedná se o nic zvláštního.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Jsem přesvědčený, že pokud se do budoucna podaří příslušníky nelegálních uprchlických skupin integrovat, tak mohou být pro nás, expected_answer: Je to pro naši zemi velká výzva, ale věřím, že pokud se podaří běžence integrovat, můžou se pro nás stát přínosem, řekl.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: "It's really the best travel documentary that's ever been filmed.", expected_answer: "It really is for me," said Spielberg, "inarguably the greatest time travel movie ever put on film."
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
Evaluating:   0%|          | 0/2395 [1:22:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:22:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:08<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:51<?, ?item/s]generated_answer: To se lišit od konce července, kdy čtyři z deseti občanů stáhli své peníze z Jeba Busha., expected_answer: To je změna z pozdního července, kdy čtyři z 10 sázeli své peníze na Jeba Bushe.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Näiden rahoitusten antaminen on käytännössä pahinta mahdollista., expected_answer: Musíme doškolovat zaměstnance, dovybavovat zařízení a znovu celý proces certifikovat, dodává Dubský.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: He then named several other players from the Czech club but didn't mention David Lafata, the league's all-time leading goal scorer and captain of Sparta Prague., expected_answer: Goian did not mention any other Sparta players by name, and was then asked directly if he knew about David Lafata, Sparta captain and top scorer in the history of the Czech league.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: But we were not selected for these major projects., expected_answer: Without Latecoere we wouldn't have won those big orders ourselves.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: He made that point in 2010, now he wants everyone to play his style of footy - not every team has two halves like Anthony Milford and Ben Hunt so they can play like that., expected_answer: Tento názor řekl v roce 2010 a nyní chce, aby všichni týmy hráli jeho styl fotbalu - ale ne každý tým má dva záložníky jako je Anthony Milford a Ben Hunt, takže takový styl hrát nemohou.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Jednoho z nich zavřeli v kápě, a zbylých deset třináct zahubili., expected_answer: Brzy zmizeli.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Bariatric surgery could be beneficial for people with mild obesity, expected_answer: For mildly obese diabetics, weight loss surgery may be helpful
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: As Deutsche Bank points out, there have been only two occasions in the last 50 years when real GDP growth has been less than 4.5% a year., expected_answer: According to Deutsche Bank, in the 118 rate hikes since 1950, only twice has nominal year over year GDP been below 4.5 percent.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Tämä on ollut tärkeää, koska se on koskettanut kaikkia kansalaisia., expected_answer: Nhaijah Russel, šestiletá dívka, která nedávno ve škole pozřela až čtyři loky sanitačního činidla s vůní jahody a byla odvezena kvůli léčbě na pohotovost.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Lamb, who co-starred with Prentiss when the two appeared together at the summer festival three years ago., expected_answer: Lamb met Prentiss when he and Abigail both performed at a summer fair three years ago.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Kunhan voimme saada yhteyden Euroopan parlamenttiin, joka on valmis tukemaan tätä hanketta., expected_answer: To může být peklo pro někoho, kdo se potřebuje nabít.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: McKee a Capewell řekli, že "nejsou důkazy, že elektronické cigarety slouží jako cesta do kouření pro děti nebo nikoho jiného,, expected_answer: McKee a Capewell řekli, že tvrzení PHE, že "zatím neexistuje žádný důkaz, že by e-cigarety působily jako cesta ke kouření pro děti nebo nekuřáky," bylo předčasné.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: If the battery is low, Apple won't let you install the update because a shutdown during the process could cause an update error., expected_answer: If the charge is too low, Apple won't let the update go ahead, since the phone dying halfway through could lead to the update breaking.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Vidím v Evitě Moniku a to byl obrovský inspirace pro mne., expected_answer: Monču jsem viděla v Evitě třikrát a rozhodně to pro mě bylo inspirativní.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Na druhé straně to, že platíce těchto organizací může být vzrůst požadované platů, zvýší riziko, že tyto organizace budou kom, expected_answer: "Na druhé straně však tento fakt zvyšuje riziko, že těžební organizace budou zvýšení úhrad kompenzovat snahou o snížení svých provozních výdajů, což by především znamenalo redukci počtu zaměstnanců," připouští vláda.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: In the Letňany area in Prague, Letov is producing complete doors for Airbus A320., expected_answer: Previously known as Letov, the company produces complete door systems for the Airbus A320 at its complex in the Letňany district of Prague.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Olemme myös huolestuneita siitä, että tämän jälkeen yhä useampi valtio on pyrkinyt muuttamaan oikeudellisia periaatteita,, expected_answer: Výzkum publikovaný asociací British Retail Consortium zjistil, že pouze £1 z každých £5 byla utracena online.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: • 1 mandarinka • 1 růžička • 1 čepice špenátu • 1 čepice zelené zelí • 3 lžičky vinné oleje, expected_answer: K němu potřebujete: • 1 ks broskve • 1 svazek rukoly • 1 šálek nakrájené okurky • 1 šálek směsi salátových listů • 3 polévkové lžíce hroznového oleje
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Donald Trump and Ben Carson have garnered about half of Republican support so far, mainly because they are outsiders., expected_answer: Donald Trump and Ben Carson now account for roughly half of the support from Republican voters, largely due to their outsider status.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Ačkoliv inflace pokračovala pod nadprůměrnou úrokovou míru centrálního banky, Fed policymakerovi tvrdil, že důsledkem vysokého, expected_answer: A i když inflace i nadále probíhá pod ročním 2% cílem centrální banky, politici Fed tvrdí, že hlavním důvodem byl dočasný účinek výrazně nižších cen ropy.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Liu Yunshan and Zhang Gaoli, the second- and third-ranked members of the Politburo, were also at the meeting., expected_answer: The meeting was also attended by Premier Li Keqiang, and senior leaders Liu Yunshan and Zhang Gaoli, according to a statement released after the meeting.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Russian, expected_answer: Czech
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: I think it's important to emphasize that this is not a dry, technical legal discussion., expected_answer: He had bitten his tongue about the spy allegations for 18 months and didn't want it "to look like sour grapes."
Evaluating:   0%|          | 0/2395 [1:23:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:23:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:10<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:26<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:24:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:18<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:25<?, ?item/s]['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Näin ollen, tämän vuoden jatkuminen tarkoittaa, että meidän on oltava valmis ottamaan vastuun, jotta voimme edistää, expected_answer: Žoviální, nafoukaný, autoritářský, arogantní, jak se mu to momentálně hodilo.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Russian, expected_answer: Czech
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Deset z posledních 11 národních průzkumů ukázalo, že Donald Trumpova vedení je dvakrát tak velké, a někteří začínají s vážnější, expected_answer: 10 z poslední 11 národních průzkumů ukazují, že je Donald Trump ve vedení o dvojciferné číslo, a někteří lidé se začínají vážně ptát, co to znamená pro nominační šance tohoto magnáta z oblasti nemovitostí.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: The resolution of the European Parliament condemns "the unprecedented repression against civil society in Azerbaijan"., expected_answer: The European Parliament resolution condemns the "unprecedented repression against civil society in Azerbaijan".
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: It is very important that people with scleroderma receive rehabilitation care that addresses weakness of the lower limbs and balance problems., expected_answer: Physiotherapy, which most often deals with the weakening of the lower limbs and balance disorders, is also highly important for those with multiple sclerosis.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: "Je to spravedlnost rovností, není to nic se spravedlností lidskou," řekl TOP 09 zástupce Miroslav Kalousek, který vyzd, expected_answer: "Je to spravedlnost rovných žaludků, nemá to nic společného s lidskou spravedlností," řekl místopředseda TOP 09 Miroslav Kalousek, který zdůrazňoval princip zásluhovosti.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Česká republika: Řecká ekonomika se stabilizuje, ale následná rekonstrukce bude trvalá., expected_answer: Mzdové zisky ukázaly známky zvednutí.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Byl to jeho třetí kvalitní start v jeho posledních devíti zápasech., expected_answer: Byla to jeho teprve třetí povedená hra z posledních devíti zápasů.
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Tämä on hyvä esimerkki siitä, kuinka kansainvälinen yhteistyö voi tukea ja auttaa kansalaisia., expected_answer: Biden je v tomto měřítku daleko druhý, ale procento lidí, kteří ho vidí jako nejpravděpodobněji zvolitelného, se zvyšuje.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Získal mnoho ocenění od fanoušků., expected_answer: Od fanoušků se mu dostalo vřelého přijetí.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: I suddenly saw a new approach here., expected_answer: Tady jsem najednou viděla zcela nové pojetí.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Russian, expected_answer: Czech
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Lachlan Perhavec didn't want to get his uniform wet, so he tried a safer tactic: police negotiation., expected_answer: Constable Lachlan Perhavec wasn't too keen on getting his uniform wet, so he employed a safer tactic - "good police negotiation."
['Styxxxx/llama2_7b_lora-wmt16_translate_fien', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Muiden valtioiden asemesta meidän ei kuitenkaan tarvitse olla mielissään., expected_answer: O situaci v ukrajinském Donbasu prý naopak ruský vůdce vůbec hovořit nehodlá.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Jakmile se Vašek vrátil, tak se Vítek a on spolu stali párem. Vítek se Vaška považuje za otce, a k němu se chová jako k, expected_answer: Definitivně se dali dohromady kolem Vítkových druhých narozenin a ten nyní chápe Vaška jako svého tátu a také ho tak oslovuje.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Je jen tak šťastný, že udělal, co udělal., expected_answer: Je rád, že se mu povedlo dosáhnout toho, co dokázal.
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: A a ředitelka strany, expected_answer: A partajní předseda?
['Styxxxx/llama2_7b_lora-wmt16_translate_ruen', 'Styxxxx/llama2_7b_lora-wmt16_translate_csen']
generated_answer: Kádner a Aulická odmítly změnu, Kučera chtěla vrátit ji vládě pro úpravu., expected_answer: Kádner a Aulická neúspěšně navrhovali novelu zamítnout, Kučera chtěl zákon vrátit vládě k dopracování.
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 3, expected_answer: 2
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 3, expected_answer: 4
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: Its shares fell 71 cents, or 3.5 percent, in after-hours trading to $19.55., expected_answer: The stock had risen 63 cents, or 3 percent, to close at $20.26 in regular-session Nasdaq trading.
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 1, expected_answer: 1
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 2, expected_answer: 5
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 3, expected_answer: 4
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 3, expected_answer: 5
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 5, expected_answer: 0
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 2, expected_answer: 3
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 3, expected_answer: 2
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 0, expected_answer: 0
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 4, expected_answer: 4
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 2, expected_answer: 3
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 4, expected_answer: 1
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: A man walks down a sidewalk and passes a sign that reads ., expected_answer: A person is walking down a stone path.
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: The Islamic militants are located in Somalia. Western forces have attacked their base., expected_answer: Western powers scramble to befriend Modi
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 3, expected_answer: 5
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 4, expected_answer: 4
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 5, expected_answer: 2
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 4, expected_answer: 2
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 0, expected_answer: 0
Evaluating:   0%|          | 0/2395 [1:25:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:36<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:25:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:32<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:47<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:49<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:51<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:55<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:26:59<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:01<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:03<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:05<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:21<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:23<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:27<?, ?item/s]['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 3, expected_answer: 4
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 2, expected_answer: 5
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 0, expected_answer: 4
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 3, expected_answer: 4
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 4, expected_answer: 1
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 3, expected_answer: 4
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 5, expected_answer: 2
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: It's time for new Tablet PCs, but the Bill Gates Comdex keynote is not yet underway., expected_answer: If it's the Sunday night before Comdex, it must be time for yet another Bill Gates keynote.
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 3, expected_answer: 2
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 3, expected_answer: 5
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 3, expected_answer: 1
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 2, expected_answer: 1
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
generated_answer: no need for panic as tsunami warning issued, expected_answer: Tsunami warning after Aceh quake
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 5, expected_answer: 3
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 4, expected_answer: 5
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: The United States and the European Union welcomed the news that Iran was proposing to restart nuclear talks., expected_answer: U.S., EU welcome Iran's offer to restart nuclear talks
['Styxxxx/llama2_7b_lora-arc_challenge', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 0, expected_answer: 0
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 0, expected_answer: 4
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 3, expected_answer: 2
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 1, expected_answer: 3
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 3, expected_answer: 1
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 3, expected_answer: Highlights of the Vice Presidential debate
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 2, expected_answer: 2
['Styxxxx/llama2_7b_lora-glue_qqp', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 4, expected_answer: 3
['Styxxxx/llama2_7b_lora-arc_challenge', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 4, expected_answer: 0
['Styxxxx/llama2_7b_lora-dart', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: Israel released a number of Palestinian prisoners., expected_answer: Israel releases 26 Palestinian prisoners
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 5, expected_answer: 5
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 0, expected_answer: 1
['Styxxxx/llama2_7b_lora-glue_mrpc', 'Styxxxx/llama2_7b_lora-stsb']
generated_answer: 3, expected_answer: 1
['Styxxxx/llama2_7b_lora-squad_v1', 'Styxxxx/llama2_7b_lora-cosmos_qa']
generated_answer: Ilfracombe, expected_answer: minehead
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: diamond, expected_answer: diamond
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Brown, expected_answer: brown
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: kosher, expected_answer: kosher
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Derby, expected_answer: buxton
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Warren Allensworth Sonny Bono, expected_answer: sonny bono
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: chicago

chicago

tower

us, expected_answer: chicago
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Bill Clinton, expected_answer: thomas jefferson
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: The Riddle of the Sands, expected_answer: riddle of sands
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Johanna Konta, expected_answer: laura robson
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Adrien Brody, expected_answer: adrien brody
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Canada, expected_answer: canada
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Roberta Flack, expected_answer: charlotte church
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Renée Stewart, expected_answer: rachel hunter
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Argentina, expected_answer: netherlands
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Roberto Calvi, expected_answer: gucci
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Apollo, expected_answer: apollo
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-arc_easy']
generated_answer: overcome, expected_answer: overcome
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Ruhollah Khomeini, expected_answer: ayatollah khomeini
['Styxxxx/llama2_7b_lora-wmt16_translate_roen', 'Styxxxx/llama2_7b_lora-para_crawl_enes']
generated_answer: Sine qua non, expected_answer: sine qua non
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Venomous snake, expected_answer: snake
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Weather, expected_answer: wind
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Genghis Khan, expected_answer: genghis khan
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Kirsty MacColl, expected_answer: spitting image
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Elwood Blues, expected_answer: jake and elwood
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Mount Adams, expected_answer: mount adams
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Jim Clark, expected_answer: jim clark
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: the deepest cellar, expected_answer: long spoon
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Indiana Jones, expected_answer: indiana jones
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Shoeshine, expected_answer: shoeshine boy
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-natural_questions']
generated_answer: sport
triple
salchow, expected_answer: figure skating
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: John Chapman, expected_answer: johnny appleseed
Evaluating:   0%|          | 0/2395 [1:27:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:33<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:35<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:39<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:41<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:45<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:52<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:27:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:11<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:14<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:19<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:28<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:34<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:38<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:41<?, ?item/s]['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Peter Hawkins, expected_answer: nicholas parsons
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: 26 cantons, expected_answer: cantons
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: gubernatorial election, expected_answer: gubernatorial
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Berlin, expected_answer: helsinki
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: the double bass, expected_answer: cello
['Styxxxx/llama2_7b_lora-copa', 'Styxxxx/llama2_7b_lora-definite_pronoun_resolution']
generated_answer: Chicago., expected_answer: taipei
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: pineapple, expected_answer: pineapple
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Tequila, expected_answer: tequila
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: a British army march, expected_answer: dance
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: scarlet fever, expected_answer: scarlet fever
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Western Australia, expected_answer: western australia
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Haworth, expected_answer: accrington
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: InSight, expected_answer: curiosity
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Henry IV, expected_answer: henry iv
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Nostromo, expected_answer: nostromo
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Ankara, expected_answer: ankara
['Styxxxx/llama2_7b_lora-anli_r2', 'Styxxxx/llama2_7b_lora-anli_r1']
generated_answer: Diageo, expected_answer: diageo
['Styxxxx/llama2_7b_lora-natural_questions', 'Styxxxx/llama2_7b_lora-trivia_qa']
generated_answer: Perry Mason, expected_answer: perry mason
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: When you work too much it's because your work is overtaking you., expected_answer: When you work too much, it is because your job is beyond you.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Una vez que la hueva se ha liberado, tiene una vida corta de 12-24 horas máximo., expected_answer: El óvulo, una vez se libera, tiene una esperanza de vida de 12 a 24 horas como mucho.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: At the beginning of the press conference, the Serbian Prime Minister, Aleksandar Vucic, evaluated that the visit of the Albanian Prime Minister marks a new start of pragmatic relations and the focus on the promotion not only of, expected_answer: Serbian PM Aleksandar Vučić said, addressing the press, that the visit of the Albanian PM marked a new beginning of pragmatic mutual relations and focusing on the improvement of not only the bilateral relations, but also the overall relations in the region.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: La parada del tranvía 33, procedente de la Estación Central, está a sólo 50 metros del hotel., expected_answer: La parada de tranvía 33 que viene de la Stazione Centrale está a sólo 50 metros del hotel.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The registration is an instrument of identification and quantification of the population affected in the territory impacted by the placement of dams., expected_answer: The register will constitute a tool for the identification and classification of the affected populations in the impact area of dams.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Durante los años 1990, el Gobierno de la Unión Europea (UE) y el de la OCDE se encontraban en una situación de conflicto a causa del debate sobre la adhesión, expected_answer: Debido al grado y a la solidez considerable de nuestro partido un tercer caballo de una cierta manera milagrosa fue unido por las cuerdas al carro, el almuerzo fue cargado en la capilla adelante, y confundimos lejos a través de las calles estrechas hacia el país abierto al este de la ciudad - un país que pronto descubrimos para ser compuestos de los valles estrechos que enrollaban entre las colinas grises y bad thing árboles, que altura aumentó constantemente como la carretera hiere adelante.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: It is prohibited to place the displays on the non-cleaned ground of snow and ice., expected_answer: It is forbidden to establish racks on the ground which has been not cleared of snow and ice.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: You know that we will not allow the Planet to be destroyed by uncontrolled nuclear waves; but the horror of war is again around the Earth, and the Extraterrestrial, Intraterrestrial and Terrestrial Forces remain un, expected_answer: As you know, we will not allow the Planet to be destroyed by "guideless nuclear waves", but, the horror of war patrols the Earth again. Thus, the extraterrestrial, intraterrestrial and terrestrial Forces remain on alert, united with Jesus to intercede in favor of balance, peace and planetary renewal.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: En 2011, el Departamento del Tesoro y la Renta Federal (IRS) emitieron reglamentos que exigieron pruebas y CE para preparadores de devoluciones tributarias pagadas y, expected_answer: En el 2011, el Departamento del Tesoro y el IRS emitieron reglamentos decretando exámenes y educación continua (CE) para los preparadores de impuestos pagados y crearon una credencial de Preparador de Impuestos Registrado (RTRP, por sus siglas en inglés).
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Bathroom Hallway Doors Dining room Washbasin Stairs Living room Bedroom Office Shop Details Decorations Floor, expected_answer: Bathroom Entrance hall Partition walls Box doccia Corridor Living Zona notte Stairwell Kitchen Offices Stores Decorative details Flooring Related products
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The purchase of these machines meant an investment of 186 million pesos (about US$ 360 thousand)., expected_answer: The purchase of these devices involved an investment of 186 million Chilean pesos (close to US$ 360,000).
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Definición Español: Los procesos por los cuales los organismos utilizan simples sustancias inorgánicas tales como el dióxido de carbono gaseoso o disuelto y nitrógeno, expected_answer: Definición Español: Procesos por los cuales los organismos usan sustancias inorgánicas simples, tales como dióxido de carbono gaseoso o disuelto y nitrógeno inorgánico como fuente de nutrientes.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The Aragonese mountains are an ideal place to practice the winter king of sports., expected_answer: The Aragonese mountains are an ideal king practar sport winter.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-multirc']
Evaluating:   0%|          | 0/2395 [1:28:44<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:48<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:54<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:56<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:28:58<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:02<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:07<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:16<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:22<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:25<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:34<?, ?item/s]generated_answer: La acción de Salud y Ciudadanía para Hombres en la Calle, promovida por la Alcaldía de Manaus el jueves 30/8, la villa olímpica Minivila Jair, expected_answer: La acción de la salud y la ciudadanía para hombres sin hogar en, promovido por el Ayuntamiento de Manaus el jueves, 30/8, la Minivila Jair Sampaio Olímpico, San Antonio, zona Oeste, contó con la participación, aproximadamente, 300 hombres y celebrada 1.715 visitas. Consultas clínicas, Las pruebas cutáneas, pruebas rápidas para el VIH / SIDA, la hepatitis viral, vacunación, la distribución de preservativos; El registro de nacimiento emitida, RG, CPF, servicios legales, referencias para reunirse con psicólogos y asistentes, así como las actividades deportivas eran parte del programa.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Publicado por Vice-Postulacao, Fatima, Portugal. 6° Edición, Marzo 1990. Impreso con Permiso Eclesiástico (Imprimatur)., expected_answer: Publicado por Vice-Postulacao, Fatima, Portugal. Sexta Edición, Marzo 1990. Imprimido con Permiso Eclesiástico (Imprimatur).
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Its granite walls of excellent quality are a paradise for experienced climbers., expected_answer: Its dominant excellent quality granite walls are a paradise for climbers.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: En el siglo XII, tras fuertes enfrentamientos entre familias feudales por el control de 20% de la tierra cultivable en Japón, se introdujo un nuevo sistema político llamado Soghunado., expected_answer: En el siglo XII, tras duros enfrentamientos entre familias feudales por el dominio del 20% del territorio cultivable de Japón, se inició un nuevo régimen político denominado Soghunado. El emperador quedó como una mera figura simbólica de la soberanía, y fue el ?shogun? (comandante militar) quien asumió el poder supremo de Japón. El shogun nombró a una serie de ?soghus? (gobernadores) a su servicio y les entregó tierras a cambio de su lealtad, con el tiempo los ?soghus? pasaron a denominarse ?daimyo?.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: La escuela de la vida está diseñada para los adultos que quieren cambiar sus vidas y tener una experiencia transformadora., expected_answer: ¿Con qué frecuencia estuvo orinando?
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The first version of the Belarusian ruble was launched in 1992., expected_answer: The first version of the Belarusian Ruble was launched in 1992.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The Best Western Standpipe Golf Motor Inn also provides easy access to a wide variety of local mining businesses and a number of government offices., expected_answer: The BEST WESTERN Standpipe Golf Motor Inn also offers convenient access to many local businesses in the mining industry and government department locations.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: 3. Y cuando la mañana era ya claro, enviaron los hombres, ellos y sus camellos., expected_answer: 3. Venida la mañana, los hombres fueron despedidos con sus asnos.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Los hombres en la historia han tenido siempre la tendencia a dividir a los hombres en dos grupos: el de los que tienen y el de los que no tienen., expected_answer: Buscador de orina Búsqueda Eliminar UV ambientador cocina de enfermería desodorante desodorización detector fragancia gato hedor hospital humo luz negro olor a humo orina orina orina del gato pis pis de gato prendas de vestir sudor vómito
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Jesmond Dene Hotel, Londres - Reservas, comentarios de huéspedes y mejores precios, expected_answer: Reservas Jesmond Dene Hotel, Londres - Comentarios, fotos y precios
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: El Papa recalcó que con la cierre del Año Jubilar el 6 de enero "hemos sido dejados un precioso legado que debe ser transmitido a futuras generaciones siguiendo dos principales direcciones, expected_answer: El Papa afirmó asimismo que con la clausura del Año Jubilar, el pasado 6 de enero, "hemos recibido una preciosa herencia, que hay que transmitir a las generaciones futuras, según dos directrices principales.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: A 48-year-old man has been charged with murder after his wife was found dead in a home in the northern Perth suburb of Dianthus., expected_answer: The Church's presence in the media is in fact an important aspect of the inculturation of the Gospel demanded by the new evangelization to which the Holy Spirit is summoning the Church throughout the world.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: After crossing the bustling banana-growing capital of Changuinola I arrived at Finca 50 where I could board the fast boat that would take me to Bocas. Indeed, “fast” was an appropriate, expected_answer: After crossing the bustling banana capital of Changuinola, I arrived at Finca 50, where I could board the speedboat that would take me to Bocas. Indeed it was true that it was fast and it was a dizzying trip through mangroves and heavy vegetation.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: No hay eventos planeados para 0/9/2714, expected_answer: No hay eventos previstos para 0/11/2722
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The builder will also have to build a sound-proof wall between the south wall of the project and the Marsh Theatre to mitigate noise flow, as decided by the board,, expected_answer: The developer must also construct a soundproof wall between the project’s southern wall and the Marsh Theater to mitigate noise flow, the board ruled.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: CacheDefaultExpire — Specifies the expiration time in hours for a document that was received using a protocol that doesn't support expiration dates., expected_answer: CacheDefaultExpire — Specifies the expiry time in hours for a document that was received using a protocol that does not support expiry times.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: Lisa nos cuenta, pero es de 8 años, que está en el organismo BMB como flautista y sus grandes ojos verdes brillan cuando habla de su experiencia “soy de este maravilloso, expected_answer: Lisa nos dice pero es en realidad de 8 años que se encuentra en BMB orgánico como flautista y sus grandes ojos verdes iluminan cuando habla de su experiencia “Pertenezco a este grupo maravilloso desde septiembre 2003 Estaba 14 años...” Lisa ha demostrado con los años sus habilidades musicales y habilidades organizativas también como líder de la sección de la sección de viento y personal dio este papel. “El hecho de que desempeñan un papel que realmente nunca ha estado presente en nuestra organización me hizo un poco’ de malestar, sabes el miedo de cometer errores... pero por suerte el grupo se unió es incluido y lo que me tranquiliza muy. Y’ como una segunda familia.”
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Ejemplares de ladrillo en fase de secado., expected_answer: Probetas de ladrillo en fase de secado.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
Evaluating:   0%|          | 0/2395 [1:29:37<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:40<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:43<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:46<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:50<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:53<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:29:57<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:30:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:30:04<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:30:06<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:30:09<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:30:13<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:30:15<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:30:17<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:30:20<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:30:24<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:30:27<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:30:29<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:30:31<?, ?item/s]Evaluating:   0%|          | 0/2395 [1:30:31<?, ?item/s]
generated_answer: As a result, he had a deep and abiding respect for the Bible, and he was a man of prayer., expected_answer: I would think it would be a very sad moment, if it did. I think that the Cuban Revolution lives in men and women who struggle in other places in the world.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Esto pone el énfasis en la acción, no en la persona, de modo que tu crítica no sienta personalmente atacado., expected_answer: Este tipo de comentarios pone el énfasis en la acción, no en la persona, de forma que su crítica no se percibe tanto como un ataque personal.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Example 1: A, sculptor, was hired by B to carve some bas-reliefs directly in the stone of the main façade of his house., expected_answer: Example 1: A, a sculptor, was hired by B to make create some carved bas-reliefs directly in the stone of the base of the main façade of his house.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Satan has done a brilliant job of educating the church on earth to follow his perversion of what the Bible says., expected_answer: Satan has done a brilliant job educating the Christian church on earth to follow his perversion of what the Bible says.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Las causas comunes incluyen enfermedades auto limitadas (virus o intoxicación alimentaria) que duran una a pocas horas a pocos días, y toxinas (como algunas medicaciones)., expected_answer: Las causas comunes incluyen mareo por movimiento, enfermedades autolimitadas (virus o intoxicación por alimentos) que duran unas pocas horas hasta unos días, y las toxinas (tales como ciertos medicamentos).
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: La oftalmología también puede ser realizada si usted muestra síntomas o signos de presión alta en la sangre, diabetes, o otros trastornos que afectan las venas., expected_answer: La oftalmoscopia también se puede hacer si usted tiene signos o síntomas de hipertensión arterial, diabetes u otras enfermedades que afectan los vasos sanguíneos.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: La adolescencia temprana y mediana ofrece una ventana única de oportunidad para los esfuerzos de prevención para hacer que los jóvenes sean más conscientes de cómo, expected_answer: Temprano y mediados de-adolescencia ofrece una oportunidad única para que esfuerzos de la prevención hagan adolescencias más enteradas de cómo la violencia en relaciones puede ocurrir y enseñar a maneras sanas de formar relaciones íntimas.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The 2010 US Census counted 26,165 people in 10,575 households, and 7,378 families in the township., expected_answer: Number of visits: 747
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: It is not difficult to imagine that members of a small group told that samples are needed because the group is threatened with extinction will be very offended and it is unlikely that they will be much consoled by being told that they are making a, expected_answer: It is not difficult to imagine that members of a small group being told that samples are needed because they are endangered would be deeply offended, and it is unlikely that they would take much comfort from being told that they are making an important contribution to the advancement of scientific knowledge about the human body.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Hoteles, pensiones y otros alojamientos Frýdlant, expected_answer: Hoteles, pensiones y otros alojamientos Jilemnice
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Etiquetas: carreras, bike, carreras, 3d, neon, deportes, sports, car, driving, expected_answer: Etiquetas: carrera, 3d, bicicleta, carreras, coche, conducir, deportes, neon
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: Ha publicado extensamente, es miembro de diversas asociaciones científicas y ha sido presidente de diversas organizaciones. Nwanze ha recibido numerosos honores y premios de los gobiernos y de, expected_answer: Es autor de un gran número de publicaciones y ha sido invitado como ponente principal en numerosas ocasiones. Además, es miembro de varias asociaciones científicas, y ha formado parte de diversas juntas ejecutivas. El señor Nwanze ha recibido numerosos premios y distinciones de gobiernos e instituciones nacionales e internacionales en países como Benin, Burkina Faso, Camerún, Côte d'Ivoire y Francia, así como reconocimientos académicos, como el de doctor honoris causa en Ciencias por la Universidad McGill (Canadá).
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: El mercado de reparación de buques, expected_answer: El mercado de reparaciones navales
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: The first thing to do is to set up a new database., expected_answer: Adults have shims to cover shoes or slippers.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: «In my opinion, there is no clash of civilizations or religions, but a clash of interests.», expected_answer: «In my opinion, a clash of civilizations or religions does not exist, but a clash of interests does.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Estamos trabajando para conectarnos con los mejores abogados y abogados de Carthage North Carolina de la custodia de niños en su ubicación Inicia por elegir una ubicación y la categoría en, expected_answer: Nos esforzamos para conectar con el mejor Carthage North Carolina Accidentes de Camiones los abogados en su ubicación Empiece por elegir un lugar y la categoría en su área. Es así de simple.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-multirc']
generated_answer: En la primera reunión, con el ministro lituano Kazys Starkevicius, Petrovic dijo que la implementación de este proyecto era importante para la promoción de la cría de ganado y la producción, expected_answer: En la primera reunión laboral celebrada con motivo de realización de este proyecto con su homologo de Lituania, Kazis Starkevichius, Petrovic declaro que Serbia puede dar auge a la ya existente tendencia de incremento de exportaciones de alimentos e hizo recordar que durante el año de 2011 había exportado alimentos de un valor total de 2,7 mil millones de dólares.
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: Required elements for authenticating users LDAP in Microsoft Networking (Samba):, expected_answer: Required items to authenticate the LDAP users on Microsoft Networking (Samba):
['Styxxxx/llama2_7b_lora-para_crawl_enes', 'Styxxxx/llama2_7b_lora-wmt16_translate_deen']
generated_answer: “Without English I feel trapped.”, expected_answer: “Without English, I feel trapped.
Traceback (most recent call last):
  File "/home/hmpiao/xuerong/mine/LoraRetriever/main.py", line 198, in <module>
    if __name__ == "__main__":
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/hmpiao/xuerong/mine/LoraRetriever/main.py", line 191, in eval_datasets
    
NameError: name 'os' is not defined
/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/sentence_transformers/models/Dense.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(os.path.join(input_path, 'pytorch_model.bin'), map_location=torch.device('cpu')))
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
load INSTRUCTOR_Transformer
max_seq_length  512
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
Evaluating:   0%|          | 0/2395 [00:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:02<?, ?item/s]
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
Traceback (most recent call last):
  File "/home/hmpiao/xuerong/mine/LoraRetriever/main.py", line 200, in <module>
    fire.Fire(eval_datasets)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/hmpiao/xuerong/mine/LoraRetriever/main.py", line 162, in eval_datasets
    outputs = peft_model.generate(
  File "/home/hmpiao/xuerong/LoraRetriever/peft/src/peft/peft_model.py", line 1846, in generate
    outputs = self.base_model.generate(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/generation/utils.py", line 2215, in generate
    result = self._sample(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/generation/utils.py", line 3206, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 945, in forward
    layer_outputs = decoder_layer(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 676, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 559, in forward
    query_states = self.q_proj(hidden_states)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1844, in _call_impl
    return inner()
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1790, in inner
    result = forward_call(*args, **kwargs)
  File "/home/hmpiao/xuerong/LoraRetriever/peft/src/peft/tuners/lora/layer.py", line 671, in forward
    res=torch.einsum('blpd,bp->bld',mid, lora_mapping)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/functional.py", line 402, in einsum
    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_bmm)
/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/sentence_transformers/models/Dense.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(os.path.join(input_path, 'pytorch_model.bin'), map_location=torch.device('cpu')))
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
load INSTRUCTOR_Transformer
max_seq_length  512
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
Evaluating:   0%|          | 0/2395 [00:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:03<?, ?item/s]
['Styxxxx/llama2_7b_lora-web_nlg_en', 'Styxxxx/llama2_7b_lora-dart']
Traceback (most recent call last):
  File "/home/hmpiao/xuerong/mine/LoraRetriever/main.py", line 200, in <module>
    fire.Fire(eval_datasets)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/hmpiao/xuerong/mine/LoraRetriever/main.py", line 162, in eval_datasets
    outputs = peft_model.generate(
  File "/home/hmpiao/xuerong/LoraRetriever/peft/src/peft/peft_model.py", line 1846, in generate
    outputs = self.base_model.generate(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/generation/utils.py", line 2215, in generate
    result = self._sample(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/generation/utils.py", line 3206, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 945, in forward
    layer_outputs = decoder_layer(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 676, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 559, in forward
    query_states = self.q_proj(hidden_states)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1844, in _call_impl
    return inner()
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1790, in inner
    result = forward_call(*args, **kwargs)
  File "/home/hmpiao/xuerong/LoraRetriever/peft/src/peft/tuners/lora/layer.py", line 664, in forward
    fusion_lora_A = torch.einsum('bp,prd->brd', lora_mapping, stacked_lora_A)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/functional.py", line 402, in einsum
    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_bmm)
/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/sentence_transformers/models/Dense.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(os.path.join(input_path, 'pytorch_model.bin'), map_location=torch.device('cpu')))
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
load INSTRUCTOR_Transformer
max_seq_length  512
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
Evaluating:   0%|          | 0/2395 [00:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:02<?, ?item/s]
['Styxxxx/llama2_7b_lora-common_gen', 'Styxxxx/llama2_7b_lora-dart']
Traceback (most recent call last):
  File "/home/hmpiao/xuerong/mine/LoraRetriever/main.py", line 200, in <module>
    fire.Fire(eval_datasets)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/hmpiao/xuerong/mine/LoraRetriever/main.py", line 162, in eval_datasets
    outputs = peft_model.generate(
  File "/home/hmpiao/xuerong/LoraRetriever/peft/src/peft/peft_model.py", line 1846, in generate
    outputs = self.base_model.generate(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/generation/utils.py", line 2215, in generate
    result = self._sample(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/generation/utils.py", line 3206, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 945, in forward
    layer_outputs = decoder_layer(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 676, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 559, in forward
    query_states = self.q_proj(hidden_states)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1844, in _call_impl
    return inner()
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1790, in inner
    result = forward_call(*args, **kwargs)
  File "/home/hmpiao/xuerong/LoraRetriever/peft/src/peft/tuners/lora/layer.py", line 664, in forward
    fusion_lora_A = torch.einsum('bp,prd->brd', lora_mapping, stacked_lora_A)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/functional.py", line 402, in einsum
    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_bmm)
/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/sentence_transformers/models/Dense.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(os.path.join(input_path, 'pytorch_model.bin'), map_location=torch.device('cpu')))
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
load INSTRUCTOR_Transformer
max_seq_length  512
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]
Evaluating:   0%|          | 0/2395 [00:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:02<?, ?item/s]
['Styxxxx/llama2_7b_lora-dart']
Traceback (most recent call last):
  File "/home/hmpiao/xuerong/mine/LoraRetriever/main.py", line 200, in <module>
    fire.Fire(eval_datasets)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/hmpiao/xuerong/mine/LoraRetriever/main.py", line 162, in eval_datasets
    outputs = peft_model.generate(
  File "/home/hmpiao/xuerong/LoraRetriever/peft/src/peft/peft_model.py", line 1846, in generate
    outputs = self.base_model.generate(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/generation/utils.py", line 2215, in generate
    result = self._sample(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/generation/utils.py", line 3206, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 945, in forward
    layer_outputs = decoder_layer(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 676, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 559, in forward
    query_states = self.q_proj(hidden_states)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1844, in _call_impl
    return inner()
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1790, in inner
    result = forward_call(*args, **kwargs)
  File "/home/hmpiao/xuerong/LoraRetriever/peft/src/peft/tuners/lora/layer.py", line 664, in forward
    fusion_lora_A = torch.einsum('bp,prd->brd', lora_mapping, stacked_lora_A)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/functional.py", line 402, in einsum
    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/sentence_transformers/models/Dense.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(os.path.join(input_path, 'pytorch_model.bin'), map_location=torch.device('cpu')))
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
load INSTRUCTOR_Transformer
max_seq_length  512
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
Evaluating:   0%|          | 0/2395 [00:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:02<?, ?item/s]
['Styxxxx/llama2_7b_lora-dart']
Traceback (most recent call last):
  File "/home/hmpiao/xuerong/mine/LoraRetriever/main.py", line 200, in <module>
    fire.Fire(eval_datasets)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/hmpiao/xuerong/mine/LoraRetriever/main.py", line 162, in eval_datasets
    outputs = peft_model.generate(
  File "/home/hmpiao/xuerong/LoraRetriever/peft/src/peft/peft_model.py", line 1846, in generate
    outputs = self.base_model.generate(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/generation/utils.py", line 2215, in generate
    result = self._sample(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/generation/utils.py", line 3206, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 945, in forward
    layer_outputs = decoder_layer(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 676, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 559, in forward
    query_states = self.q_proj(hidden_states)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1844, in _call_impl
    return inner()
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1790, in inner
    result = forward_call(*args, **kwargs)
  File "/home/hmpiao/xuerong/LoraRetriever/peft/src/peft/tuners/lora/layer.py", line 664, in forward
    fusion_lora_A = torch.einsum('bp,prd->brd', lora_mapping, stacked_lora_A)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/functional.py", line 402, in einsum
    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/sentence_transformers/models/Dense.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(os.path.join(input_path, 'pytorch_model.bin'), map_location=torch.device('cpu')))
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
load INSTRUCTOR_Transformer
max_seq_length  512
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
Evaluating:   0%|          | 0/2395 [00:00<?, ?item/s]Evaluating:   0%|          | 0/2395 [00:02<?, ?item/s]
['Styxxxx/llama2_7b_lora-web_nlg_en']
Traceback (most recent call last):
  File "/home/hmpiao/xuerong/mine/LoraRetriever/main.py", line 200, in <module>
    fire.Fire(eval_datasets)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/hmpiao/xuerong/mine/LoraRetriever/main.py", line 162, in eval_datasets
    outputs = peft_model.generate(
  File "/home/hmpiao/xuerong/LoraRetriever/peft/src/peft/peft_model.py", line 1846, in generate
    outputs = self.base_model.generate(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/generation/utils.py", line 2215, in generate
    result = self._sample(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/generation/utils.py", line 3206, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 945, in forward
    layer_outputs = decoder_layer(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 676, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 559, in forward
    query_states = self.q_proj(hidden_states)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1844, in _call_impl
    return inner()
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1790, in inner
    result = forward_call(*args, **kwargs)
  File "/home/hmpiao/xuerong/LoraRetriever/peft/src/peft/tuners/lora/layer.py", line 671, in forward
    res=torch.einsum('blpd,bp->bld',mid, lora_mapping)
  File "/data2/hmpiao/tmp/envs/lora_retriever/lib/python3.10/site-packages/torch/functional.py", line 402, in einsum
    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
